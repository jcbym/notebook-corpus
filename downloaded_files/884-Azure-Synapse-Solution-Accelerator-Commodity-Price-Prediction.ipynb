{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation.\r\n",
        "Licensed under the MIT license."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate forecast data\n",
        "Prepare new forecast data for scoring script and store it as a spark table\n",
        "\n",
        "1. Define forecasting dates\n",
        "2. Create date range and store data\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define forecasting start and end dates\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Define date range for forecast\n",
        "table_name = \"default.forecast\"\n",
        "start_date = '2020-01-01'\n",
        "end_date = '2021-01-01'\n",
        "\n",
        "data_lake_account_name = \"\"\n",
        "file_system_name = \"\"\n",
        "scored_data_path = \"abfss://%s@%s.dfs.core.windows.net/Result/Forecast\" % (file_system_name, data_lake_account_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create forecasting data\n",
        "Create a forecasting dataset and store it as a spark table\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dates\n",
        "dates = pd.date_range(start=start_date,end=end_date,freq='MS')\n",
        "\n",
        "# Create a pandas dataframe\n",
        "df = pd.DataFrame({'Date': dates, 'average_value': [0.0] * len(dates)})\n",
        "\n",
        "# Create a pyspark dataframe\n",
        "df_forecast = spark.createDataFrame(df)\n",
        "\n",
        "df_forecast.write.mode('overwrite').save(scored_data_path,format='parquet')\n",
        "# Store forecast results\n",
        "df_forecast.write.mode(\"overwrite\").saveAsTable(table_name) \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}