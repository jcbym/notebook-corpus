{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Selección de predictores mediante algoritmo genético</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Joaquín Amat Rodrigo</b> <i>j.amatrodrigo@gmail.com</i></center>\n",
    "\n",
    "<center><i>Agosto, 2019</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tabla de contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introducción\" data-toc-modified-id=\"Introducción-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introducción</a></span></li><li><span><a href=\"#Algoritmo\" data-toc-modified-id=\"Algoritmo-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Algoritmo</a></span><ul class=\"toc-item\"><li><span><a href=\"#Población\" data-toc-modified-id=\"Población-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Población</a></span></li><li><span><a href=\"#Fitness\" data-toc-modified-id=\"Fitness-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Fitness</a></span></li><li><span><a href=\"#Seleccionar-individuos\" data-toc-modified-id=\"Seleccionar-individuos-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Seleccionar individuos</a></span></li><li><span><a href=\"#Cruzar-dos-individuos-(crossover,-recombinación)\" data-toc-modified-id=\"Cruzar-dos-individuos-(crossover,-recombinación)-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Cruzar dos individuos (<em>crossover</em>, recombinación)</a></span></li><li><span><a href=\"#Mutar-individuo\" data-toc-modified-id=\"Mutar-individuo-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Mutar individuo</a></span></li></ul></li><li><span><a href=\"#Implementación-python\" data-toc-modified-id=\"Implementación-python-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Implementación python</a></span><ul class=\"toc-item\"><li><span><a href=\"#Librerías-necesarias\" data-toc-modified-id=\"Librerías-necesarias-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Librerías necesarias</a></span></li><li><span><a href=\"#Clase-individuo\" data-toc-modified-id=\"Clase-individuo-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Clase individuo</a></span></li><li><span><a href=\"#Clase-Población\" data-toc-modified-id=\"Clase-Población-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Clase Población</a></span></li></ul></li><li><span><a href=\"#Ejemplos\" data-toc-modified-id=\"Ejemplos-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Ejemplos</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Los algoritmos genéticos son métodos de optimización heurística que, entre otras aplicaciones, pueden emplearse para encontrar la combinación de variables que consigue maximizar la capacidad predictiva de un modelo. Su funcionamiento está inspirado en la [teoría evolutiva de selección natural](https://es.wikipedia.org/wiki/Selecci%C3%B3n_natural) propuesta por Darwin y Alfred Russel: los individuos de una población se reproducen generando nuevos descendientes, cuyas características, son combinación de las características de los progenitores (más ciertas mutaciones). De todos ellos, únicamente los mejores individuos sobreviven y pueden reproducirse de nuevo, transmitiendo así sus características a las siguientes generaciones.\n",
    "\n",
    "> *Los algoritmos genéticos son solo una de las muchas estrategias que existen para seleccionar los predictores más relevantes, y no tiene por qué ser la más adecuada en todos los escenarios. Por ejemplo, existen estrategias iterativas Stepwise selection, modelos como Random Forest, Boosting y Lasso capaces de excluir automáticamente predictores, y técnicas de reducción de dimensión como PCA y t-SNE.*\n",
    "\n",
    "> *La implementación de algoritmo que se muestra en este documento pretende ser lo más explicativa posible aunque para ello no sea la más eficiente.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo \n",
    "\n",
    "Aunque existen variaciones, algunas de las cuales se describen a lo largo de este documento, en términos generales,la estructura de un algoritmo genético para la selección de predictores sigue los siguientes pasos:\n",
    "\n",
    "---\n",
    "\n",
    "1. Crear una población inicial aleatoria de $P$ individuos. En este caso, cada individuo representa una combinación de predictores.\n",
    "<br><br>\n",
    "\n",
    "2. Calcular la fortaleza (*fitness*) de cada individuo de la población.\n",
    "<br><br>\n",
    "\n",
    "3. Crear una nueva población vacía y repetir los siguientes pasos hasta que se hayan creado $P$ nuevos individuos.\n",
    "\n",
    "    3.1 Seleccionar dos individuos de la población existente, donde la probabilidad de selección es proporcional al *fitness* de los individuos.\n",
    "\n",
    "    3.2 Cruzar los dos individuos seleccionados para generar un nuevo descendiente (*crossover*).\n",
    "\n",
    "    3.3 Aplicar un proceso de mutación aleatorio sobre el nuevo individuo.\n",
    "\n",
    "    3.4 Añadir el nuevo individuo a la nueva población.\n",
    "<br><br>\n",
    "\n",
    "4. Reemplazar la antigua población por la nueva.\n",
    "<br><br>\n",
    "\n",
    "5. Si no se cumple un criterio de parada, volver al paso 2.\n",
    "<br><br>\n",
    "\n",
    "En los siguientes apartados se describe cada una de las etapas del proceso para, finalmente, combinarlas todas en una única función. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Población\n",
    "\n",
    "En el contexto de algoritmos genéticos, el término individuo hace referencia a cada una de las posibles soluciones del problema que se quiere optimizar. En el caso particular de la selección de mejores predictores, cada individuo representa una posible combinación de variables. Para representar dichas combinaciones, se pueden emplear vectores binarios, cuya longitud es igual al número total de predictores disponibles, y cada posición toma el valor *TRUE/FALSE* dependiendo de si el predictor que ocupa esa posición se incluye o excluye. También es común encontrar la representación en términos *0/1*.\n",
    "\n",
    "Por ejemplo, supóngase que las variables disponibles son: $X$1, $X2$, $X3$, $X4$ y $X5$. El individuo *TRUE,FALSE,TRUE,TRUE,FALSE*, o su equivalente codificación *1,0,1,1,0* representa la selección de los predictores $X1$, $X3$, y $X4$.\n",
    "\n",
    "El primer paso del algoritmo genético para la selección de predictores consiste en crear una población inicial aleatoria de individuos. El número máximo y mínimo de *TRUEs* por fila puede estar acotado. Esta acotación resulta útil cuando se quiere limitar, en cierta medida, el número de predictores que pueden incluir los individuos. Es en cierta medida porque, debido a los cruces y mutaciones a lo largo de las generaciones, se pueden crear individuos que excedan los límites iniciales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness\n",
    "\n",
    "Cada individuo de la población debe ser evaluado para cuantificar su fortaleza (*fitness*). Dado que, en este caso, el objetivo es encontrar la combinación de predictores que da lugar al mejor modelo, el fitness de un individuo se calcula con una métrica de calidad del modelo. Dependiendo de la métrica, la relación con el fitness puede ser:\n",
    "\n",
    "+ Error del modelo: si se emplea una métrica de error, el individuo tiene mayor *fitness* cuanto menor sea el error.\n",
    "\n",
    "+ Accuracy, precision, recall, F1…: con este tipo de métricas, el individuo tiene mayor *fitness* cuanto mayor sea la métrica.\n",
    "<br><br>\n",
    "\n",
    "Para conseguir que, independientemente de la métrica, cuanto mayor sea su valor, mayor el *fitness* del individuo, se puede utilizar el −(error). De esta forma, la estrategia de selección es la misma. Es importante recordar que, en el caso del −(error), el intervalo de valores posibles es ($-ifnt$ a 0]. Además, para que las estimaciones sean robustas y evitar el *overfitting*, es muy importante recurrir a estrategias de validación cruzada o *bootstrapping* en la cuantificación del fitness.\n",
    "\n",
    "En este ejemplo, se presentan tres opciones de modelos de evaluación: un modelo lineal por mínimos cuadrados, un modelo de regresión logística y un random forest.\n",
    "\n",
    "+ El modelo lineal solo puede utilizarse para problemas de regresión y emplea la métrica -MSE o -MAE como indicativo de *fitness*.\n",
    "\n",
    "+ El modelo de regresión logística solo puede utilizarse para clasificación binaria y emplea las métricas *Accuracy*,  o índice F1.\n",
    "\n",
    "+ El *random forest* puede utilizarse para problemas de regresión, en cuyo caso emplea la métrica -MSE o -MAE, y clasificación, en cuyo caso emplea el *Accuracy* o índice F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar individuos\n",
    "\n",
    "La forma en que se seleccionan los individuos que participan en cada cruce difiere en las distintas implementaciones de los algoritmos genéticos. Por lo general, todas ellas tienden a favorecer la selección de aquellos individuos con mayor *fitness*. Algunas de las estrategias más comunes son:\n",
    "\n",
    "+ Método de ruleta: la probabilidad de que un individuo sea seleccionado es proporcional a su *fitness* relativo, es decir, a su *fitness* dividido por la suma del *fitness* de todos los individuos de la población. Si el *fitness* de un individuo es el doble que el de otro, también lo será la probabilidad de que sea seleccionado. Este método presenta problemas si el *fitness* de unos pocos individuos es muy superior (varios órdenes de magnitud) al resto, ya que estos serán seleccionados de forma repetida y casi todos los individuos de la siguiente generación serán \"hijos\" de los mismos \"padres\" (poca variación).\n",
    "<br><br>\n",
    "\n",
    "+ Método *rank*: la probabilidad de selección de un individuo es inversamente proporcional a la posición que ocupa tras ordenar todos los individuos de mayor a menor *fitness*. Este método es menos agresivo que el método ruleta cuando la diferencia entre los mayores *fitness* es varios órdenes de magnitud superior al resto.\n",
    "<br><br>\n",
    "\n",
    "+ Selección competitiva (*tournament*): se seleccionan aleatoriamente dos parejas de individuos de la población (todos con la misma probabilidad). De cada pareja se selecciona el que tenga mayor *fitness*. Finalmente, se comparan los dos finalistas y se selecciona el de mayor *fitness*. Este método tiende a generar una distribución de la probabilidad de selección más equilibrada que las dos anteriores.\n",
    "<br><br>\n",
    "\n",
    "+ Selección truncada (*truncated selection*): se realizan selecciones aleatorias de individuos, habiendo descartado primero los *n* individuos con menor *fitness* de la población.\n",
    "<br><br>\n",
    "\n",
    "La conversión de *fitness* a probabilidad es distinta dependiendo de la métrica utilizada para calcular el *fitness*.\n",
    "\n",
    "+ Si el *fitness* es el valor negativo del error (-MSE o -MAE), cuanto menor sea el *fitness* (menor la magnitud del valor negativo), mayor debe ser la probabilidad de ser seleccionado. Para lograr la conversión se emplea $fitness= \\frac{−1}{−1∗(MSE)}$.<br><br>\n",
    "\n",
    "+ Si el *fitness* es el *fitness* o f1, cuanto mayor sea el *fitness*, mayor debe ser la probabilidad de ser seleccionado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cruzar dos individuos (*crossover*, recombinación)\n",
    "\n",
    "El objetivo de esta etapa es generar, a partir de individuos ya existentes (parentales), nuevos individuos (descendencia) que combinen las características de los anteriores. Este es otro de los puntos del algoritmo en los que se puede seguir varias estrategias. Tres de las más empleadas son:\n",
    "\n",
    "+ Cruzamiento a partir de uno solo punto: se selecciona aleatoriamente una posición que actúa como punto de corte. Cada individuo parental se divide en dos partes y se intercambian las mitades. Como resultado de este proceso, por cada cruce, se generan dos nuevos individuos.\n",
    "<br><br>\n",
    "\n",
    "+ Cruzamiento a partir múltiples puntos: se seleccionan aleatoriamente varias posiciones que actúan como puntos de corte. Cada individuo parental se divide por los puntos de corte y se intercambian las partes. Como resultado de este proceso, por cada cruce, se generan dos nuevos individuos.\n",
    "<br><br>\n",
    "\n",
    "+ Cruzamiento uniforme: el valor que toma cada posición del nuevo individuo se obtiene de uno de los dos parentales. Por lo general, la probabilidad de que el valor proceda de cada parental es la misma, aunque podría, por ejemplo, estar condicionada al *fitness* de cada uno. A diferencia de las anteriores estrategias, con esta, de cada cruce se genera un único descendiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutar individuo\n",
    "\n",
    "Tras generar cada nuevo individuo de la descendencia, este se somete a un proceso de mutación en el que, cada una de sus posiciones, puede verse modificada con una probabilidad $p$. Este paso es importante para añadir diversidad al proceso y evitar que el algoritmo caiga en mínimos locales por que todos los individuos sean demasiado parecidos de una generación a otra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "#               SELECCIÓN DE PREDICTORES CON ALGORITMO GENÉTICO                #\n",
    "#                                                                              #\n",
    "# This work by Joaquín Amat Rodrigo is licensed under a Creative Commons       #\n",
    "# Attribution 4.0 International License.                                       #\n",
    "################################################################################\n",
    "# coding=utf-8\n",
    "\n",
    "#%%\n",
    "################################################################################\n",
    "#                          LIBRERÍAS NECESARIAS                                #\n",
    "################################################################################\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "import copy\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from scipy.stats import rankdata\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase individuo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "################################################################################\n",
    "#                              CLASE INDIVIDUO                                 #\n",
    "################################################################################\n",
    "\n",
    "class Individuo:\n",
    "    \"\"\"\n",
    "    Esta clase representa un individuo con una determinada selección de\n",
    "    predictores.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_variables : `int`\n",
    "        longitud del array que define al individuo. Debe coincidir con el\n",
    "        número total de predictores disponibles.\n",
    "\n",
    "    n_max: `int`, optional\n",
    "        número máximo de predictores que puede contener inicialmente un individuo.\n",
    "        Si no se indica un valor (default ``None``) se emplea `n_variables`.\n",
    "\n",
    "    n_min: `int`, optional\n",
    "        número mínimo de predictores que puede contener un individuo. (default 1)\n",
    "\n",
    "    n_max_estricto: `bool`, optional\n",
    "        forzar a que el individuo no pueda contener más de `n_max` predictores.\n",
    "        (default ``False``) Ver notas para más info.\n",
    "\n",
    "    verbose : `bool`, optional\n",
    "        mostrar información del proceso por pantalla. (default ``False``)\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_variables : `int`\n",
    "        longitud del array que define al individuo. Debe coincidir con el\n",
    "        número total de predictores disponibles.\n",
    "\n",
    "    n_max: `int`\n",
    "        número máximo de predictores que puede contener inicialmente un individuo.\n",
    "        Si no se indica un valor (default ``None``) se emplea `n_variables`.\n",
    "\n",
    "    n_max_estricto: `bool`, optional\n",
    "        forzar a que el individuo no pueda contener más de `n_max` predictores.\n",
    "        (default ``False``) Ver notas para más info.\n",
    "\n",
    "    n_min: `int`\n",
    "        número mínimo de predictores que puede contener un individuo. (default 1)\n",
    "\n",
    "    secuencia: `numpy.ndarray`\n",
    "        array de ``True`` y ``False`` que define las columnas que incluye y\n",
    "        excluye como predictores el individuo.\n",
    "    \n",
    "    predictores: `numpy.ndarray`\n",
    "        array con el índice de las columnas empleadas como predictores.\n",
    "\n",
    "    fitness : `float`\n",
    "        valor de fitness del individuo.\n",
    "\n",
    "    metrica : {\"neg_mean_squared_error\",\"neg_mean_absolute_error\", \"f1\", \"accuracy\"}\n",
    "        métrica de evaluación con la que se calcula el fitness.\n",
    "\n",
    "    valor_metrica : `float`\n",
    "        valor de la métrica empleada para calcular el fitness.\n",
    "\n",
    "    n_predictores_incluidos: `int`\n",
    "        número de predictores que incluye el individuo.\n",
    "\n",
    "    modelo: {lineal, logistico, randomforest}\n",
    "        modelo empleado para evaluar al individuo.\n",
    "\n",
    "    tipo_modelo: {regresion, clasificacion}\n",
    "        tipo de modelo (regresión o clasificación)\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    raise Exception\n",
    "        si `n_max` es distinto de ``None`` y mayor que `n_variables`.\n",
    "\n",
    "    raise Exception\n",
    "        si `metrica` es distinto de \"neg_mean_squared_error\",\n",
    "        \"neg_mean_absolute_error\", \"f1\" o \"accuracy\".\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "    El argumento `n_max` establece el número máximo de predictores que puede\n",
    "    incluir el individuo en el momento de su creación. Sin emabrgo, como resultado\n",
    "    de cruces y mutaciones, los individuos creados en posteriores generaciones\n",
    "    pueden exceder este valor. Con `n_max_estricto` = ``True`` se fuerza a que\n",
    "    el número de predictores incluidos nunca supere `n_max`. Para lograrlo,\n",
    "    tras el proceso de cruce y mutación, si el número de ``True`` en la secuencia\n",
    "    del individuo supera `n_max`, se cambian a ``False`` tantas posiciones\n",
    "    (seleccionadas aleatoriamente) hasta que cumplan la condición de `n_max`.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Ejemplo creación individuo.\n",
    "\n",
    "    >>> individuo = Individuo(\n",
    "                        n_variables = 5,\n",
    "                        n_max = 4,\n",
    "                        n_min = 1,\n",
    "                        n_max_estricto = False,\n",
    "                        verbose = True\n",
    "                    )\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_variables, n_max=None, n_min=1, n_max_estricto=False,\n",
    "                 verbose=False):\n",
    "\n",
    "        # Número de variables del individuo\n",
    "        self.n_variables = n_variables\n",
    "        # Número máximo de predictores incluidos\n",
    "        self.n_max = n_max\n",
    "        self.n_max_estricto = n_max_estricto\n",
    "        # Número mínimo de predictores incluidos\n",
    "        self.n_min = n_min\n",
    "        # Secuencia del individuo\n",
    "        self.secuencia = None\n",
    "        # Índices de las columans empleadas como predictores\n",
    "        self.predictores = None\n",
    "        # Número predictores incluidos\n",
    "        self.n_predictores_incluidos = None\n",
    "        # Fitness del individuo\n",
    "        self.fitness = None\n",
    "        # Métrica\n",
    "        self.metrica = None\n",
    "        # Valor de la métrica con la que se calcula el fitness\n",
    "        self.valor_metrica = None\n",
    "        # Modelo empleado para evaluar el individuo\n",
    "        self.modelo = None\n",
    "        # Tipo de modelo: regresion o clasificación\n",
    "        self.tipo_modelo = None\n",
    "\n",
    "        # COMPROBACIONES INICIALES: EXCEPTIONS Y WARNINGS\n",
    "        # ----------------------------------------------------------------------\n",
    "        if self.n_max is not None and self.n_max > self.n_variables:\n",
    "            raise Exception(\n",
    "                \"El valor de n_max no puede ser superior al de n_variables\"\n",
    "            )\n",
    "\n",
    "        # COMPROBACIONES INICIALES: ACCIONES\n",
    "        # ----------------------------------------------------------------------\n",
    "        # Si no se especifica n_max, se emplea por defecto el valor de \n",
    "        # n_variables.\n",
    "        if self.n_max is None:\n",
    "            self.n_max = n_variables\n",
    "\n",
    "        # CREACIÓN DE LA SECUENCIA BOLEANA QUE DEFINE AL INDIVIDUO\n",
    "        # ----------------------------------------------------------------------\n",
    "        # Se crea un array boleano que representa el individuo.\n",
    "        self.secuencia =  np.full(\n",
    "                            shape      = self.n_variables,\n",
    "                            fill_value = False,\n",
    "                            dtype      = \"bool\"\n",
    "                          )\n",
    "        # Se selecciona (con igual probabilidad) el número de valores TRUE \n",
    "        # que puede tener el individuo, dentro del rango acotado por n_min y\n",
    "        # n_max.\n",
    "        n_true = np.random.randint(\n",
    "                    low  = self.n_min,\n",
    "                    high = self.n_max + 1,\n",
    "                    size = None)\n",
    "\n",
    "        # Se sustituyen n_true posiciones aleatorias por valores True.\n",
    "        posiciones_true = np.random.choice(\n",
    "                            a       = self.n_variables,\n",
    "                            size    = n_true,\n",
    "                            replace = False\n",
    "                          )\n",
    "        self.secuencia[posiciones_true] = True\n",
    "        self.n_predictores_incluidos    = sum(self.secuencia)\n",
    "\n",
    "        # Se identifican los indices de las posiciones True\n",
    "        self.predictores = np.arange(self.n_variables)[self.secuencia]\n",
    "\n",
    "        # INFORMACIÓN DEL PROCESO (VERBOSE)\n",
    "        # ----------------------------------------------------------------------\n",
    "        if verbose:\n",
    "            print(\"----------------------\")\n",
    "            print(\"Nuevo individuo creado\")\n",
    "            print(\"----------------------\")\n",
    "            print(\"Secuencia: \" + str(self.secuencia))\n",
    "            print(\"Índice predictores: \" + str(self.predictores))\n",
    "            print(\"Número de predictores incluidos: \" \\\n",
    "                  + str(self.n_predictores_incluidos))\n",
    "            print(\"Fitness: \" + str(self.fitness))\n",
    "            print(\"Métrica: \"+ str(self.metrica))\n",
    "            print(\"Valor métrica: \"+ str(self.valor_metrica))\n",
    "            print(\"Modelo empleado para calcular fitness: \" \\\n",
    "                  + str(self.modelo))\n",
    "            print(\"Tipo de modelo: \" + str(self.tipo_modelo))\n",
    "            print(\"\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Información que se muestra cuando se imprime un objeto Individuo.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        texto = \"Individuo\" \\\n",
    "                + \"\\n\" \\\n",
    "                + \"---------\" \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Secuencia: \" + str(self.secuencia) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Índice predictores: \" + str(self.predictores) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Número de predictores incluidos: \" \\\n",
    "                + str(self.n_predictores_incluidos) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Fitness: \" + str(self.fitness) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Métrica: \" + str(self.metrica) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Valor métrica: \" + str(self.valor_metrica) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Modelo empleado para calcular fitness: \" + str(self.modelo) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Tipo de modelo: \" + str(self.tipo_modelo) \\\n",
    "                + \"\\n\"\n",
    "\n",
    "        return(texto)\n",
    "\n",
    "    def evaluar_individuo(self, x, y, tipo_modelo, modelo, metrica, cv=5,\n",
    "                          test_size=0.2, cv_seed=123, nivel_referencia = None,\n",
    "                          rf_n_estimators = 100, verbose = False):\n",
    "        \"\"\"Este método calcula el fitness del individuo a partir del valor de la\n",
    "        métrica obtenida por `ShuffleSplit` al ajustar un modelo empleando los\n",
    "        predictores que indica su secuencia.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : `numpy array 2d`\n",
    "            matriz con el valor de los predictores.\n",
    "\n",
    "        y : `numpy array 1d`\n",
    "            numpy array con la variable respuesta.\n",
    "\n",
    "        cv : `int`\n",
    "            número de repeticiones para la validación. EL método empleado es \n",
    "            `ShuffleSplit` de scikit-learn, que es distinto a `Kfold`.\n",
    "            (default 5)\n",
    "\n",
    "        test_size : `float`\n",
    "            porcentaje de observaciones empleadas como test en cada validación.\n",
    "            (default 0.2)\n",
    "\n",
    "        cv_seed : `int`\n",
    "            semilla empleada para el reparto aleatorio en la validación.\n",
    "            (default 123)\n",
    "\n",
    "        modelo: {lineal, logistico, randomforest}\n",
    "            modelo empleado para evaluar al individuo.\n",
    "\n",
    "        tipo_modelo: {regresion, clasificacion}\n",
    "            tipo de problema (regresión o clasificación).\n",
    "        \n",
    "        metrica: {\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"f1\",\n",
    "                 \"accuracy\"}\n",
    "            métrica empleada para calcular el fitness del individuo.\n",
    "\n",
    "        nivel_referencia : `str`\n",
    "            valor de la variable respuesta considerado como referencia.\n",
    "            Necesario cuando la métrica es f1 o kappa. (default ``None``)\n",
    "            \n",
    "        rf_n_estimators : `int`\n",
    "            número de árboles en los modelos random forest. (default 100)\n",
    "\n",
    "        verbose : `bool`, optional\n",
    "            mostrar información del proceso por pantalla. (default ``False``)\n",
    "          \n",
    "        Raises\n",
    "        ------\n",
    "        \n",
    "        raise Exception\n",
    "            si el argumento `metrica` es distinto de \"neg_mean_squared_error\",\n",
    "            \"neg_mean_absolute_error\", \"f1\" o \"accuracy\".\n",
    "\n",
    "        raise Exception\n",
    "            si el argumento `metrica` es distinto de \"neg_mean_squared_error\" o\n",
    "            \"neg_mean_absolute_error\" y `tipo_modelo` es \"regresion\".\n",
    "\n",
    "        raise Exception\n",
    "            si el argumento `metrica` es distinto de \"accuracy\" o \"f1\" y\n",
    "            `tipo_modelo` es \"clasificacion\".\n",
    "\n",
    "        raise Exception\n",
    "            si el número de columnas de x es distinto al argumento `n_variables`.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        # Regresión:\n",
    "        >>> boston = datasets.load_boston(return_X_y= True)\n",
    "        >>> individuo = Individuo(\n",
    "                            n_variables = 13,\n",
    "                            n_max       = 3,\n",
    "                            n_min       = 1,\n",
    "                            n_max_restricto = False,\n",
    "                            verbose     = True\n",
    "                        )\n",
    "        >>> individuo.evaluar_individuo(\n",
    "                x  = boston[0],\n",
    "                y  = boston[1],\n",
    "                cv = 5,\n",
    "                test_size = 0.2,\n",
    "                tipo_modelo = \"regresion\",\n",
    "                modelo      = \"randomforest\",\n",
    "                metrica     = \"neg_mean_squared_error\",\n",
    "                verbose     = True\n",
    "            )\n",
    "        >>> individuo\n",
    "\n",
    "        # Clasificación\n",
    "        >>> iris = datasets.load_iris()\n",
    "        >>> individuo = Individuo(\n",
    "                            n_variables = 4,\n",
    "                            n_max       = 3,\n",
    "                            n_min       = 1,\n",
    "                            n_max_restricto = False,\n",
    "                            verbose     = True\n",
    "                        )\n",
    "        >>> individuo.evaluar_individuo(\n",
    "                x  = iris.data,\n",
    "                y  = iris.target,\n",
    "                cv = 5,\n",
    "                test_size = 0.2,\n",
    "                tipo_modelo = \"clasificacion\",\n",
    "                modelo      = \"randomforest\",\n",
    "                metrica     = \"accuracy\",\n",
    "                verbose     = True\n",
    "            )\n",
    "        >>> individuo\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # COMPROBACIONES INICIALES: EXCEPTIONS Y WARNINGS\n",
    "        # ----------------------------------------------------------------------\n",
    "        if metrica not in [\"neg_mean_squared_error\",\n",
    "                           \"neg_mean_absolute_error\",\n",
    "                           \"f1\", \"accuracy\"]:\n",
    "            raise Exception(\n",
    "                \"La métrica debe ser: neg_mean_squared_error, \" \\\n",
    "                 + \"neg_mean_absolute_error, f1 o accuracy\"\n",
    "            )\n",
    "        \n",
    "        if self.n_variables != x.shape[1]:\n",
    "            raise Exception(\n",
    "                \"n_variables debe ser igual al número de columnas de x.\"\n",
    "            )\n",
    "\n",
    "        if not isinstance(x, np.ndarray) or x.ndim != 2:\n",
    "            raise Exception(\n",
    "                \"x debe ser un array numpy de dos dimensiones (una matriz).\"\n",
    "            )\n",
    "        if not isinstance(y, np.ndarray) or y.ndim != 1:\n",
    "            raise Exception(\n",
    "                \"y debe ser un array numpy de 1 dimensiones.\"\n",
    "            )\n",
    "\n",
    "        if modelo == \"lineal\":\n",
    "            if metrica not in [\"neg_mean_squared_error\", \"neg_mean_absolute_error\"]:\n",
    "                raise Exception(\n",
    "                \"Para el modelo lineal, la metrica debe ser: \" \\\n",
    "                + \"neg_mean_squared_error, neg_mean_absolute_error.\"\n",
    "                )\n",
    "            if tipo_modelo != \"regresion\":\n",
    "                raise Exception(\n",
    "                \"El modelo lineal solo puede aplicarse a problemas de regresión.\"\n",
    "                )\n",
    "\n",
    "        if modelo == \"glm\":\n",
    "            if metrica not in [\"f1\", \"accuracy\"]:\n",
    "                raise Exception(\n",
    "                \"Para el modelo glm la métrica de evaluación debe ser f1,\" \\\n",
    "                + \"o accuracy.\"\n",
    "                )\n",
    "            if tipo_modelo != \"clasificacion\":\n",
    "                raise Exception(\n",
    "                \"El modelo glm solo puede aplicarse a problemas de clasificación.\"\n",
    "                )\n",
    "            if len(np.unique(y)) != 1:\n",
    "                raise Exception(\n",
    "                \"El modelo glm solo puede aplicarse a problemas de clasificación\" \\\n",
    "                + \"binaria.\"\n",
    "                )\n",
    "\n",
    "        # Se identifica el modelo y el tipo\n",
    "        self.modelo = modelo\n",
    "        self.tipo_modelo = tipo_modelo\n",
    "        self.metrica = metrica\n",
    "\n",
    "        # Se selecciona la clase de scikit-learn correspondiente al modelo\n",
    "        if self.modelo == \"lineal\":\n",
    "            mod = LinearRegression()\n",
    "        elif self.modelo == \"glm\":\n",
    "            mod = LogisticRegression()\n",
    "        elif self.modelo == \"randomforest\" and self.tipo_modelo == \"regresion\":\n",
    "            mod = RandomForestRegressor(\n",
    "                    n_estimators = rf_n_estimators,\n",
    "                    random_state = 1234,\n",
    "                    bootstrap    = False\n",
    "                  )      \n",
    "        elif self.modelo == \"randomforest\" and self.tipo_modelo == \"clasificacion\":\n",
    "            mod = RandomForestClassifier(\n",
    "                    n_estimators = rf_n_estimators,\n",
    "                    random_state = 1234,\n",
    "                    bootstrap    = False\n",
    "                  ) \n",
    "        \n",
    "        cv = ShuffleSplit(\n",
    "                n_splits     = cv,\n",
    "                test_size    = test_size,\n",
    "                random_state = cv_seed\n",
    "             )\n",
    "\n",
    "        metrica_cv = cross_val_score(\n",
    "                        estimator = mod,\n",
    "                        X         = x[:,self.predictores],\n",
    "                        y         = y,\n",
    "                        cv        = cv,\n",
    "                        scoring   = metrica,\n",
    "                        n_jobs    = 1\n",
    "                     )\n",
    "\n",
    "        self.valor_metrica = metrica_cv.mean()\n",
    "        self.fitness       = metrica_cv.mean()\n",
    "\n",
    "        # INFORMACIÓN DEL PROCESO (VERBOSE)\n",
    "        # ----------------------------------------------------------------------\n",
    "        if verbose:\n",
    "            print(\"El individuo ha sido evaluado\")\n",
    "            print(\"-----------------------------\")\n",
    "            print(\"Métrica: \" + str(self.metrica))\n",
    "            print(\"Valor métrica: \" + str(self.valor_metrica))\n",
    "            print(\"Fitness: \" + str(self.fitness))\n",
    "            print(\"\")\n",
    "\n",
    "    def mutar(self, prob_mut=0.01, verbose=False):\n",
    "        \"\"\"\n",
    "        Este método somete al individuo a un proceso de mutación en el que, cada\n",
    "        una de sus posiciones, puede verse modificada con una probabilidad \n",
    "        `prob_mut`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        prob_mut : `float`, optional\n",
    "            probabilidad que tiene cada posición del individuo de mutar.\n",
    "            (default 0.01)\n",
    "    \n",
    "        verbose : `bool`, optional\n",
    "            mostrar información del proceso por pantalla. (default ``False``)\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        raise Exception\n",
    "            si el argumento `prob_mut` es está fuera del rango [0,1].\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        Ejemplo mutar individuo.\n",
    "\n",
    "        >>> boston = datasets.load_boston(return_X_y= True)\n",
    "        >>> individuo = Individuo(\n",
    "                            n_variables = 13,\n",
    "                            n_max       = 3,\n",
    "                            n_min       = 1,\n",
    "                            verbose     = True\n",
    "                        )\n",
    "\n",
    "        >>> individuo.mutar(\n",
    "                prob_mut = 0.5,\n",
    "                verbose  = True\n",
    "            )\n",
    "        \"\"\"\n",
    "\n",
    "        # COMPROBACIONES INICIALES: EXCEPTIONS Y WARNINGS\n",
    "        # ----------------------------------------------------------------------\n",
    "        if prob_mut < 0 or prob_mut > 1:\n",
    "            raise Exception(\n",
    "                \"El argumento prob_mut debe de estar en el rango [0,1].\"\n",
    "            )\n",
    "\n",
    "        # SELECCIÓN PROBABILISTA DE POSICIONES (VARIABLES) QUE MUTAN\n",
    "        #-----------------------------------------------------------------------\n",
    "        posiciones_mutadas = np.random.uniform(\n",
    "                                low=0,\n",
    "                                high=1,\n",
    "                                size=self.n_variables\n",
    "                             )\n",
    "        posiciones_mutadas = posiciones_mutadas < prob_mut\n",
    "\n",
    "        # Se modifican las posiciones de la secuencia del individuo que coinciden \n",
    "        # con las posiciones_mutadas.\n",
    "        self.secuencia[posiciones_mutadas] = \\\n",
    "                np.logical_not(self.secuencia[posiciones_mutadas])\n",
    "        \n",
    "        # Todo individuo debe tener como mínimo 1 predictor, si como consecuencia de la \n",
    "        # mutación, ningun valor de la secuencia es True, se selecciona una posición\n",
    "        # aleatoria y se sobreescribe con True.\n",
    "        \n",
    "        if sum(self.secuencia == True) == 0:\n",
    "            indice = np.random.choice(\n",
    "                        a       = np.arange(self.n_variables),\n",
    "                        size    = 1, \n",
    "                        replace = False\n",
    "                      )\n",
    "            self.secuencia[indice] = True\n",
    "\n",
    "        # Se actualiza el indice de los predictores incluidos.\n",
    "        self.predictores = np.arange(self.n_variables)[self.secuencia]\n",
    "        # Se actualiza el número total de predictores incluidos.\n",
    "        self.n_predictores_incluidos = sum(self.secuencia)\n",
    "        \n",
    "        # INFORMACIÓN DEL PROCESO (VERBOSE)\n",
    "        # ----------------------------------------------------------------------\n",
    "        if verbose:\n",
    "            print(\"El individuo ha sido mutado\")\n",
    "            print(\"---------------------------\")\n",
    "            print(\"Total mutaciones: \" + str(np.sum(posiciones_mutadas)))\n",
    "            print(\"Secuencia: \" + str(self.secuencia))\n",
    "            print(\"Índice predictores: \" + str(self.predictores))\n",
    "            print(\"\")  \n",
    "\n",
    "    def forzar_n_max(self):\n",
    "        \"\"\"\n",
    "        Este método modifica la secuencia del individuo de forma que, como\n",
    "        máximo contenga n_max valores True.\n",
    "        \n",
    "        Examples\n",
    "        --------\n",
    "        Ejemplo mutar individuo.\n",
    "\n",
    "        >>> boston = datasets.load_boston(return_X_y= True)\n",
    "        >>> individuo = Individuo(\n",
    "                            n_variables = 13,\n",
    "                            n_max       = 3,\n",
    "                            n_min       = 1,\n",
    "                            verbose     = True\n",
    "                        )\n",
    "\n",
    "        >>> individuo.mutar(\n",
    "                prob_mut = 0.5,\n",
    "                verbose  = True\n",
    "            )\n",
    "\n",
    "        >>> individuo.forzar_n_max()\n",
    "        >>> individuo\n",
    "\n",
    "        \"\"\"\n",
    "        #Se identifica si el número de True es la secuencia supera a n_max.\n",
    "        n_exceso = sum(self.secuencia) - self.n_max\n",
    "\n",
    "        if n_exceso > 0:\n",
    "            # Se seleccionan aleatoriamente n_max posiciones con valor True en \n",
    "            # la secuencia del individuo.\n",
    "            indices = np.random.choice(\n",
    "                        a       = np.flatnonzero(self.secuencia == True),\n",
    "                        size    = n_exceso, \n",
    "                        replace = False\n",
    "                      )\n",
    "            self.secuencia[indices] = \\\n",
    "                np.logical_not(self.secuencia[indices])\n",
    "\n",
    "            # Se actualiza el indice de los predictores incluidos.\n",
    "            self.predictores = np.arange(self.n_variables)[self.secuencia]\n",
    "            # Se actualiza el número total de predictores incluidos.\n",
    "            self.n_predictores_incluidos = sum(self.secuencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase Población"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "################################################################################\n",
    "#                               CLASE POBLACIÓN                                #\n",
    "################################################################################\n",
    "\n",
    "class Poblacion:\n",
    "    \"\"\"\n",
    "    Esta clase crea una población de n individuos.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_individuos :`int`\n",
    "        número de individuos de la población.\n",
    "\n",
    "    n_variables : `int`\n",
    "        longitud del array que define a los individuos. Debe coincidir con el\n",
    "        número total de predictores disponibles.\n",
    "\n",
    "    n_max: `int`, optional\n",
    "        número máximo de predictores que pueden contener inicialmente los\n",
    "        individuos. Si no se indica un valor (default ``None``) se emplea\n",
    "        `n_variables`.\n",
    "\n",
    "    n_min: `int`, optional\n",
    "        número mínimo de predictores que pueden contener los individuos.\n",
    "        (default 1)\n",
    "\n",
    "    n_max_estricto: `bool`, optional\n",
    "        forzar a que ningún individuo a lo largo del proceso pueda contener más\n",
    "        de `n_max` predictores. (default ``False``) Ver notas para más info.\n",
    "\n",
    "    verbose : `bool`, optional\n",
    "        mostrar información del proceso por pantalla. (default ``False``)\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    individuos : `list`\n",
    "        lista con todos los individuos de la población en su estado actual.\n",
    "    \n",
    "    n_individuos :`int`\n",
    "        número de individuos de la población.\n",
    "\n",
    "    n_variables : `int`\n",
    "        longitud del array que define a los individuos. Debe coincidir con el\n",
    "        número total de predictores disponibles.\n",
    "\n",
    "    n_max: `int`, optional\n",
    "        número máximo de predictores que pueden contener inicialmente los\n",
    "        individuos. Si no se indica un valor (default ``None``) se emplea\n",
    "        `n_variables`.\n",
    "\n",
    "    n_min: `int`, optional\n",
    "        número mínimo de predictores que pueden contener los individuos.\n",
    "        (default 1)\n",
    "\n",
    "    n_max_estricto: `bool`, optional\n",
    "        forzar a que ningún individuo a lo largo del proceso pueda contener más\n",
    "        de `n_max` predictores. (default ``False``) Ver notas para más info.\n",
    "\n",
    "    metrica: {\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"f1\",\n",
    "              \"accuracy\"}\n",
    "        métrica empleada para calcular el fitness del individuo.\n",
    "\n",
    "    modelo: {lineal, logistico, randomforest}\n",
    "            modelo empleado para evaluar al individuo.\n",
    "\n",
    "    mejor_individuo : `object individuo`\n",
    "        mejor individuo de la población en su estado actual.\n",
    "\n",
    "    mejor_fitness : `float`\n",
    "        fitness del mejor individuo de la población en su estado actual.\n",
    "        \n",
    "    mejor_valor_metrica : `float`\n",
    "        valor de la métrica del mejor individuo de la población en su\n",
    "        estado actual.\n",
    "\n",
    "    mejor_secuencia : `numpy.ndarray`\n",
    "        secuencia del mejor individuo de la población en su estado actual.\n",
    "\n",
    "    mejor_predictores : `numpy.ndarray`\n",
    "        índice de las columnas que incluye como predictores el mejor individuo\n",
    "        de la población\n",
    "\n",
    "    historico_individuos : `list`\n",
    "        lista con la información de todos los individuos en cada una de las \n",
    "        generaciones que ha tenido la población.\n",
    "\n",
    "    historico_mejor_secuencia : `list`\n",
    "        lista con valor de las secuencias del mejor individuo en cada una de las \n",
    "        generaciones que ha tenido la población.\n",
    "\n",
    "    historico_mejor_predictores : `list`\n",
    "        lista con los índice de las columnas que incluye como predictores el \n",
    "        mejor individuo en cada una de las generaciones que ha tenido la\n",
    "        población.\n",
    "\n",
    "    historico_mejor_fitness : `list`\n",
    "        lista con el mejor fitness en cada una de las generaciones que ha tenido\n",
    "        la población.\n",
    "\n",
    "    historico_mejor_valor_metrica : `list`\n",
    "        lista con valor de la métrica del mejor individuo en cada una\n",
    "        de las generaciones que ha tenido la población.\n",
    "\n",
    "    diferencia_abs : `list`\n",
    "        diferencia absoluta entre el mejor fitness de generaciones consecutivas.\n",
    "\n",
    "    resultados_df : `pandas.core.frame.DataFrame`\n",
    "        dataframe con la información del mejor fitness y secuencia encontrada\n",
    "        en cada generación, así como la diferencia respecto a la generación\n",
    "        anterior.\n",
    "\n",
    "    fitness_optimo : `float`\n",
    "        mejor fitness encontrado tras el proceso de optimización.\n",
    "\n",
    "    valor_metrica_optimo : `float`\n",
    "        mejor valor de la métrica encontrado tras el proceso de optimización.\n",
    "\n",
    "    secuencia_optima : `numpy.narray`\n",
    "        secuencia con la que se ha conseguido el mejor fitness tras el proceso\n",
    "        de optimización.\n",
    "\n",
    "    predictores_optimos : `numpy.narray`\n",
    "        índice de las columnas que incluye como predictores el individuo con\n",
    "        mejor fitness tras el proceso de optimización.\n",
    "\n",
    "    evaluada : `bool`\n",
    "        si la población ha sido evaluada.\n",
    "\n",
    "    optimizada : `bool`\n",
    "        si la población ha sido optimizada.\n",
    "\n",
    "    iter_optimizacion : `int`\n",
    "        número de iteraciones de optimización (generaciones).\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    Ejemplo crear población\n",
    "\n",
    "    >>> poblacion = Poblacion(\n",
    "                        n_individuos = 5,\n",
    "                        n_variables  = 10,\n",
    "                        n_max        = 5,\n",
    "                        n_min        = 1,\n",
    "                        verbose      = True\n",
    "                    )\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_individuos, n_variables, n_max=None,\n",
    "                 n_min=1, n_max_estricto=False, verbose=False):\n",
    "\n",
    "        # Número de individuos de la población\n",
    "        self.n_individuos = n_individuos\n",
    "        # Número de variables de cada individuo\n",
    "        self.n_variables = n_variables\n",
    "        # Número máximo de predictores incluidos\n",
    "        self.n_max = n_max\n",
    "        self.n_max_estricto = n_max_estricto\n",
    "        # Número mínimo de predictores incluidos\n",
    "        self.n_min = n_min\n",
    "        # Métrica utilizada en la evaluación de los individuos\n",
    "        self.metrica = None\n",
    "        # Modelo empleado para evaluar el individuo\n",
    "        self.modelo = None\n",
    "        # Lista de los individuos de la población\n",
    "        self.individuos = []\n",
    "        # Etiqueta para saber si la población ha sido evaluada\n",
    "        self.evaluada = False\n",
    "        # Etiqueta para saber si la población ha sido optimizada\n",
    "        self.optimizada = False\n",
    "        # Número de iteraciones de optimización llevadas a cabo\n",
    "        self.iter_optimizacion = None\n",
    "        # Mejor individuo de la población\n",
    "        self.mejor_individuo = None\n",
    "        # Fitness del mejor individuo de la población (el de mayor fitness)\n",
    "        self.mejor_fitness = None\n",
    "        # Valor de la métrica del mejor individuo de la población\n",
    "        self.mejor_valor_metrica = None\n",
    "        # Secuencia del mejor individuo de la población\n",
    "        self.mejor_secuencia = None\n",
    "        # Índice de las columnas que incluye como predictores el mejor individuo\n",
    "        # de la población\n",
    "        self.mejor_predictores = None\n",
    "        # Información de todas los individuos de la población en cada generación\n",
    "        self.historico_individuos = []\n",
    "        # Secuencia del mejor individuo en cada generación\n",
    "        self.historico_mejor_secuencia = []\n",
    "        # Índice de las columnas que incluye como predictores el mejor individuo\n",
    "        # en cada generación.\n",
    "        self.historico_mejor_predictores = []\n",
    "        # Fitness del mejor individuo en cada generación\n",
    "        self.historico_mejor_fitness = []\n",
    "        # Valor de la métrica del mejor individuo en cada generación\n",
    "        self.historico_mejor_valor_metrica = []\n",
    "        # Diferencia absoluta entre el mejor fitness de generaciones consecutivas\n",
    "        self.diferencia_abs = []\n",
    "        # data.frame con la información del mejor fitness y valor de variables\n",
    "        # encontrado en cada generación, así como la diferencia respecto a la \n",
    "        # generación anterior.\n",
    "        self.resultados_df = None\n",
    "        # Fitness del mejor individuo de todas las generaciones\n",
    "        self.fitness_optimo = None\n",
    "        # Secuencia del mejor individuo de todas las generaciones\n",
    "        self.secuencia_optima = None\n",
    "        # Índice de las columnas incluidas como predictores en el mejor individuo\n",
    "        # de todas las generaciones.\n",
    "        self.predictores_optimos = None\n",
    "        # Valor de función objetivo del mejor individuo de todas las generaciones\n",
    "        self.valor_metrica_optimo = None\n",
    "\n",
    "        # COMPROBACIONES INICIALES: EXCEPTIONS Y WARNINGS\n",
    "        # ----------------------------------------------------------------------\n",
    "        if self.n_max is not None and self.n_max > self.n_variables:\n",
    "            raise Exception(\n",
    "                \"El valor de n_max no puede ser superior al de n_variables\"\n",
    "            )\n",
    "\n",
    "        # COMPROBACIONES INICIALES: ACCIONES\n",
    "        # ----------------------------------------------------------------------\n",
    "        # Si no se especifica n_max, se emplea por defecto el valor de \n",
    "        # n_variables.\n",
    "        if self.n_max is None:\n",
    "            self.n_max = n_variables\n",
    "\n",
    "        # SE CREAN LOS INDIVIDUOS DE LA POBLACIÓN Y SE ALMACENAN\n",
    "        # ----------------------------------------------------------------------\n",
    "        for i in np.arange(n_individuos):\n",
    "            individuo_i = Individuo(\n",
    "                            n_variables = self.n_variables,\n",
    "                            n_max = self.n_max,\n",
    "                            n_min = self.n_min,\n",
    "                            verbose = verbose\n",
    "                          )\n",
    "            self.individuos.append(individuo_i)\n",
    "\n",
    "        # INFORMACIÓN DEL PROCESO (VERBOSE)\n",
    "        # ----------------------------------------------------------------------\n",
    "        if verbose:\n",
    "            print(\"----------------\")\n",
    "            print(\"Población creada\")\n",
    "            print(\"----------------\")\n",
    "            print(\"Número de individuos: \" + str(self.n_individuos))\n",
    "            print(\"Número máximo de predictores iniciales: \" + str(self.n_max))\n",
    "            print(\"Número mínimo de predictores iniciales: \" + str(self.n_min))\n",
    "            print(\"\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Información que se muestra cuando se imprime un objeto población.\n",
    "        \"\"\"\n",
    "\n",
    "        texto = \"============================\" \\\n",
    "                + \"\\n\" \\\n",
    "                + \"         Población\" \\\n",
    "                + \"\\n\" \\\n",
    "                + \"============================\" \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Número de individuos: \" + str(self.n_individuos) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Número máximo de predictores iniciales: \" + str(self.n_max) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Número mínimo de predictores iniciales: \" + str(self.n_min) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Evaluada: \" + str(self.evaluada) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Optimizada: \" + str(self.optimizada) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Métrica de evaluación: \" + str(self.metrica) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Modelo: \" + str(self.modelo) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Iteraciones optimización (generaciones): \" \\\n",
    "                    + str(self.iter_optimizacion) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Información del mejor individuo:\" \\\n",
    "                + \"\\n\" \\\n",
    "                + \"--------------------------------\" \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Secuencia: \" + str(self.mejor_secuencia) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Índice predictores: \" + str(self.mejor_predictores) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Fitness: \" + str(self.mejor_fitness) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Resultados tras optimizar:\" \\\n",
    "                + \"\\n\" \\\n",
    "                + \"--------------------------\" \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Secuencia óptima: \" + str(self.secuencia_optima) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Índice predictores óptimos: \" + str(self.predictores_optimos) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Valor óptimo métrica: \" + str(self.valor_metrica_optimo) \\\n",
    "                + \"\\n\" \\\n",
    "                + \"Fitness óptimo: \" + str(self.fitness_optimo)\n",
    "                \n",
    "        return(texto)\n",
    "\n",
    "    def mostrar_individuos(self, n=None):\n",
    "        \"\"\"\n",
    "        Este método muestra la información de cada uno de los n primeros \n",
    "        individuos de la población.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n : `int`\n",
    "            número de individuos que se muestran. Si no se indica el valor\n",
    "            (por defecto ``None``), se muestran todos. Si el valor es mayor\n",
    "            que `self.n_individuos` se muestran todos.\n",
    "        \n",
    "        Examples\n",
    "        --------\n",
    "        >>> poblacion = Poblacion(\n",
    "                            n_individuos = 5,\n",
    "                            n_variables  = 10,\n",
    "                            n_max        = 5,\n",
    "                            n_min        = 1,\n",
    "                            verbose      = False\n",
    "                        )\n",
    "        >>> poblacion.mostrar_individuos(n = 5)\n",
    "        \"\"\"\n",
    "\n",
    "        if n is None:\n",
    "            n = self.n_individuos\n",
    "        elif n > self.n_individuos:\n",
    "            n = self.n_individuos\n",
    "\n",
    "        for i in np.arange(n):\n",
    "            print(self.individuos[i])\n",
    "            \n",
    "        return(None)\n",
    "\n",
    "\n",
    "    def evaluar_poblacion(self, x, y, tipo_modelo, modelo, metrica, cv=5,\n",
    "                          test_size=0.2, cv_seed=123, forzar_evaluacion = True,\n",
    "                          rf_n_estimators=100, nivel_referencia = None, verbose = False):\n",
    "        \"\"\"\n",
    "        Este método calcula el fitness de todos los individuos de la población,\n",
    "        actualiza sus valores e identifica el mejor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : `numpy array 2d`\n",
    "            matriz con el valor de los predictores.\n",
    "\n",
    "        y : `numpy array 1d`\n",
    "            numpy array con la variable respuesta\n",
    "\n",
    "        cv : `int`\n",
    "            número de repeticiones para la validación. EL método empleado es \n",
    "            `ShuffleSplit` de la libreria Scikit-learn, que es distinto a `Kfold`.\n",
    "            (default 5)\n",
    "\n",
    "        test_size : `float`\n",
    "            porcentaje de observaciones empleadas como test en cada validación.\n",
    "            (default 0.2)\n",
    "\n",
    "        cv_seed : `int`\n",
    "            semilla empleada para el reparto aleatorio. (default 123)\n",
    "\n",
    "        modelo: {lineal, logistico, randomforest}\n",
    "            modelo empleado para evaluar al individuo.\n",
    "\n",
    "        tipo_modelo: {regresion, clasificacion}\n",
    "            tipo de problema (regresión o clasificación)\n",
    "        \n",
    "        metrica: {\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"f1\",\n",
    "                 \"accuracy\"}\n",
    "            métrica empleada para calcular el fitness del individuo.\n",
    "\n",
    "        forzar_evaluacion = `bool`\n",
    "            si es ``False`` los individuos que ya hayan sido evaluados\n",
    "            anteriormente no se evaluan de nuevo. (default ``False``).\n",
    "\n",
    "        nivel_referencia : `str`\n",
    "            valor de la variable respuesta considerado como referencia.\n",
    "            Necesario cuando la métrica es f1 o kappa.\n",
    "            \n",
    "        rf_n_estimators : `int`\n",
    "            número de árboles en los modelos random forest. (default 100)\n",
    "\n",
    "        verbose : `bool`, optional\n",
    "            mostrar información del proceso por pantalla. (default ``False``).\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        \n",
    "        raise Exception\n",
    "            si `n_max` es distinto de ``None`` y mayor que `n_variables`.\n",
    "\n",
    "                            \n",
    "        raise Exception\n",
    "            si el argumento `metrica` es distinto de \"neg_mean_squared_error\",\n",
    "            \"neg_mean_absolute_error\", \"f1\" o \"accuracy\".\n",
    "\n",
    "        raise Exception\n",
    "            si el argumento `metrica` es distinto de \"neg_mean_squared_error\" o\n",
    "            \"neg_mean_absolute_error\" y `tipo_modelo` es \"regresión\".\n",
    "\n",
    "        raise Exception\n",
    "            si el argumento `metrica` es distinto de accuracy\" o \"f1\" y\n",
    "            `tipo_modelo` es clasificacion.\n",
    "\n",
    "        raise Exception\n",
    "            si el número de columnas de x es distinto al argumento `n_variables`.\n",
    "        \n",
    "        Examples\n",
    "        --------\n",
    "        Ejemplo evaluar población regresión:\n",
    "        \n",
    "        >>> boston = datasets.load_boston(return_X_y= True)\n",
    "        >>> poblacion = Poblacion(\n",
    "                            n_individuos = 5,\n",
    "                            n_variables  = 13,\n",
    "                            n_max        = 8,\n",
    "                            n_min        = 1,\n",
    "                            n_max_estricto = False,\n",
    "                            verbose      = False\n",
    "                        )\n",
    "        >>> poblacion               \n",
    "        >>> poblacion.evaluar_poblacion(\n",
    "                x  = boston[0],\n",
    "                y  = boston[1],\n",
    "                cv = 5,\n",
    "                test_size   = 0.2,\n",
    "                tipo_modelo = \"regresion\",\n",
    "                modelo      = \"randomforest\",\n",
    "                metrica     = \"neg_mean_squared_error\",\n",
    "                forzar_evaluacion = True,\n",
    "                rf_n_estimators = 150,\n",
    "                verbose     = True\n",
    "            )\n",
    "        >>> poblacion\n",
    "\n",
    "        Ejemplo evaluar población clasificación:\n",
    "\n",
    "        >>> iris = datasets.load_iris()\n",
    "        >>> poblacion = Poblacion(\n",
    "                            n_individuos = 5,\n",
    "                            n_variables  = 4,\n",
    "                            n_max        = 3,\n",
    "                            n_min        = 1,\n",
    "                            n_max_estricto = False,\n",
    "                            verbose      = True\n",
    "                        )\n",
    "\n",
    "        >>> poblacion               \n",
    "        >>> poblacion.evaluar_poblacion(\n",
    "                x  = iris.data,\n",
    "                y  = iris.target,\n",
    "                cv = 5,\n",
    "                tipo_modelo = \"clasificacion\",\n",
    "                modelo      = \"randomforest\",\n",
    "                metrica     = \"accuracy\",\n",
    "                forzar_evaluacion = True,\n",
    "                rf_n_estimators = 150,\n",
    "                verbose     = True\n",
    "            )\n",
    "        >>> poblacion\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # COMPROBACIONES INICIALES: EXCEPTIONS Y WARNINGS\n",
    "        # ----------------------------------------------------------------------\n",
    "        if metrica not in [\"neg_mean_squared_error\",\n",
    "                           \"neg_mean_absolute_error\",\n",
    "                           \"f1\", \"accuracy\"]:\n",
    "            raise Exception(\n",
    "                \"La métrica debe ser: neg_mean_squared_error, \" \\\n",
    "                 + \"neg_mean_absolute_error, f1 o accuracy.\"\n",
    "            )\n",
    "\n",
    "        if self.n_variables != x.shape[1]:\n",
    "            raise Exception(\n",
    "                \"n_variables debe ser igual al número de columnas de x.\"\n",
    "            )\n",
    "\n",
    "        if not isinstance(x, np.ndarray) or x.ndim != 2:\n",
    "            raise Exception(\n",
    "                \"x debe ser un array numpy de dos dimensiones (una matriz).\"\n",
    "            )\n",
    "        if not isinstance(y, np.ndarray) or y.ndim != 1:\n",
    "            raise Exception(\n",
    "                \"y debe ser un array numpy de 1 dimensiones.\"\n",
    "            )\n",
    "\n",
    "        if modelo == \"lineal\":\n",
    "            if metrica not in [\"neg_mean_squared_error\", \"neg_mean_absolute_error\"]:\n",
    "                raise Exception(\n",
    "                \"Para el modelo lineal, la métrica debe ser: \" \\\n",
    "                + \"neg_mean_squared_error o neg_mean_absolute_error.\"\n",
    "                )\n",
    "            if tipo_modelo != \"regresion\":\n",
    "                raise Exception(\n",
    "                \"El modelo lineal solo puede aplicarse a problemas de regresión.\"\n",
    "                )\n",
    "\n",
    "        if modelo == \"glm\":\n",
    "            if metrica not in [\"f1\", \"accuracy\"]:\n",
    "                raise Exception(\n",
    "                \"Para el modelo glm la métrica de evaluación debe ser f1,\" \\\n",
    "                + \"o accuracy.\"\n",
    "                )\n",
    "            if tipo_modelo != \"clasificacion\":\n",
    "                raise Exception(\n",
    "                \"El modelo glm solo puede aplicarse a problemas de clasificación.\"\n",
    "                )\n",
    "            if len(np.unique(y)) != 1:\n",
    "                raise Exception(\n",
    "                \"El modelo glm solo puede aplicarse a problemas de clasificación\" \\\n",
    "                + \"binaria.\"\n",
    "                )\n",
    "\n",
    "        # SE EVALÚA CADA INDIVIDUO DE LA POBLACIÓN\n",
    "        # ----------------------------------------------------------------------\n",
    "        self.metrica = metrica\n",
    "        self.modelo  = modelo\n",
    "\n",
    "        for i in np.arange(self.n_individuos):\n",
    "            if forzar_evaluacion:\n",
    "                #Se evaluan todos los individuos\n",
    "                self.individuos[i].evaluar_individuo(\n",
    "                    x = x,\n",
    "                    y = y,\n",
    "                    cv = cv,\n",
    "                    test_size = test_size,\n",
    "                    tipo_modelo = tipo_modelo,\n",
    "                    modelo = modelo,\n",
    "                    metrica = metrica,\n",
    "                    rf_n_estimators = rf_n_estimators,\n",
    "                    verbose = verbose\n",
    "                )\n",
    "            else:\n",
    "                if self.individuos[i].fitness is None:\n",
    "                    # Solo los no previamente evaluados se evaluan\n",
    "                    self.individuos[i].evaluar_individuo(\n",
    "                        x = x,\n",
    "                        y = y,\n",
    "                        cv = cv,\n",
    "                        test_size = test_size,\n",
    "                        tipo_modelo = tipo_modelo,\n",
    "                        modelo = modelo,\n",
    "                        metrica = metrica,\n",
    "                        rf_n_estimators = rf_n_estimators,\n",
    "                        verbose = verbose\n",
    "                    )\n",
    "\n",
    "        # MEJOR INDIVIDUO DE LA POBLACIÓN\n",
    "        # ----------------------------------------------------------------------\n",
    "        # Se identifica el mejor individuo de toda el población, el de mayor\n",
    "        # fitness.\n",
    "\n",
    "        # Se selecciona inicialmente como mejor individuo el primero.\n",
    "        self.mejor_individuo = copy.deepcopy(self.individuos[0])\n",
    "        # Se comparan todas los individuos de la población.\n",
    "        for i in np.arange(1,self.n_individuos):\n",
    "            if self.individuos[i].fitness > self.mejor_individuo.fitness:\n",
    "                self.mejor_individuo = copy.deepcopy(self.individuos[i])\n",
    "\n",
    "        # Se extrae la información del mejor individuo de la población.\n",
    "        self.mejor_fitness = copy.copy(self.mejor_individuo.fitness)\n",
    "        self.mejor_valor_metrica = copy.copy(self.mejor_individuo.valor_metrica)\n",
    "        self.mejor_secuencia = copy.copy(self.mejor_individuo.secuencia)\n",
    "        self.mejor_predictores = copy.copy(self.mejor_individuo.predictores)\n",
    "        \n",
    "        self.evaluada = True\n",
    "        \n",
    "        # INFORMACIÓN DEL PROCESO (VERBOSE)\n",
    "        # ----------------------------------------------------------------------\n",
    "        if verbose:\n",
    "            print(\"------------------\")\n",
    "            print(\"Población evaluada\")\n",
    "            print(\"------------------\")\n",
    "            print(\"Mejor fitness encontrado : \" + str(self.mejor_fitness))\n",
    "            print(\"Mejor valor de la métrica: \" + str(self.mejor_valor_metrica))\n",
    "            print(\"Mejor secuencia encontrada: \" \n",
    "                + str(self.mejor_secuencia))\n",
    "            print(\"Mejores predictores encontrados: \" \n",
    "                + str(self.mejor_predictores))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "    def cruzar_individuos(self, parental_1, parental_2, metodo_cruce = \"uniforme\",\n",
    "                          verbose=False):\n",
    "        \"\"\"\n",
    "        Este método genera un nuevo individuo a partir de dos individuos\n",
    "        parentales empleando el método de cruzamiento uniforme.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parental_1 : `int`\n",
    "            índice del individuo de la población que se quiere emplear como\n",
    "            parental 1 para el cruzamiento.\n",
    "\n",
    "        parental_2 : `int`\n",
    "            índice del individuo de la población que se quiere emplear como\n",
    "            parental 2 para el cruzamiento.\n",
    "            \n",
    "        metodo_cruce : {\"uniforme\", \"punto_simple\"}\n",
    "            método de cruamiento empleado.\n",
    "        \n",
    "        verbose : `bool`, optional\n",
    "            mostrar información del proceso por pantalla. (default ``False``)\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        raise Exception\n",
    "            si los índices parental_1 o parental_2 no son índices válidos.\n",
    "\n",
    "        Returns\n",
    "        ------\n",
    "        descendencia : `Individuo`\n",
    "            Nuevo individuo generado por cruzamiento de dos parentales.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> poblacion = Poblacion(\n",
    "                            n_individuos = 2,\n",
    "                            n_variables  = 10,\n",
    "                            n_max        = 5,\n",
    "                            n_min        = 1,\n",
    "                            verbose      = True\n",
    "                        )\n",
    "\n",
    "        >>> descendencia = poblacion.cruzar_individuos(\n",
    "                            parental_1 = 0,\n",
    "                            parental_2 = 1,\n",
    "                            metodo_cruce = \"punto_simple\",\n",
    "                            verbose    = True\n",
    "                           )\n",
    "        Notes\n",
    "        -----\n",
    "        El objetivo del cruzamiento es generar, a partir de individuos ya\n",
    "        existentes (parentales), nuevos individuos (descendencia) que combinen\n",
    "        las características de los anteriores. Este es otro de los puntos del\n",
    "        algoritmo en los que se puede seguir varias estrategias. Tres de las más\n",
    "        empleadas son:\n",
    "        Cruzamiento a partir de uno solo punto: se selecciona aleatoriamente\n",
    "        una posición que actúa como punto de corte. Cada individuo parental se\n",
    "        divide en dos partes y se intercambian las mitades. Como resultado de\n",
    "        este proceso, por cada cruce, se generan dos nuevos individuos.\n",
    "\n",
    "        Cruzamiento a partir múltiples puntos: se seleccionan aleatoriamente\n",
    "        varias posiciones que actúan como puntos de corte. Cada individuo\n",
    "        parental se divide por los puntos de corte y se intercambian las partes.\n",
    "        Como resultado de este proceso, por cada cruce, se generan dos nuevos\n",
    "        individuos.\n",
    "\n",
    "        Cruzamiento uniforme: el valor que toma cada posición del nuevo\n",
    "        individuo se obtiene de uno de los dos parentales. Por lo general,\n",
    "        la probabilidad de que el valor proceda de cada parental es la misma,\n",
    "        aunque podría, por ejemplo, estar condicionada al fitness de cada uno.\n",
    "        A diferencia de las anteriores estrategias, con esta, de cada cruce se\n",
    "        genera un único descendiente.     \n",
    "        \"\"\"\n",
    "\n",
    "        # COMPROBACIONES INICIALES: EXCEPTIONS Y WARNINGS\n",
    "        # ----------------------------------------------------------------------\n",
    "        if parental_1 not in np.arange(self.n_individuos):\n",
    "            raise Exception(\n",
    "                \"El índice del parental_1 debe de ser un valor entre 0 y \" +\n",
    "                \"el número de individuos de la población.\"\n",
    "                )\n",
    "        if parental_2 not in np.arange(self.n_individuos):\n",
    "            raise Exception(\n",
    "                \"El índice del parental_2 debe de ser un valor entre 0 y \" +\n",
    "                \"el número de individuos de la población.\"\n",
    "                )\n",
    "\n",
    "        if metodo_cruce not in [\"uniforme\", \"punto_simple\"]:\n",
    "            raise Exception(\n",
    "                \"El argumento metodo_cruce debe de ser\" +\n",
    "                \"uniforme o punto_simple.\"\n",
    "                )\n",
    "\n",
    "        # CREACIÓN DE LA DESCENDENCIA\n",
    "        # ----------------------------------------------------------------------\n",
    "        # Se extraen los parentales acorde a los índices indicados.\n",
    "        parental_1 = self.individuos[parental_1]\n",
    "        parental_2 = self.individuos[parental_2]\n",
    "        \n",
    "        # Se clona uno de los parentales para utilizarlo como plantilla del nuevo\n",
    "        # individuo.\n",
    "        descendencia = copy.deepcopy(parental_1)\n",
    "        descendencia.secuencia = np.repeat(None, descendencia.n_variables)\n",
    "        descendencia.predictores = None\n",
    "        descendencia.fitness = None\n",
    "        descendencia.valor_metrica = None\n",
    "        descendencia.n_predictores_incluidos = None\n",
    "\n",
    "        if metodo_cruce == \"uniforme\":\n",
    "            # Se seleccionan aleatoriamente las posiciones que se heredan del\n",
    "            # parental_1 y del parental 2.\n",
    "            herencia_parent_1 = np.random.choice(\n",
    "                                    a       = [True, False],\n",
    "                                    size    = descendencia.n_variables,\n",
    "                                    p       = [0.5, 0.5],\n",
    "                                    replace = True\n",
    "                                )\n",
    "            herencia_parent_2 = np.logical_not(herencia_parent_1)\n",
    "\n",
    "            # Se transfieren los valores al nuevo individuo.\n",
    "            descendencia.secuencia[herencia_parent_1] \\\n",
    "                = parental_1.secuencia[herencia_parent_1]\n",
    "\n",
    "            descendencia.secuencia[herencia_parent_2] \\\n",
    "                = parental_2.secuencia[herencia_parent_2]\n",
    "            \n",
    "        if metodo_cruce == \"punto_simple\":\n",
    "            punto_cruce  = np.random.choice(\n",
    "                            a = np.arange(1, descendencia.n_variables - 1),\n",
    "                            size = 1\n",
    "                            )\n",
    "            punto_cruce = punto_cruce[0]\n",
    "            descendencia.secuencia = np.hstack(   \n",
    "                                        (parental_1.secuencia[:punto_cruce],\n",
    "                                        parental_2.secuencia[punto_cruce:])\n",
    "                                    )\n",
    "            \n",
    "        # Todo individuo debe tener como mínimo 1 predictor, si como consecuencia del \n",
    "        # cruzamiento, ningun valor de la secuencia es True, se selecciona una posición\n",
    "        # aleatoria y se sobreescribe con True.\n",
    "        if sum(descendencia.secuencia == True) == 0:\n",
    "            indice = np.random.choice(\n",
    "                        a       = np.arange(descendencia.n_variables),\n",
    "                        size    = 1, \n",
    "                        replace = False\n",
    "                      )\n",
    "            descendencia.secuencia[indice] = True\n",
    "\n",
    "        descendencia.secuencia = descendencia.secuencia.astype('bool')\n",
    "        descendencia.predictores \\\n",
    "            = np.arange(descendencia.n_variables)[descendencia.secuencia]\n",
    "\n",
    "        descendencia.n_predictores_incluidos = np.sum(descendencia.secuencia)\n",
    "        # Se crea un deepcopy para que el nuevo individuo sea independiente de \n",
    "        # los parentales. Esto evita problemas si posteriormente se muta.\n",
    "        descendencia = copy.deepcopy(descendencia)\n",
    "            \n",
    "        \n",
    "\n",
    "        # INFORMACIÓN DEL PROCESO (VERBOSE)\n",
    "        # ----------------------------------------------------------------------\n",
    "        if verbose:\n",
    "            print(\"---------------\")\n",
    "            print(\"Cruce realizado\")\n",
    "            print(\"---------------\")\n",
    "            print(\"Secuencia: \" + str(descendencia.secuencia))\n",
    "            print(\"Índice predictores: \" + str(descendencia.predictores))\n",
    "            print(\"\")\n",
    "\n",
    "        return(descendencia)\n",
    "\n",
    "\n",
    "    def seleccionar_individuo(self, n, return_indices=True,\n",
    "                              metodo_seleccion=\"tournament\", verbose=False):\n",
    "        \"\"\"\n",
    "        Este método selecciona los índices de n individuos de una población,\n",
    "        donde la probabilidad de selección está relacionada con el fitness de  \n",
    "        cada individuo. Si el argumento `return_indices=False` en lugar de los\n",
    "        índices se devuelve una copia de los individuos seleccionados.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n : `int`\n",
    "            número de individuos de la población que se seleccionan.\n",
    "\n",
    "        return_indices : `bool`, optional\n",
    "            cuando es ``True``, se devuelve el índice que ocupan los individuos\n",
    "            seleccionados, cuando es ``False`` se devuelve una lista que contiene\n",
    "            una copia de los individuos. (default ``True``)\n",
    "\n",
    "        metodo_seleccion : {\"ruleta\", \"rank\", \"tournament\"}\n",
    "            método de selección, ver notas para más información.\n",
    "            (default \"tournament\")\n",
    "\n",
    "        verbose : `bool`, optional\n",
    "            mostrar información del proceso por pantalla. (default ``False``)\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        raise Exception\n",
    "            si el argumento `metodo_seleccion` no es 'ruleta', 'rank' o\n",
    "            'tournament'.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        indices : `numpy.ndarray`\n",
    "            índice de los individuos seleccionados (si `return_indices=True`)\n",
    "\n",
    "        individuos : `list`\n",
    "            lista con los individuos seleccionados (si `return_indices=False`)\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "\n",
    "        >>> boston = datasets.load_boston(return_X_y= True)\n",
    "        >>> poblacion = Poblacion(\n",
    "                            n_individuos = 5,\n",
    "                            n_variables  = 13,\n",
    "                            n_max        = 5,\n",
    "                            n_min        = 1,\n",
    "                            verbose      = False\n",
    "                        )\n",
    "        >>> poblacion.evaluar_poblacion(\n",
    "                x  = boston[0],\n",
    "                y  = boston[1],\n",
    "                cv = 5,\n",
    "                test_size = 0.2,\n",
    "                tipo_modelo = \"regresion\",\n",
    "                modelo      = \"randomforest\",\n",
    "                metrica     = \"neg_mean_squared_error\",\n",
    "                forzar_evaluacion = True,\n",
    "                cv_seed           = 123,\n",
    "                verbose           = True\n",
    "            )\n",
    "        >>> poblacion.seleccionar_individuo(\n",
    "                n                = 2,\n",
    "                return_indices   = True,\n",
    "                metodo_seleccion = \"tournament\",\n",
    "                verbose          = True\n",
    "            )\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        La forma en que se seleccionan los individuos que participan en cada cruce\n",
    "        difiere en las distintas implementaciones de los algoritmos genéticos.\n",
    "        Por lo general, todas ellas tienden a favorecer la selección de aquellos\n",
    "        individuos con mayor fitness. Algunas de las estrategias más comunes son:\n",
    "        Método de ruleta: la probabilidad de que un individuo sea seleccionado\n",
    "        es proporcional a su fitness relativo, es decir, a su fitness dividido\n",
    "        por la suma del fitness de todos los individuos de la población. Si el\n",
    "        fitness de un individuo es el doble que el de otro, también lo será la\n",
    "        probabilidad de que sea seleccionado. Este método presenta problemas si\n",
    "        el fitness de unos pocos individuos es muy superior (varios órdenes de\n",
    "        magnitud) al resto, ya que estos serán seleccionados de forma repetida y\n",
    "        casi todos los individuos de la siguiente generación serán “hijos” de\n",
    "        los mismos “padres” (poca variación).\n",
    "        Método rank: la probabilidad de selección de un individuo es inversamente\n",
    "        proporcional a la posición que ocupa tras ordenar todos los individuos\n",
    "        de mayor a menor fitness. Este método es menos agresivo que el método\n",
    "        ruleta cuando la diferencia entre los mayores fitness es varios órdenes\n",
    "        de magnitud superior al resto.\n",
    "        Selección competitiva (tournament): se seleccionan aleatoriamente dos\n",
    "        parejas de individuos de la población (todos con la misma probabilidad).\n",
    "        De cada pareja se selecciona el que tenga mayor fitness. Finalmente,\n",
    "        se comparan los dos finalistas y se selecciona el de mayor fitness. Este\n",
    "        método tiende a generar una distribución de la probabilidad de selección\n",
    "        más equilibrada que las dos anteriores.\n",
    "        Selección truncada (truncated selection): se realizan selecciones\n",
    "        aleatorias de individuos, habiendo descartado primero los n individuos\n",
    "        con menor fitness de la población.\n",
    "\n",
    "        La conversión de fitness a probabilidad es distinta dependiendo de la\n",
    "        métrica utilizada para calcular el fitness. Si el fitness toma valores en\n",
    "        el rango [-inf, 0], cuanto más próximo a 0 sea el fitness (menor la\n",
    "        magnitud del valor negativo), mayor debe ser la probabilidad de ser\n",
    "        seleccionado. Para lograr la conversión se emplea −1/fitness.\n",
    "\n",
    "        Si el fitness equivale al accuracy o f1, cuanto mayor sea el fitness,\n",
    "        mayor debe ser la probabilidad de ser seleccionado. En este caso, no es\n",
    "        necesaria ninguna modificación.\n",
    "        \"\"\"\n",
    "\n",
    "        # COMPROBACIONES INICIALES: EXCEPTIONS Y WARNINGS\n",
    "        # ----------------------------------------------------------------------\n",
    "        if metodo_seleccion not in [\"ruleta\", \"rank\", \"tournament\"]:\n",
    "            raise Exception(\n",
    "                \"El método de selección debe de ser ruleta, rank o tournament.\"\n",
    "                )\n",
    "        \n",
    "        # SELECCIÓN DE INDIVIDUOS\n",
    "        # ----------------------------------------------------------------------\n",
    "        # Se crea un array con el fitness de cada individuo de la población.\n",
    "        array_fitness = np.full(self.n_individuos, None, dtype = \"float\")\n",
    "        for i in np.arange(self.n_individuos):\n",
    "            array_fitness[i] = copy.copy(self.individuos[i].fitness)\n",
    "        \n",
    "        # Se calcula la probabilidad de selección de cada individuo en función\n",
    "        # de su fitness.\n",
    "        if metodo_seleccion == \"ruleta\":\n",
    "            if self.metrica in [\"neg_mean_squared_error\", \"neg_mean_absolute_error\"]:\n",
    "                # Si el fitness es [-inf,0] se emplea 1/fitness\n",
    "                array_fitness = 1/array_fitness\n",
    "\n",
    "            probabilidad_seleccion = array_fitness / np.sum(array_fitness)\n",
    "            ind_seleccionado = np.random.choice(\n",
    "                                    a       = np.arange(self.n_individuos),\n",
    "                                    size    = n,\n",
    "                                    p       = list(probabilidad_seleccion),\n",
    "                                    replace = True\n",
    "                               )\n",
    "        elif metodo_seleccion == \"rank\":\n",
    "            # La probabilidad con este método es inversamente proporcional a la\n",
    "            # posición en la que quedan ordenados los individuos de menor a mayor\n",
    "            # fitness.\n",
    "            ranks = rankdata(-1*array_fitness)\n",
    "            probabilidad_seleccion = 1 / ranks\n",
    "            probabilidad_seleccion = probabilidad_seleccion / np.sum(probabilidad_seleccion)\n",
    "            ind_seleccionado = np.random.choice(\n",
    "                                a       = np.arange(self.n_individuos),\n",
    "                                size    = n,\n",
    "                                p       = list(probabilidad_seleccion),\n",
    "                                replace = True\n",
    "                            )\n",
    "        elif metodo_seleccion == \"tournament\":\n",
    "            if self.metrica in [\"neg_mean_squared_error\", \"neg_mean_absolute_error\"]:\n",
    "                # Si el fitness es [-inf,0] se emplea 1/fitness\n",
    "                array_fitness = 1/array_fitness\n",
    "\n",
    "            ind_seleccionado = np.repeat(None,n)\n",
    "            for i in np.arange(n):\n",
    "                # Se seleccionan aleatoriamente dos parejas de individuos.\n",
    "                candidatos_a = np.random.choice(\n",
    "                                a       = np.arange(self.n_individuos),\n",
    "                                size    = 2,\n",
    "                                replace = False\n",
    "                            )\n",
    "                candidatos_b = np.random.choice(\n",
    "                                a       = np.arange(self.n_individuos),\n",
    "                                size    = 2,\n",
    "                                replace = False\n",
    "                            )\n",
    "                # De cada pareja se selecciona el de mayor fitness.\n",
    "                if array_fitness[candidatos_a[0]] > array_fitness[candidatos_a[1]]:\n",
    "                    ganador_a = candidatos_a[0]\n",
    "                else:\n",
    "                    ganador_a = candidatos_a[1]\n",
    "\n",
    "                if array_fitness[candidatos_b[0]] > array_fitness[candidatos_b[1]]:\n",
    "                    ganador_b = candidatos_b[0]\n",
    "                else:\n",
    "                    ganador_b = candidatos_b[1]\n",
    "\n",
    "                # Se comparan los dos ganadores de cada pareja.\n",
    "                if array_fitness[ganador_a] > array_fitness[ganador_b]:\n",
    "                    ind_final = ganador_a\n",
    "                else:\n",
    "                    ind_final = ganador_b\n",
    "                \n",
    "                ind_seleccionado[i] = ind_final\n",
    "\n",
    "        # INFORMACIÓN DEL PROCESO (VERBOSE)\n",
    "        # ----------------------------------------------------------------------\n",
    "        if verbose:\n",
    "            print(\"----------------------\")\n",
    "            print(\"Individuo seleccionado\")\n",
    "            print(\"----------------------\")\n",
    "            print(\"Método selección: \" + metodo_seleccion)\n",
    "            print(\"Índice seleccionado: \" + str(ind_seleccionado))\n",
    "            print(\"\")\n",
    "\n",
    "        if(return_indices):\n",
    "            return(ind_seleccionado)\n",
    "        else:\n",
    "            if n == 1:\n",
    "                return(copy.deepcopy(self.individuos[int(ind_seleccionado)]))\n",
    "            if n > 1:\n",
    "                return(\n",
    "                    [copy.deepcopy(self.individuos[i]) for i in ind_seleccionado]\n",
    "                )\n",
    "\n",
    "    def crear_nueva_generacion(self, metodo_seleccion=\"tournament\",\n",
    "                               metodo_cruce = \"uniforme\",\n",
    "                               elitismo=0.1, prob_mut=0.1,\n",
    "                               verbose=False, verbose_seleccion=False,\n",
    "                               verbose_cruce=False, verbose_mutacion=False):\n",
    "        \"\"\"\n",
    "        Este método somete la población a una nueva generación.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        metodo_seleccion : {\"ruleta\", \"rank\", \"tournament\"}\n",
    "            método de selección, ver notas para más información.\n",
    "            (default `tournament`)\n",
    "\n",
    "        metodo_cruce : {\"uniforme\", \"punto_simple\"}\n",
    "            método de cruamiento empleado.\n",
    "\n",
    "        elitismo : `float`, optional\n",
    "            porcentaje de mejores individuos de la población actual que pasan\n",
    "            directamente a la siguiente población. De esta forma, se asegura\n",
    "            que la siguiente generación no sea nunca peor. (default `0.1`)\n",
    "\n",
    "        prob_mut : `float`, optional\n",
    "            probabilidad que tiene cada posición del individuo de mutar.\n",
    "            (default 0.1)\n",
    "\n",
    "        verbose : `bool`, optional\n",
    "            mostrar información del proceso por pantalla. (default ``False``)\n",
    "        \n",
    "        verbose_seleccion : `bool`, optional\n",
    "            mostrar información de cada selección por pantalla.\n",
    "            (default ``False``)\n",
    "\n",
    "        verbose_cruce : `bool`, optional\n",
    "            mostrar información de cada cruce por pantalla.\n",
    "            (default ``False``)\n",
    "\n",
    "        verbose_mutacion : `bool`, optional\n",
    "            mostrar información de cada mutación por pantalla.\n",
    "            (default ``False``)\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> boston = datasets.load_boston(return_X_y= True)\n",
    "        >>> poblacion = Poblacion(\n",
    "                            n_individuos   = 5,\n",
    "                            n_variables    = 13,\n",
    "                            n_max          = 5,\n",
    "                            n_max_estricto = True,    \n",
    "                            n_min          = 1,\n",
    "                            verbose        = False\n",
    "                        )\n",
    "        >>> poblacion.evaluar_poblacion(\n",
    "                x  = boston[0],\n",
    "                y  = boston[1],\n",
    "                cv = 5,\n",
    "                tipo_modelo = \"regresion\",\n",
    "                modelo      = \"randomforest\",\n",
    "                metrica     = \"neg_mean_squared_error\",\n",
    "                forzar_evaluacion = True,\n",
    "                cv_seed           = 123,\n",
    "                verbose           = True\n",
    "            )\n",
    "        \n",
    "        >>> poblacion.crear_nueva_generacion(\n",
    "                metodo_seleccion   = \"tournament\",\n",
    "                metodo_cruce       = \"uniforme\",\n",
    "                elitismo           = 0.1,\n",
    "                prob_mut           = 0.01,\n",
    "                verbose            = True,\n",
    "                verbose_seleccion  = False,\n",
    "                verbose_cruce      = False,\n",
    "                verbose_mutacion   = False\n",
    "                )\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # Lista donde almacenar los individuos de la nueva generación.\n",
    "        nuevos_individuos = []\n",
    "\n",
    "        # ELITISMO\n",
    "        # ----------------------------------------------------------------------\n",
    "        if elitismo > 0:\n",
    "            # Número de individuos que pasan directamente a la siguiente\n",
    "            # generación.\n",
    "            n_elitismo = int(np.ceil(self.n_individuos*elitismo))\n",
    "\n",
    "            # Se identifican los n_elitismo individuos con mayor fitness (élite).\n",
    "            array_fitness = np.zeros(shape = self.n_individuos, dtype=float)\n",
    "            for i in np.arange(self.n_individuos):\n",
    "                array_fitness[i] = copy.copy(self.individuos[i].fitness)\n",
    "            rank = np.flip(np.argsort(array_fitness), axis = 0)\n",
    "            elite = [copy.deepcopy(self.individuos[i]) for i in rank[:n_elitismo]]\n",
    "            # Se añaden los individuos élite a la lista de nuevos individuos.\n",
    "            nuevos_individuos = nuevos_individuos + elite\n",
    "        else:\n",
    "            n_elitismo = 0\n",
    "            \n",
    "        # CREACIÓN DE NUEVOS INDIVIDUOS POR CRUCES\n",
    "        # ----------------------------------------------------------------------\n",
    "        for i in np.arange(self.n_individuos-n_elitismo):\n",
    "            # Seleccionar parentales\n",
    "            indice_parentales = self.seleccionar_individuo(\n",
    "                                    n                = 2,\n",
    "                                    return_indices   = True,\n",
    "                                    metodo_seleccion = metodo_seleccion,\n",
    "                                    verbose          = verbose_seleccion\n",
    "                                 )\n",
    "            # Cruzar parentales para obtener la descendencia\n",
    "            descendencia = self.cruzar_individuos(\n",
    "                            parental_1   = indice_parentales[0],\n",
    "                            parental_2   = indice_parentales[1],\n",
    "                            metodo_cruce = metodo_cruce,\n",
    "                            verbose      = verbose_cruce\n",
    "                           )\n",
    "            # Mutar la descendencia\n",
    "            descendencia.mutar(\n",
    "                prob_mut         = prob_mut,\n",
    "                verbose          = verbose_mutacion\n",
    "            )\n",
    "\n",
    "            # Si n_max_estricto=True, se elimina el exceso de Trues en la\n",
    "            # secuencia de la descendencia.\n",
    "            if self.n_max_estricto:\n",
    "                descendencia.forzar_n_max()\n",
    "\n",
    "            # Se añade la descendencia a la lista de nuevos individuos. Para\n",
    "            # que no de error la unión, se introduce el individuo descendencia\n",
    "            # dentro de una lista.\n",
    "            nuevos_individuos.append(copy.deepcopy(descendencia))\n",
    "\n",
    "        # ACTUALIZACIÓN INFORMACIÓN DE LA POBLACIÓN\n",
    "        # ----------------------------------------------------------------------\n",
    "        self.individuos = copy.deepcopy(nuevos_individuos)\n",
    "        self.mejor_individuo = None\n",
    "        self.mejor_fitness = None\n",
    "        self.mejor_valor_metrica = None\n",
    "        self.mejor_secuencia = None\n",
    "        self.mejor_predictores = None\n",
    "        self.evaluada = False\n",
    "        \n",
    "        # INFORMACIÓN DEL PROCESO (VERBOSE)\n",
    "        # ----------------------------------------------------------------------\n",
    "        if verbose:\n",
    "            print(\"----------------------\")\n",
    "            print(\"Nueva población creada\")\n",
    "            print(\"----------------------\")\n",
    "            print(\"Método selección: \" + metodo_seleccion)\n",
    "            print(\"Elitismo: \" + str(elitismo))\n",
    "            print(\"Número individuos élite: \" + str(n_elitismo))\n",
    "            print(\"Número de nuevos individuos: \"\\\n",
    "                + str(self.n_individuos-n_elitismo))\n",
    "            print(\"\")\n",
    "\n",
    "    def optimizar(self, x, y, tipo_modelo, modelo, metrica, cv = 5,\n",
    "                  test_size=0.2, cv_seed=123, nivel_referencia = None,\n",
    "                  n_generaciones = 50, metodo_seleccion=\"tournament\",\n",
    "                  metodo_cruce = \"uniforme\", elitismo=0.1,\n",
    "                  prob_mut=0.1, rf_n_estimators=100,\n",
    "                  parada_temprana=False, rondas_parada=None,\n",
    "                  tolerancia_parada=None,verbose=False,\n",
    "                  verbose_nueva_generacion=False,\n",
    "                  verbose_seleccion=False, verbose_cruce=False,\n",
    "                  verbose_mutacion=False, verbose_evaluacion=False):\n",
    "        \"\"\"\n",
    "        Este método realiza el proceso de optimización de una población.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        x : `numpy array 2d`\n",
    "            matriz con el valor de los predictores.\n",
    "\n",
    "        y : `numpy array 1d`\n",
    "            numpy array con la variable respuesta.\n",
    "\n",
    "        cv : `int`\n",
    "            número de repeticiones para la validación. EL método empleado es \n",
    "            `ShuffleSplit` de scikit-learn. (default 5)\n",
    "\n",
    "        test_size : `float`\n",
    "            porcentaje de observaciones empleadas como test en cada validación.\n",
    "            (default 0.2)\n",
    "\n",
    "        cv_seed : `int`\n",
    "            semilla empleada para el reparto aleatorio. (default 123)\n",
    "\n",
    "        modelo: {lineal, logistico, randomforest}\n",
    "            modelo empleado para evaluar al individuo.\n",
    "\n",
    "        tipo_modelo: {regresion, clasificacion}\n",
    "            tipo de problema (regresión o clasificación)\n",
    "        \n",
    "        metrica: {\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"f1\",\n",
    "                 \"accuracy\"}\n",
    "            métrica empleada para calcular el fitness del individuo.\n",
    "\n",
    "        nivel_referencia : `str`\n",
    "            valor de la variable respuesta considerado como referencia.\n",
    "            Necesario cuando la métrica es f1 o kappa. (default ``None``)\n",
    "            \n",
    "        rf_n_estimators : `int`\n",
    "            número de árboles en los modelos random forest. (default 100)\n",
    "\n",
    "        n_generaciones : `int` , optional\n",
    "            número de generaciones de optimización. (default 50)\n",
    "\n",
    "        metodo_seleccion : {\"ruleta\", \"rank\", \"tournament\"}\n",
    "            método de selección, ver notas para más información.\n",
    "            (default `tournament`)\n",
    "        \n",
    "        metodo_cruce : {\"uniforme\", \"punto_simple\"}\n",
    "            método de cruamiento empleado.\n",
    "\n",
    "        elitismo : `float`, optional\n",
    "            porcentaje de mejores individuos de la población actual que pasan\n",
    "            directamente a la siguiente población. De esta forma, se asegura\n",
    "            que, la siguiente generación, no sea nunca peor. (default 0.1)\n",
    "\n",
    "        prob_mut : `float`, optional\n",
    "            probabilidad que tiene cada posición del individuo de mutar.\n",
    "            (default 0.1)\n",
    "     \n",
    "        parada_temprana : `bool`, optional\n",
    "            si durante las últimas `rondas_parada` generaciones la diferencia\n",
    "            absoluta entre mejores individuos no es superior al valor de \n",
    "            `tolerancia_parada`, se detiene el algoritmo y no se crean nuevas\n",
    "            generaciones. (default ``False``)\n",
    "\n",
    "        rondas_parada : `int`, optional\n",
    "            número de generaciones consecutivas sin mejora mínima para que se\n",
    "            active la parada temprana. (default ``None``)\n",
    "\n",
    "        tolerancia_parada : `float` or `int`, optional\n",
    "            valor mínimo que debe tener la diferencia de generaciones consecutivas\n",
    "            para considerar que hay cambio. (default ``None``)\n",
    "\n",
    "        verbose : `bool`, optional\n",
    "            mostrar información del proceso por pantalla. (default ``False``)\n",
    "        \n",
    "        verbose_nueva_generacion : `bool`, optional\n",
    "            mostrar información de cada nueva generación por pantalla.\n",
    "            (default ``False``)\n",
    "\n",
    "        verbose_seleccion : `bool`, optional\n",
    "            mostrar información de cada selección por pantalla.\n",
    "            (default ``False``)\n",
    "\n",
    "        verbose_cruce : `bool`, optional\n",
    "            mostrar información de cada cruce por pantalla.\n",
    "            (default ``False``)\n",
    "\n",
    "        verbose_mutacion : `bool`, optional\n",
    "            mostrar información de cada mutación por pantalla.\n",
    "            (default ``False``)\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        raise Exception\n",
    "            si se indica `parada_temprana = True` y los argumentos `rondas_parada`\n",
    "            o `tolerancia_parada` son ``None``.\n",
    "\n",
    "        raise Exception\n",
    "            si el argumento `metodo_seleccion` no es 'ruleta', 'rank' o\n",
    "            'tournament'.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> boston = datasets.load_boston(return_X_y= True)\n",
    "        >>> poblacion = Poblacion(\n",
    "                            n_individuos   = 50,\n",
    "                            n_variables    = 13,\n",
    "                            n_max          = 5,\n",
    "                            n_max_estricto = False,    \n",
    "                            n_min          = 1,\n",
    "                            verbose        = False\n",
    "                        )\n",
    "        >>> poblacion.optimizar(\n",
    "                x                  = boston[0],\n",
    "                y                  = boston[1],\n",
    "                cv                 = 5,\n",
    "                test_size          = 0.2,\n",
    "                tipo_modelo        = \"regresion\",\n",
    "                modelo             = \"randomforest\",\n",
    "                metrica            = \"neg_mean_squared_error\",\n",
    "                n_generaciones     = 25,\n",
    "                metodo_seleccion   = \"tournament\",\n",
    "                metodo_cruce       = \"uniforme\",\n",
    "                elitismo           = 0.1,\n",
    "                prob_mut           = 0.1,\n",
    "                parada_temprana    = True,\n",
    "                rondas_parada      = 5,\n",
    "                tolerancia_parada  = 10**-4,\n",
    "                verbose            = True,\n",
    "                verbose_nueva_generacion = False,\n",
    "                verbose_seleccion        = False,\n",
    "                verbose_cruce            = False,\n",
    "                verbose_mutacion         = False,\n",
    "                verbose_evaluacion       = False\n",
    "            )\n",
    "        \"\"\"\n",
    "\n",
    "        # COMPROBACIONES INICIALES: EXCEPTIONS Y WARNINGS\n",
    "        # ----------------------------------------------------------------------\n",
    "        # Si se activa la parada temprana, hay que especificar los argumentos\n",
    "        # rondas_parada y tolerancia_parada.\n",
    "        if parada_temprana \\\n",
    "        and (rondas_parada is None or tolerancia_parada is None):\n",
    "            raise Exception(\n",
    "                \"Para activar la parada temprana es necesario indicar un \" \\\n",
    "                + \" valor de rondas_parada y de tolerancia_parada.\"\n",
    "                )\n",
    "\n",
    "        # ITERACIONES (GENERACIONES)\n",
    "        # ----------------------------------------------------------------------\n",
    "        start = time.time()\n",
    "\n",
    "        for i in np.arange(n_generaciones):\n",
    "            if verbose:\n",
    "                print(\"-------------\")\n",
    "                print(\"Generación: \" + str(i))\n",
    "                print(\"-------------\")\n",
    "\n",
    "            # En la primera iteración, la población ya está creada\n",
    "            if i > 0:\n",
    "                # CREAR UNA NUEVA GENERACIÓN\n",
    "                # --------------------------------------------------------------    \n",
    "                self.crear_nueva_generacion(\n",
    "                    metodo_seleccion   = metodo_seleccion,\n",
    "                    metodo_cruce       = metodo_cruce,\n",
    "                    elitismo           = elitismo,\n",
    "                    prob_mut           = prob_mut,\n",
    "                    verbose            = verbose_nueva_generacion,\n",
    "                    verbose_seleccion  = verbose_seleccion,\n",
    "                    verbose_cruce      = verbose_cruce,\n",
    "                    verbose_mutacion   = verbose_mutacion\n",
    "                    )\n",
    "            \n",
    "            # EVALUAR INDIVIDUOS DE LA POBLACIÓN\n",
    "            # ------------------------------------------------------------------\n",
    "            self.evaluar_poblacion(\n",
    "                x  = x,\n",
    "                y  = y,\n",
    "                cv = cv,\n",
    "                test_size   = test_size,\n",
    "                cv_seed     = cv_seed,\n",
    "                tipo_modelo = tipo_modelo,\n",
    "                modelo      = modelo,\n",
    "                metrica     = metrica,\n",
    "                forzar_evaluacion = False,\n",
    "                rf_n_estimators = rf_n_estimators,\n",
    "                verbose     = verbose_evaluacion\n",
    "                )\n",
    "\n",
    "            # SE ALMACENA LA INFORMACIÓN DE LA GENERACIÓN EN LOS HISTÓRICOS\n",
    "            # ------------------------------------------------------------------\n",
    "            self.historico_individuos.append(copy.deepcopy(self.individuos))\n",
    "            self.historico_mejor_fitness.append(copy.deepcopy(self.mejor_fitness))\n",
    "            self.historico_mejor_secuencia.append(\n",
    "                                    copy.deepcopy(self.mejor_secuencia)\n",
    "                                )\n",
    "            self.historico_mejor_predictores.append(\n",
    "                                    copy.deepcopy(self.mejor_predictores)\n",
    "                                )\n",
    "            self.historico_mejor_valor_metrica.append(\n",
    "                                    copy.deepcopy(self.mejor_valor_metrica)\n",
    "                                )\n",
    "\n",
    "            # SE CALCULA LA DIFERENCIA ABSOLUTA RESPECTO A LA GENERACIÓN ANTERIOR\n",
    "            # ------------------------------------------------------------------\n",
    "            # La diferencia solo puede calcularse a partir de la segunda\n",
    "            # generación.\n",
    "            if i == 0:\n",
    "                self.diferencia_abs.append(None)\n",
    "            else:\n",
    "                diferencia = abs(self.historico_mejor_fitness[i] \\\n",
    "                                 - self.historico_mejor_fitness[i-1])\n",
    "                self.diferencia_abs.append(diferencia)\n",
    "\n",
    "            # CRITERIO DE PARADA\n",
    "            # ------------------------------------------------------------------\n",
    "            # Si durante las últimas n generaciones, la diferencia absoluta entre\n",
    "            # mejores individuos no es superior al valor de tolerancia_parada,\n",
    "            # se detiene el algoritmo y no se crean nuevas generaciones.\n",
    "            if parada_temprana and i > rondas_parada:\n",
    "                ultimos_n = np.array(self.diferencia_abs[-(rondas_parada): ])\n",
    "                if all(ultimos_n < tolerancia_parada):\n",
    "                    print(\"Algoritmo detenido en la generación \" \n",
    "                          + str(i) \\\n",
    "                          + \" por falta cambio absoluto mínimo de \" \\\n",
    "                          + str(tolerancia_parada) \\\n",
    "                          + \" durante \" \\\n",
    "                          + str(rondas_parada) \\\n",
    "                          + \" generaciones consecutivas.\")\n",
    "                    break\n",
    "\n",
    "        end = time.time()\n",
    "        self.optimizada = True\n",
    "        self.iter_optimizacion = i + 1\n",
    "        \n",
    "        # IDENTIFICACIÓN DEL MEJOR INDIVIDUO DE TODO EL PROCESO\n",
    "        # ----------------------------------------------------------------------\n",
    "        indice_valor_optimo  = np.argmax(np.array(self.historico_mejor_fitness))\n",
    "        self.fitness_optimo  = self.historico_mejor_fitness[indice_valor_optimo]\n",
    "        self.valor_metrica_optimo= self \\\n",
    "                             .historico_mejor_valor_metrica[indice_valor_optimo]\n",
    "        self.secuencia_optima = self \\\n",
    "                                .historico_mejor_secuencia[indice_valor_optimo]\n",
    "        self.predictores_optimos = self \\\n",
    "                                .historico_mejor_predictores[indice_valor_optimo]\n",
    "        \n",
    "        # CREACIÓN DE UN DATAFRAME CON LOS RESULTADOS\n",
    "        # ----------------------------------------------------------------------\n",
    "        self.resultados_df = pd.DataFrame(\n",
    "            {\n",
    "            \"mejor_fitness\"        : self.historico_mejor_fitness,\n",
    "            \"mejor_valor_metrica\"  : self.historico_mejor_valor_metrica,\n",
    "            \"mejor_secuencia\"      : self.historico_mejor_secuencia,\n",
    "            \"mejor_predictores\"    : self.historico_mejor_predictores,\n",
    "            \"diferencia_abs\"       : self.diferencia_abs\n",
    "            }\n",
    "        )\n",
    "        self.resultados_df[\"generacion\"] = self.resultados_df.index\n",
    "        \n",
    "        print(\"-------------------------------------------\")\n",
    "        print(\"Optimización finalizada \" \\\n",
    "              + datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        print(\"-------------------------------------------\")\n",
    "        print(\"Duración optimización: \" + str(end - start))\n",
    "        print(\"Número de generaciones: \" + str(self.iter_optimizacion))\n",
    "        print(\"Secuencia óptima: \" + str(self.secuencia_optima))\n",
    "        print(\"Predictores óptimos: \" + str(self.predictores_optimos))\n",
    "        print(\"Valor métrica óptimo: \" + str(self.valor_metrica_optimo))\n",
    "        print(\"\")\n",
    "\n",
    "    def plot_evolucion_fitness(self):\n",
    "        \"\"\"\n",
    "        Este método crea un gráfico con la evolución del fitness del mejor\n",
    "        individuo a lo largo de las generaciones.\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.optimizada:\n",
    "            raise Exception(\n",
    "                \"El gráfico solo puede generarse si la población ha sido \" \\\n",
    "                    + \"optimizada previamente.\"\n",
    "            )\n",
    "        plt.style.use('ggplot')\n",
    "        fig, ax = plt.subplots()\n",
    "        self.resultados_df.plot(\n",
    "            x = \"generacion\",\n",
    "            y = \"mejor_fitness\",\n",
    "            ax = ax\n",
    "        )\n",
    "        ax.set(title='Evolución del mejor Individuo',\n",
    "               xlabel='generacion', ylabel='fitness')\n",
    "        ax.legend().set_visible(False)\n",
    "\n",
    "    def plot_frecuencia_seleccion(self):\n",
    "        \"\"\"\n",
    "        Este método crea un gráfico con la frecuencia relativa con la que\n",
    "        aparece cada predictor en el mejor individuo a lo largo de las\n",
    "        generaciones.\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.optimizada:\n",
    "            raise Exception(\n",
    "                \"El gráfico solo puede generarse si la población ha sido \" \\\n",
    "                    + \"optimizada previamente.\"\n",
    "            )\n",
    "        unique, counts =  np.unique(\n",
    "                            np.concatenate(\n",
    "                                self.resultados_df.mejor_predictores.ravel(),\n",
    "                                axis = 0\n",
    "                            ),\n",
    "                            return_counts=True\n",
    "                          )\n",
    "        frecuencia = 100* (counts/self.iter_optimizacion)\n",
    "        frecuencia_selecion = pd.DataFrame(\n",
    "                                {\"predictor\":unique,\n",
    "                                 \"frecuencia\" : frecuencia}) \\\n",
    "                              .sort_values(\n",
    "                                    by=[\"frecuencia\"],\n",
    "                                    ascending = False\n",
    "                               )\n",
    "\n",
    "        plt.style.use('ggplot')\n",
    "        fig, ax = plt.subplots()\n",
    "        frecuencia_selecion.plot.barh(\n",
    "            x = \"predictor\",\n",
    "            y = \"frecuencia\",\n",
    "            ax = ax\n",
    "        )\n",
    "        ax.set(title='Frecuencia de selección',\n",
    "               xlabel='frecuencia', ylabel='predictor')\n",
    "        ax.legend().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Para que las imágenes se muestren en el centro de la celda.\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Generación: 0\n",
      "-------------\n",
      "-------------\n",
      "Generación: 1\n",
      "-------------\n",
      "-------------\n",
      "Generación: 2\n",
      "-------------\n",
      "-------------\n",
      "Generación: 3\n",
      "-------------\n",
      "-------------\n",
      "Generación: 4\n",
      "-------------\n",
      "-------------\n",
      "Generación: 5\n",
      "-------------\n",
      "-------------\n",
      "Generación: 6\n",
      "-------------\n",
      "-------------\n",
      "Generación: 7\n",
      "-------------\n",
      "-------------\n",
      "Generación: 8\n",
      "-------------\n",
      "-------------\n",
      "Generación: 9\n",
      "-------------\n",
      "-------------\n",
      "Generación: 10\n",
      "-------------\n",
      "Algoritmo detenido en la generación 10 por falta cambio absoluto mínimo de 0.01 durante 5 generaciones consecutivas.\n",
      "-------------------------------------------\n",
      "Optimización finalizada 2019-09-02 12:31:53\n",
      "-------------------------------------------\n",
      "Duración optimización: 266.8408863544464\n",
      "Número de generaciones: 11\n",
      "Secuencia óptima: [ True  True  True  True  True  True  True False False False False  True\n",
      " False False False  True False False False False  True  True False  True\n",
      "  True False False False False  True]\n",
      "Predictores óptimos: [ 0  1  2  3  4  5  6 11 15 20 21 23 24 29]\n",
      "Valor métrica óptimo: -9.057578290046992\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "################################################################################\n",
    "#                                 EJEMPLOS                                     #\n",
    "################################################################################\n",
    "\n",
    "# EJEMPLO REGRESIÓN 1\n",
    "# En la libreria sklearn.datasets.make_friedman1 puede encontrarse, el problema\n",
    "# de regresión propuesto por Friedman (1991) y Breiman (1996). Con la función\n",
    "# make_friedman1() se puede generar un conjunto de datos simulados que siguen la\n",
    "# ecuación:\n",
    "\n",
    "# y(X) = 10 * sin(pi * X[:, 0] * X[:, 1]) + 20 * (X[:, 2] - 0.5) ** 2 +\n",
    "#        10 * X[:, 3] + 5 * X[:, 4] + noise * N(0, 1)\n",
    "\n",
    "# Además de las primeras 5 columnas, que están relacionadas con la variable\n",
    "# respuesta, se añaden automáticamente columnas adicionales que siguen una\n",
    "# distribución uniforme [0,1] y que, por lo tanto, no guardan relación alguna\n",
    "# con la variable respuesta.\n",
    "\n",
    "from sklearn.datasets import make_friedman1\n",
    "datos = make_friedman1(\n",
    "            n_samples    = 500,\n",
    "            n_features   = 10,\n",
    "            noise        = 1,\n",
    "            random_state = None\n",
    "        )\n",
    "\n",
    "# Se añaden además 20 columnas adicionales con valores aleatorios distribuidos\n",
    "# de forma normal.\n",
    "x = datos[0]\n",
    "y = datos[1]\n",
    "ruido = np.random.normal(size = (500,20))\n",
    "x = np.hstack((x, ruido))\n",
    "\n",
    "\n",
    "datos = pd.read_csv(\"datos_testing.csv\")\n",
    "x = datos.iloc[:, 1:].values\n",
    "y = datos[\"y\"].values\n",
    "\n",
    "poblacion = Poblacion(\n",
    "                n_individuos   = 50,\n",
    "                n_variables    = x.shape[1],\n",
    "                n_max          = 5,\n",
    "                n_max_estricto = False,    \n",
    "                n_min          = 1,\n",
    "                verbose        = False\n",
    "            )\n",
    "\n",
    "poblacion.optimizar(\n",
    "    x                  = x,\n",
    "    y                  = y,\n",
    "    cv                 = 3,\n",
    "    test_size          =  0.2,\n",
    "    tipo_modelo        = \"regresion\",\n",
    "    modelo             = \"randomforest\",\n",
    "    rf_n_estimators    = 50,\n",
    "    metrica            = \"neg_mean_squared_error\",\n",
    "    n_generaciones     = 50,\n",
    "    metodo_seleccion   = \"ruleta\",\n",
    "    metodo_cruce       = \"uniforme\",\n",
    "    elitismo           = 0.01,\n",
    "    prob_mut           = 0.1,\n",
    "    parada_temprana    = True,\n",
    "    rondas_parada      = 5,\n",
    "    tolerancia_parada  = 0.01,\n",
    "    verbose            = True,\n",
    "    verbose_nueva_generacion = False,\n",
    "    verbose_seleccion        = False,\n",
    "    verbose_cruce            = False,\n",
    "    verbose_mutacion         = False,\n",
    "    verbose_evaluacion       = False    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "         Población\n",
      "============================\n",
      "Número de individuos: 50\n",
      "Número máximo de predictores iniciales: 5\n",
      "Número mínimo de predictores iniciales: 1\n",
      "Evaluada: True\n",
      "Optimizada: True\n",
      "Métrica de evaluación: neg_mean_squared_error\n",
      "Modelo: randomforest\n",
      "Iteraciones optimización (generaciones): 11\n",
      "\n",
      "Información del mejor individuo:\n",
      "--------------------------------\n",
      "Secuencia: [ True  True  True  True  True  True  True False False False False  True\n",
      " False False False  True False False False False  True  True False  True\n",
      "  True False False False False  True]\n",
      "Índice predictores: [ 0  1  2  3  4  5  6 11 15 20 21 23 24 29]\n",
      "Fitness: -9.057578290046992\n",
      "\n",
      "Resultados tras optimizar:\n",
      "--------------------------\n",
      "Secuencia óptima: [ True  True  True  True  True  True  True False False False False  True\n",
      " False False False  True False False False False  True  True False  True\n",
      "  True False False False False  True]\n",
      "Índice predictores óptimos: [ 0  1  2  3  4  5  6 11 15 20 21 23 24 29]\n",
      "Valor óptimo métrica: -9.057578290046992\n",
      "Fitness óptimo: -9.057578290046992\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(poblacion)\n",
    "\n",
    "# Evolución de la optimización\n",
    "poblacion.plot_evolucion_fitness()\n",
    "\n",
    "# Frecuencia relativa selección predictores\n",
    "poblacion.plot_frecuencia_seleccion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />\n",
    "\n",
    "This work by Joaquín Amat Rodrigo is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de contenidos",
   "title_sidebar": "Tabla de contenidos",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
