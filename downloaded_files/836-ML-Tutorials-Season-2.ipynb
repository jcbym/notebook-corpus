{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c290928",
   "metadata": {},
   "source": [
    "# Challenge - Cancer Cell Identification\n",
    "\n",
    "![leukemia_cells](https://th.bing.com/th/id/OIP.ItCI5TcUURtqdBK3ANXbGQHaE1?pid=ImgDet&rs=1)\n",
    "\n",
    "## Background information\n",
    "\n",
    "Leukemia is the most common type of the pediatric cancer. After taking blood sample, it is possible to take microscopy images that can later be used for diagnostics. However, the current procedure requires constant professional supervision which is not time efficient.\n",
    "\n",
    "To make cancer cell identification process more time efficient, we are going to create a CNN model that will take example microscopy image and decide whether the cell is cancerous or non-cancerous.\n",
    "\n",
    "## Data\n",
    "\n",
    "Similarly to last week, this week's challenge will be done in the Kaggle InClass competition format. Data can be accessed via the following [link]().\n",
    "\n",
    "While training the model, use ```train``` folder. It should contain two folders - ```pos``` (cancerous cells) and ```neg``` (healthy cells). The background in the images has already been removed to make it simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb85415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying data path\n",
    "path = \"\"\n",
    "\n",
    "#Creating empty arrays for images and labels\n",
    "Images = []\n",
    "Labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1c990d",
   "metadata": {},
   "source": [
    "### Visualizing sample image\n",
    "\n",
    "Before moving to the following sections, it would be useful to first visualize a sample image just to get a rough idea of what preprocessing functions we might use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e959b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing sample image\n",
    "sample_path = ___\n",
    "#Reading image\n",
    "sample_img = ___\n",
    "#Visualizing image\n",
    "plt.imshow(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bacbfc",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "This step in our case involves reading, labelling data and then passing it through our custom OpenCV-based preprocessing function. There are variety of ways in which you could perform the last preprocessing step, but for starters, we are going to do the base minimum - color conversion, image resizing and standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b78519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing function\n",
    "def preprocessing(img):\n",
    "    \n",
    "    #Converting to grayscale\n",
    "    img = ___\n",
    "    \n",
    "    #Resizing images        \n",
    "    img = ___\n",
    "    \n",
    "    #Standardization        \n",
    "    img = ___\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedcd63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data\n",
    "def read_data(path):\n",
    "    Images = []\n",
    "    Labels = []\n",
    "    \n",
    "    for cat in os.listdir(path):\n",
    "        folder = os.path.join(path, cat)\n",
    "        for image_name in os.listdir(folder):\n",
    "            \n",
    "            #Write OpenCV function for reading image data\n",
    "            img = ___(os.path.join(folder, image_name))\n",
    "            \n",
    "            img = preprocessing(img)\n",
    "            \n",
    "            #Labelling data\n",
    "            if cat == 'pos':\n",
    "                Labels.append(1)\n",
    "            elif cat == 'neg':\n",
    "                Labels.append(0)\n",
    "            \n",
    "            Images.append(img)\n",
    "    \n",
    "    return Images, Labels\n",
    "\n",
    "Images, Labels = read_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7583a50c",
   "metadata": {},
   "source": [
    "Let's visualize how our defined preprocessing function changes previously discussed sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5449fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passing sample image through our preprocessing function\n",
    "sample_img = preprocessing(sample_img)\n",
    "plt.imshow(sample_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e757bbe2",
   "metadata": {},
   "source": [
    "### Splitting data\n",
    "\n",
    "As in the previous challenges, after performing basic preprocessing, we need to split our data into train-test datasets. On the other hand, we will also need to change the dimensions of our data as well as use the Keras function for converting our labels to categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data\n",
    "X_train, X_test, y_train, y_test = ___\n",
    "\n",
    "#Expanding dimensions in the -1 axis for X_train and X_test\n",
    "X_train = ___\n",
    "X_test = ___\n",
    "\n",
    "#Use Keras function for producing categorical labels\n",
    "y_train = ___\n",
    "y_test = ___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d209b40",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "For the model, we are going to build a LeNet structure CNN. Between each convolutional layers, there are pooling, batch normalization and dropout layers. The last two are used to omit overfitting our data. For the last layer, we flatten our network and pass through two dense layers last having a softmax activation function and two outputs (malignant - non-malignant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d783cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        #Feel free to add multiple convolutional layers\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #Flatten\n",
    "        \n",
    "        \n",
    "        #Write code for the last output layer\n",
    "\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a5a0f2",
   "metadata": {},
   "source": [
    "Train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa3e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model()\n",
    "\n",
    "#Choose an appropriate loss function\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = ___,\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "#Fitting model\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
