{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shubhambindal2017/Algorithms/blob/master/Age/Gender_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqDCogsbmJWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def network(feature_input, labels, mode):\n",
        "    \"\"\"\n",
        "    Creates a simple multi-layer convolutional neural network\n",
        "    \n",
        "    :param feature_input: \n",
        "    :param labels: \n",
        "    :param mode: \n",
        "    :return: \n",
        "    \"\"\"\n",
        "    filters = [32, 64, 128]\n",
        "    dropout_rates = [0.2, 0.4, 0.7]\n",
        "    conv_layer = feature_input\n",
        "\n",
        "    for filter_num, dropout_rate in zip(filters, dropout_rates):\n",
        "        conv_layer = conv_block(conv_layer, mode, filters=filter_num, dropout=dropout_rate)\n",
        "\n",
        "    # Dense Layer\n",
        "    pool4_flat = tf.layers.flatten(conv_layer)\n",
        "    dense = tf.layers.dense(inputs=pool4_flat, units=1024, activation=tf.nn.relu)\n",
        "    dropout = tf.layers.dropout(\n",
        "        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    # Age Head\n",
        "    age_dense = tf.layers.dense(inputs=dropout, units=1024)\n",
        "    age_logits = tf.layers.dense(inputs=age_dense, units=101)\n",
        "\n",
        "    # Gender head\n",
        "    gender_dense = tf.layers.dense(inputs=dropout, units=1024)\n",
        "    gender_logits = tf.layers.dense(inputs=gender_dense, units=2)\n",
        "\n",
        "    return age_logits, gender_logits\n",
        "\n",
        "\n",
        "def conv_block(input_layer, mode, filters=64, dropout=0.0):\n",
        "    conv = tf.layers.conv2d(\n",
        "        inputs=input_layer,\n",
        "        filters=filters,\n",
        "        kernel_size=[5, 5],\n",
        "        padding=\"same\",\n",
        "        activation=tf.nn.relu)\n",
        "    pool = tf.layers.max_pooling2d(inputs=conv, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    dropout_layer = tf.layers.dropout(\n",
        "        inputs=pool, rate=dropout, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    return dropout_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEMUz6D8mL0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def csv_record_input_fn(img_dir, filenames, img_size=150, repeat_count=-1, shuffle=True,\n",
        "                        batch_size=16, random=True):\n",
        "    \"\"\"\n",
        "    Creates tensorflow dataset iterator over records from :param{filenames}.\n",
        "    \n",
        "    :param img_dir: Path to directory of cropped images\n",
        "    :param filenames: array of file paths to load rows from\n",
        "    :param img_size: size of image\n",
        "    :param repeat_count: number of times for iterator to repeat\n",
        "    :param shuffle: flag for shuffling dataset\n",
        "    :param batch_size: number of examples in batch\n",
        "    :param random: flag for random distortion to the image\n",
        "    :return: Iterator of dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def parse_csv_row(line):\n",
        "        defaults = [[\"\"], [0], [0]]\n",
        "        filename, age, gender = tf.decode_csv(line, defaults)\n",
        "        filename = os.path.join(img_dir) + '/' + filename\n",
        "\n",
        "        image_string = tf.read_file(filename)\n",
        "        image = tf.image.decode_image(image_string, channels=3)\n",
        "        image = tf.cast(image, tf.float32)\n",
        "        image = tf.image.per_image_standardization(image)\n",
        "        image.set_shape([img_size, img_size, 3])\n",
        "\n",
        "        age = tf.cast(age, tf.int64)\n",
        "        gender = tf.cast(gender, tf.int64)\n",
        "\n",
        "        if random:\n",
        "            image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "        return {'image': image}, dict(gender=gender, age=age)\n",
        "\n",
        "    dataset = tf.data.TextLineDataset(filenames).skip(1)\n",
        "    dataset = dataset.map(parse_csv_row)\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=2000)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.repeat(repeat_count)\n",
        "    dataset = dataset.prefetch(batch_size * 10)\n",
        "\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    return iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOt5CbFnml__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "def model_fn(features, labels, mode, params):\n",
        "    \"\"\"\n",
        "    Creates model_fn for Tensorflow estimator. This function takes features and input, and\n",
        "    is responsible for the creation and processing of the Tensorflow graph for training, prediction and evaluation.\n",
        "    \n",
        "    Expected feature: {'image': image tensor }\n",
        "    \n",
        "    :param features: dictionary of input features\n",
        "    :param labels: dictionary of ground truth labels\n",
        "    :param mode: graph mode\n",
        "    :param params: params to configure model\n",
        "    :return: Estimator spec dependent on mode\n",
        "    \"\"\"\n",
        "    learning_rate = params['learning_rate']\n",
        "    image_input = features['image']\n",
        "\n",
        "    age_logits, logits = network(image_input, labels, mode)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return get_prediction_spec(age_logits, logits)\n",
        "\n",
        "    joint_loss = get_loss(age_logits, logits, labels)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return get_training_spec(learning_rate, joint_loss)\n",
        "\n",
        "    else:\n",
        "        return get_eval_spec(logits, age_logits, labels, joint_loss)\n",
        "\n",
        "\n",
        "def get_prediction_spec(age_logits, logits):\n",
        "    \"\"\"\n",
        "    Creates estimator spec for prediction\n",
        "    \n",
        "    :param age_logits: logits of age task\n",
        "    :param logits: logits of gender task\n",
        "    :return: Estimator spec \n",
        "    \"\"\"\n",
        "    predictions = {\n",
        "        \"classes\": tf.argmax(input=logits, axis=1),\n",
        "        \"age_class\": tf.argmax(input=age_logits, name='age_class', axis=1),\n",
        "        \"age_prob\": tf.nn.softmax(age_logits, name='age_prob'),\n",
        "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "    }\n",
        "    return tf.estimator.EstimatorSpec(mode=tf.estimator.ModeKeys.PREDICT, predictions=predictions)\n",
        "\n",
        "\n",
        "def get_loss(age_logits, gender_logits, labels):\n",
        "    \"\"\"\n",
        "    Creates joint loss function\n",
        "    \n",
        "    :param age_logits: logits of age\n",
        "    :param gender_logits: logits of gender task\n",
        "    :param labels: ground-truth labels of age and gender\n",
        "    :return: joint loss of age and gender\n",
        "    \"\"\"\n",
        "    gender_loss = tf.losses.sparse_softmax_cross_entropy(labels=labels['gender'], logits=gender_logits)\n",
        "    age_loss = tf.losses.sparse_softmax_cross_entropy(labels=labels['age'], logits=age_logits)\n",
        "    joint_loss = gender_loss + age_loss\n",
        "    return joint_loss\n",
        "\n",
        "\n",
        "def get_eval_spec(gender_logits, age_logits, labels, loss):\n",
        "    \"\"\"\n",
        "    Creates eval spec for tensorflow estimator\n",
        "    :param gender_logits: logits of gender task \n",
        "    :param age_logits: logits of age task\n",
        "    :param labels: ground truth labels for age and gender\n",
        "    :param loss: loss op\n",
        "    :return: Eval estimator spec\n",
        "    \"\"\"\n",
        "    eval_metric_ops = {\n",
        "        \"gender_accuracy\": tf.metrics.accuracy(\n",
        "            labels=labels['gender'], predictions=tf.argmax(gender_logits, axis=1)),\n",
        "        'age_accuracy': tf.metrics.accuracy(labels=labels['age'], predictions=tf.argmax(age_logits, axis=1)),\n",
        "        'age_precision': tf.metrics.sparse_precision_at_k(labels=labels['age'],\n",
        "                                                          predictions=age_logits, k=10)\n",
        "    }\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode=tf.estimator.ModeKeys.EVAL, loss=loss, eval_metric_ops=eval_metric_ops)\n",
        "\n",
        "\n",
        "def get_training_spec(learning_rate, joint_loss):\n",
        "    \"\"\"\n",
        "    Creates training estimator spec\n",
        "    \n",
        "    :param learning rate for optimizer\n",
        "    :param joint_loss: loss op\n",
        "    :return: Training estimator spec\n",
        "    \"\"\"\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "    gender_train_op = optimizer.minimize(\n",
        "        loss=joint_loss,\n",
        "        global_step=tf.train.get_global_step())\n",
        "    return tf.estimator.EstimatorSpec(mode=tf.estimator.ModeKeys.TRAIN, loss=joint_loss, train_op=gender_train_op)\n",
        "\n",
        "\n",
        "def serving_fn():\n",
        "    receiver_tensor = {\n",
        "        'image': tf.placeholder(dtype=tf.float32, shape=[None, None, None, 3])\n",
        "    }\n",
        "\n",
        "    features = {\n",
        "        'image': tf.image.resize_images(receiver_tensor['image'], [224, 224])\n",
        "    }\n",
        "\n",
        "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib5zxacnmvEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "dd3ae029-704d-4007-b298-81230342c730"
      },
      "source": [
        "\n",
        "! curl https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar -O\n",
        "! tar -xzvf imdb_crop.tar -o data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 6687M  100 6687M    0     0  18.4M      0  0:06:01  0:06:01 --:--:-- 16.6M\n",
            "\n",
            "gzip: stdin: not in gzip format\n",
            "tar: Child returned status 1\n",
            "tar: Error is not recoverable: exiting now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDoSNMwlnH5a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ccb49dee-2616-45af-cf63-86dfb307521b"
      },
      "source": [
        "! file imdb_crop.tar"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imdb_crop.tar: POSIX tar archive (GNU)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyldSJOVpCzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e0afde2e-5aa4-4f5c-f8f9-07aa14e3bc4b"
      },
      "source": [
        "! sudo tar -xzvf imdb_crop.tar"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "gzip: stdin: not in gzip format\n",
            "tar: Child returned status 1\n",
            "tar: Error is not recoverable: exiting now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19qIQubEpRPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "5e19e5f9-67ac-4a82-cf72-7a81f8a49d37"
      },
      "source": [
        "! apt-get install file"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libmagic-mgc libmagic1\n",
            "The following NEW packages will be installed:\n",
            "  file libmagic-mgc libmagic1\n",
            "0 upgraded, 3 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 275 kB of archives.\n",
            "After this operation, 5,294 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.2 [184 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.2 [68.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.2 [22.1 kB]\n",
            "Fetched 275 kB in 1s (201 kB/s)\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 131183 files and directories currently installed.)\n",
            "Preparing to unpack .../libmagic-mgc_1%3a5.32-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../libmagic1_1%3a5.32-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.2) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../file_1%3a5.32-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.2) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.2) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up file (1:5.32-2ubuntu0.2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtCdLPH0p0zq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! tar -xvf imdb_crop.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY5v-EsWqQwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}