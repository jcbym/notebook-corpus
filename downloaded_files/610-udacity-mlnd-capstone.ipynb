{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity MLND Capstone Project\n",
    "## \"Determination of studentsâ€™ interaction patterns with an intelligent tutoring system and study of their correlation with successful learning\"\n",
    "### Step 3 (comparison of learning rates between clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_parameter</th>\n",
       "      <th>difficulty_parameter</th>\n",
       "      <th>number of attempts</th>\n",
       "      <th>number of incorrect attempts</th>\n",
       "      <th>cluster_index</th>\n",
       "      <th>frac_incorrect_atts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.172964</td>\n",
       "      <td>0.577597</td>\n",
       "      <td>303</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.011161</td>\n",
       "      <td>0.623980</td>\n",
       "      <td>295</td>\n",
       "      <td>187.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.633898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.084896</td>\n",
       "      <td>0.459276</td>\n",
       "      <td>529</td>\n",
       "      <td>269.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.508507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.459728</td>\n",
       "      <td>1286</td>\n",
       "      <td>556.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.432348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.066242</td>\n",
       "      <td>0.486793</td>\n",
       "      <td>821</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.449452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_parameter  difficulty_parameter  number of attempts  \\\n",
       "0            0.172964              0.577597                 303   \n",
       "1           -0.011161              0.623980                 295   \n",
       "2           -0.084896              0.459276                 529   \n",
       "3            0.044947              0.459728                1286   \n",
       "4            0.066242              0.486793                 821   \n",
       "\n",
       "   number of incorrect attempts  cluster_index  frac_incorrect_atts  \n",
       "0                         146.0              1             0.481848  \n",
       "1                         187.0              5             0.633898  \n",
       "2                         269.0              6             0.508507  \n",
       "3                         556.0              2             0.432348  \n",
       "4                         369.0              1             0.449452  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_learning = pd.read_csv('student_learning_final.csv')\n",
    "stud_learning.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "cluster_index = pd.read_csv(\"cluster_index.csv\", header=None)\n",
    "stud_learning['cluster_index'] = cluster_index[1]\n",
    "stud_learning['frac_incorrect_atts'] = stud_learning['number of incorrect attempts'] / stud_learning['number of attempts']\n",
    "stud_learning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['learning_parameter', 'difficulty_parameter', 'number of attempts',\n",
       "       'number of incorrect attempts', 'cluster_index', 'frac_incorrect_atts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_learning.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sess</th>\n",
       "      <th>num_days</th>\n",
       "      <th>num_probs</th>\n",
       "      <th>num_atts</th>\n",
       "      <th>num_hints</th>\n",
       "      <th>frac_corr_atts</th>\n",
       "      <th>frac_3s_atts</th>\n",
       "      <th>frac_1s_hints</th>\n",
       "      <th>time_atts</th>\n",
       "      <th>time_hints</th>\n",
       "      <th>max_probl_views</th>\n",
       "      <th>max_atts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>303</td>\n",
       "      <td>213</td>\n",
       "      <td>0.518152</td>\n",
       "      <td>0.184818</td>\n",
       "      <td>0.286385</td>\n",
       "      <td>9577.000</td>\n",
       "      <td>3660.999</td>\n",
       "      <td>1.101266</td>\n",
       "      <td>3.835443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>295</td>\n",
       "      <td>111</td>\n",
       "      <td>0.366102</td>\n",
       "      <td>0.071186</td>\n",
       "      <td>0.063063</td>\n",
       "      <td>10409.000</td>\n",
       "      <td>2570.000</td>\n",
       "      <td>1.610169</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>529</td>\n",
       "      <td>180</td>\n",
       "      <td>0.491493</td>\n",
       "      <td>0.102079</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>14850.000</td>\n",
       "      <td>2295.000</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>3.526667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>457</td>\n",
       "      <td>14</td>\n",
       "      <td>215</td>\n",
       "      <td>1288</td>\n",
       "      <td>687</td>\n",
       "      <td>0.566770</td>\n",
       "      <td>0.148292</td>\n",
       "      <td>0.066958</td>\n",
       "      <td>25290.001</td>\n",
       "      <td>7743.000</td>\n",
       "      <td>2.148837</td>\n",
       "      <td>5.990698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>267</td>\n",
       "      <td>13</td>\n",
       "      <td>166</td>\n",
       "      <td>821</td>\n",
       "      <td>602</td>\n",
       "      <td>0.550548</td>\n",
       "      <td>0.068210</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>20504.667</td>\n",
       "      <td>5347.334</td>\n",
       "      <td>1.660606</td>\n",
       "      <td>4.945783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_sess  num_days  num_probs  num_atts  num_hints  frac_corr_atts  \\\n",
       "0        89         9         79       303        213        0.518152   \n",
       "1        86         7         59       295        111        0.366102   \n",
       "2       181        10        150       529        180        0.491493   \n",
       "3       457        14        215      1288        687        0.566770   \n",
       "4       267        13        166       821        602        0.550548   \n",
       "\n",
       "   frac_3s_atts  frac_1s_hints  time_atts  time_hints  max_probl_views  \\\n",
       "0      0.184818       0.286385   9577.000    3660.999         1.101266   \n",
       "1      0.071186       0.063063  10409.000    2570.000         1.610169   \n",
       "2      0.102079       0.077778  14850.000    2295.000         1.240000   \n",
       "3      0.148292       0.066958  25290.001    7743.000         2.148837   \n",
       "4      0.068210       0.267442  20504.667    5347.334         1.660606   \n",
       "\n",
       "   max_atts  \n",
       "0  3.835443  \n",
       "1  5.000000  \n",
       "2  3.526667  \n",
       "3  5.990698  \n",
       "4  4.945783  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data = pd.read_hdf('stud_data.hdf','test')\n",
    "stud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sess</th>\n",
       "      <th>num_days</th>\n",
       "      <th>num_probs</th>\n",
       "      <th>num_atts</th>\n",
       "      <th>num_hints</th>\n",
       "      <th>frac_corr_atts</th>\n",
       "      <th>frac_3s_atts</th>\n",
       "      <th>frac_1s_hints</th>\n",
       "      <th>time_atts</th>\n",
       "      <th>time_hints</th>\n",
       "      <th>max_probl_views</th>\n",
       "      <th>max_atts</th>\n",
       "      <th>learning_parameter</th>\n",
       "      <th>difficulty_parameter</th>\n",
       "      <th>number of attempts</th>\n",
       "      <th>number of incorrect attempts</th>\n",
       "      <th>cluster_index</th>\n",
       "      <th>frac_incorrect_atts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>303</td>\n",
       "      <td>213</td>\n",
       "      <td>0.518152</td>\n",
       "      <td>0.184818</td>\n",
       "      <td>0.286385</td>\n",
       "      <td>9577.000</td>\n",
       "      <td>3660.999</td>\n",
       "      <td>1.101266</td>\n",
       "      <td>3.835443</td>\n",
       "      <td>0.172964</td>\n",
       "      <td>0.577597</td>\n",
       "      <td>303</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>295</td>\n",
       "      <td>111</td>\n",
       "      <td>0.366102</td>\n",
       "      <td>0.071186</td>\n",
       "      <td>0.063063</td>\n",
       "      <td>10409.000</td>\n",
       "      <td>2570.000</td>\n",
       "      <td>1.610169</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.011161</td>\n",
       "      <td>0.623980</td>\n",
       "      <td>295</td>\n",
       "      <td>187.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.633898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>529</td>\n",
       "      <td>180</td>\n",
       "      <td>0.491493</td>\n",
       "      <td>0.102079</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>14850.000</td>\n",
       "      <td>2295.000</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>3.526667</td>\n",
       "      <td>-0.084896</td>\n",
       "      <td>0.459276</td>\n",
       "      <td>529</td>\n",
       "      <td>269.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.508507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>457</td>\n",
       "      <td>14</td>\n",
       "      <td>215</td>\n",
       "      <td>1288</td>\n",
       "      <td>687</td>\n",
       "      <td>0.566770</td>\n",
       "      <td>0.148292</td>\n",
       "      <td>0.066958</td>\n",
       "      <td>25290.001</td>\n",
       "      <td>7743.000</td>\n",
       "      <td>2.148837</td>\n",
       "      <td>5.990698</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.459728</td>\n",
       "      <td>1286</td>\n",
       "      <td>556.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.432348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>267</td>\n",
       "      <td>13</td>\n",
       "      <td>166</td>\n",
       "      <td>821</td>\n",
       "      <td>602</td>\n",
       "      <td>0.550548</td>\n",
       "      <td>0.068210</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>20504.667</td>\n",
       "      <td>5347.334</td>\n",
       "      <td>1.660606</td>\n",
       "      <td>4.945783</td>\n",
       "      <td>0.066242</td>\n",
       "      <td>0.486793</td>\n",
       "      <td>821</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.449452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_sess  num_days  num_probs  num_atts  num_hints  frac_corr_atts  \\\n",
       "0        89         9         79       303        213        0.518152   \n",
       "1        86         7         59       295        111        0.366102   \n",
       "2       181        10        150       529        180        0.491493   \n",
       "3       457        14        215      1288        687        0.566770   \n",
       "4       267        13        166       821        602        0.550548   \n",
       "\n",
       "   frac_3s_atts  frac_1s_hints  time_atts  time_hints  max_probl_views  \\\n",
       "0      0.184818       0.286385   9577.000    3660.999         1.101266   \n",
       "1      0.071186       0.063063  10409.000    2570.000         1.610169   \n",
       "2      0.102079       0.077778  14850.000    2295.000         1.240000   \n",
       "3      0.148292       0.066958  25290.001    7743.000         2.148837   \n",
       "4      0.068210       0.267442  20504.667    5347.334         1.660606   \n",
       "\n",
       "   max_atts  learning_parameter  difficulty_parameter  number of attempts  \\\n",
       "0  3.835443            0.172964              0.577597                 303   \n",
       "1  5.000000           -0.011161              0.623980                 295   \n",
       "2  3.526667           -0.084896              0.459276                 529   \n",
       "3  5.990698            0.044947              0.459728                1286   \n",
       "4  4.945783            0.066242              0.486793                 821   \n",
       "\n",
       "   number of incorrect attempts  cluster_index  frac_incorrect_atts  \n",
       "0                         146.0              1             0.481848  \n",
       "1                         187.0              5             0.633898  \n",
       "2                         269.0              6             0.508507  \n",
       "3                         556.0              2             0.432348  \n",
       "4                         369.0              1             0.449452  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data = stud_data.join(stud_learning)\n",
    "stud_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine what clusters more successful in learning in terms of fraction of correct attempts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sess</th>\n",
       "      <th>num_days</th>\n",
       "      <th>num_probs</th>\n",
       "      <th>num_atts</th>\n",
       "      <th>num_hints</th>\n",
       "      <th>frac_corr_atts</th>\n",
       "      <th>frac_3s_atts</th>\n",
       "      <th>frac_1s_hints</th>\n",
       "      <th>time_atts</th>\n",
       "      <th>time_hints</th>\n",
       "      <th>max_probl_views</th>\n",
       "      <th>max_atts</th>\n",
       "      <th>learning_parameter</th>\n",
       "      <th>difficulty_parameter</th>\n",
       "      <th>number of attempts</th>\n",
       "      <th>number of incorrect attempts</th>\n",
       "      <th>frac_incorrect_atts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157381</td>\n",
       "      <td>9790</td>\n",
       "      <td>119787</td>\n",
       "      <td>463356</td>\n",
       "      <td>319334</td>\n",
       "      <td>746.328247</td>\n",
       "      <td>143.134751</td>\n",
       "      <td>320.395430</td>\n",
       "      <td>1.209619e+07</td>\n",
       "      <td>3310766.636</td>\n",
       "      <td>1700.710013</td>\n",
       "      <td>5073.330503</td>\n",
       "      <td>533.615744</td>\n",
       "      <td>590.950677</td>\n",
       "      <td>463202</td>\n",
       "      <td>197852.0</td>\n",
       "      <td>0.427140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22030</td>\n",
       "      <td>1535</td>\n",
       "      <td>17766</td>\n",
       "      <td>72336</td>\n",
       "      <td>33803</td>\n",
       "      <td>203.188547</td>\n",
       "      <td>91.172770</td>\n",
       "      <td>13.541033</td>\n",
       "      <td>1.645484e+06</td>\n",
       "      <td>459433.500</td>\n",
       "      <td>466.191313</td>\n",
       "      <td>1403.399037</td>\n",
       "      <td>426.118912</td>\n",
       "      <td>218.872902</td>\n",
       "      <td>71890</td>\n",
       "      <td>36290.0</td>\n",
       "      <td>0.504799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16010</td>\n",
       "      <td>1876</td>\n",
       "      <td>14923</td>\n",
       "      <td>33757</td>\n",
       "      <td>2842</td>\n",
       "      <td>646.793540</td>\n",
       "      <td>12.846483</td>\n",
       "      <td>2.963157</td>\n",
       "      <td>1.822630e+06</td>\n",
       "      <td>45694.000</td>\n",
       "      <td>1209.648207</td>\n",
       "      <td>3165.984896</td>\n",
       "      <td>2763.923125</td>\n",
       "      <td>546.419214</td>\n",
       "      <td>33752</td>\n",
       "      <td>12311.0</td>\n",
       "      <td>0.364749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36928</td>\n",
       "      <td>5409</td>\n",
       "      <td>32754</td>\n",
       "      <td>125483</td>\n",
       "      <td>52632</td>\n",
       "      <td>1256.070663</td>\n",
       "      <td>41.842531</td>\n",
       "      <td>26.817449</td>\n",
       "      <td>5.753900e+06</td>\n",
       "      <td>1572946.500</td>\n",
       "      <td>2775.185284</td>\n",
       "      <td>9999.657523</td>\n",
       "      <td>1684.809382</td>\n",
       "      <td>1333.332278</td>\n",
       "      <td>125470</td>\n",
       "      <td>63394.0</td>\n",
       "      <td>0.505252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>121977</td>\n",
       "      <td>12125</td>\n",
       "      <td>108264</td>\n",
       "      <td>372790</td>\n",
       "      <td>134056</td>\n",
       "      <td>1088.841940</td>\n",
       "      <td>61.644813</td>\n",
       "      <td>46.097252</td>\n",
       "      <td>1.566643e+07</td>\n",
       "      <td>3317271.000</td>\n",
       "      <td>2253.456633</td>\n",
       "      <td>6800.545131</td>\n",
       "      <td>138.585166</td>\n",
       "      <td>891.014094</td>\n",
       "      <td>372649</td>\n",
       "      <td>171703.0</td>\n",
       "      <td>0.460763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>329574</td>\n",
       "      <td>21053</td>\n",
       "      <td>265370</td>\n",
       "      <td>848789</td>\n",
       "      <td>258225</td>\n",
       "      <td>1112.744922</td>\n",
       "      <td>68.669698</td>\n",
       "      <td>62.199569</td>\n",
       "      <td>3.145390e+07</td>\n",
       "      <td>4868593.500</td>\n",
       "      <td>2292.982438</td>\n",
       "      <td>5939.409007</td>\n",
       "      <td>-11.449252</td>\n",
       "      <td>711.539726</td>\n",
       "      <td>847416</td>\n",
       "      <td>334224.0</td>\n",
       "      <td>0.394404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               num_sess  num_days  num_probs  num_atts  num_hints  \\\n",
       "cluster_index                                                       \n",
       "1                157381      9790     119787    463356     319334   \n",
       "2                 22030      1535      17766     72336      33803   \n",
       "3                 16010      1876      14923     33757       2842   \n",
       "4                 36928      5409      32754    125483      52632   \n",
       "5                121977     12125     108264    372790     134056   \n",
       "6                329574     21053     265370    848789     258225   \n",
       "\n",
       "               frac_corr_atts  frac_3s_atts  frac_1s_hints     time_atts  \\\n",
       "cluster_index                                                              \n",
       "1                  746.328247    143.134751     320.395430  1.209619e+07   \n",
       "2                  203.188547     91.172770      13.541033  1.645484e+06   \n",
       "3                  646.793540     12.846483       2.963157  1.822630e+06   \n",
       "4                 1256.070663     41.842531      26.817449  5.753900e+06   \n",
       "5                 1088.841940     61.644813      46.097252  1.566643e+07   \n",
       "6                 1112.744922     68.669698      62.199569  3.145390e+07   \n",
       "\n",
       "                time_hints  max_probl_views     max_atts  learning_parameter  \\\n",
       "cluster_index                                                                  \n",
       "1              3310766.636      1700.710013  5073.330503          533.615744   \n",
       "2               459433.500       466.191313  1403.399037          426.118912   \n",
       "3                45694.000      1209.648207  3165.984896         2763.923125   \n",
       "4              1572946.500      2775.185284  9999.657523         1684.809382   \n",
       "5              3317271.000      2253.456633  6800.545131          138.585166   \n",
       "6              4868593.500      2292.982438  5939.409007          -11.449252   \n",
       "\n",
       "               difficulty_parameter  number of attempts  \\\n",
       "cluster_index                                             \n",
       "1                        590.950677              463202   \n",
       "2                        218.872902               71890   \n",
       "3                        546.419214               33752   \n",
       "4                       1333.332278              125470   \n",
       "5                        891.014094              372649   \n",
       "6                        711.539726              847416   \n",
       "\n",
       "               number of incorrect attempts  frac_incorrect_atts  \n",
       "cluster_index                                                     \n",
       "1                                  197852.0             0.427140  \n",
       "2                                   36290.0             0.504799  \n",
       "3                                   12311.0             0.364749  \n",
       "4                                   63394.0             0.505252  \n",
       "5                                  171703.0             0.460763  \n",
       "6                                  334224.0             0.394404  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data_sum = stud_data.groupby('cluster_index').agg(np.sum).copy()\n",
    "stud_data_sum['frac_incorrect_atts'] = stud_data_sum['number of incorrect attempts'] / stud_data_sum['number of attempts']\n",
    "stud_data_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, group 3 has the smallest fraction of incorrect attempts (~36.5%). Also, not surprisingly, `'frac_incorrect_atts'` in group 1 (with large `'frac_1s_hints'`) is significantly (`p-value = 1.75e-8`) smaller than in group 2 (with small `'frac_1s_hints'` and large `'frac_3s_atts'`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-5.729328888101044, pvalue=1.7528523291077249e-08)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = np.array(stud_data[stud_data['cluster_index'] == 1]['frac_incorrect_atts'])\n",
    "arr2 = np.array(stud_data[stud_data['cluster_index'] == 2]['frac_incorrect_atts'])\n",
    "arr1 = arr1[~np.isnan(arr1)]\n",
    "arr2 = arr2[~np.isnan(arr2)]\n",
    "stats.ttest_ind(arr1,arr2, equal_var = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the difference of `'frac_incorrect_atts'`  between students with \"gaming\" and non-gaming behaviour is **not significant** (`p-value = 0.83`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.20874210756084033, pvalue=0.83466558756318543)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_gam = np.array(stud_data[stud_data['cluster_index'] <= 2]['frac_incorrect_atts'])\n",
    "arr_nongam = np.array(stud_data[stud_data['cluster_index'] > 2]['frac_incorrect_atts'])\n",
    "arr_gam = arr_gam[~np.isnan(arr_gam)]\n",
    "arr_nongam = arr_nongam[~np.isnan(arr_nongam)]\n",
    "stats.ttest_ind(arr_gam,arr_nongam, equal_var = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably, group 5 (students with medium `'num_sess'` and `'num_probs'`) has **significantly smaller** `'frac_incorrect_atts'` than group 4 (students with small `'num_sess'` and `'num_probs'`) but **significantly smaller** `'frac_incorrect_atts'` than in group 6 (students with large `'num_sess'` and `'num_probs'`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-10.153852159747615, pvalue=5.9895165350814053e-24)\n",
      "Ttest_indResult(statistic=-16.552377685289887, pvalue=1.8740538669177719e-59)\n"
     ]
    }
   ],
   "source": [
    "arr4 = np.array(stud_data[stud_data['cluster_index'] == 4]['frac_incorrect_atts'])\n",
    "arr5 = np.array(stud_data[stud_data['cluster_index'] == 5]['frac_incorrect_atts'])\n",
    "arr6 = np.array(stud_data[stud_data['cluster_index'] == 6]['frac_incorrect_atts'])\n",
    "arr4 = arr4[~np.isnan(arr4)]\n",
    "arr5 = arr5[~np.isnan(arr5)]\n",
    "arr6 = arr6[~np.isnan(arr6)]\n",
    "print(stats.ttest_ind(arr5,arr4, equal_var = False))\n",
    "print(stats.ttest_ind(arr6,arr5, equal_var = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, for students with non-gaming behaviour `'frac_incorrect_atts'` **steadily decreases with learning experience**.\n",
    "\n",
    "Other differences between groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sess</th>\n",
       "      <th>num_days</th>\n",
       "      <th>num_probs</th>\n",
       "      <th>num_atts</th>\n",
       "      <th>num_hints</th>\n",
       "      <th>frac_corr_atts</th>\n",
       "      <th>frac_3s_atts</th>\n",
       "      <th>frac_1s_hints</th>\n",
       "      <th>time_atts</th>\n",
       "      <th>time_hints</th>\n",
       "      <th>max_probl_views</th>\n",
       "      <th>max_atts</th>\n",
       "      <th>learning_parameter</th>\n",
       "      <th>difficulty_parameter</th>\n",
       "      <th>number of attempts</th>\n",
       "      <th>number of incorrect attempts</th>\n",
       "      <th>frac_incorrect_atts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121.623648</td>\n",
       "      <td>7.565688</td>\n",
       "      <td>92.571097</td>\n",
       "      <td>358.080371</td>\n",
       "      <td>246.780526</td>\n",
       "      <td>0.576761</td>\n",
       "      <td>0.110614</td>\n",
       "      <td>0.247601</td>\n",
       "      <td>9347.902114</td>\n",
       "      <td>2558.552269</td>\n",
       "      <td>1.314304</td>\n",
       "      <td>3.920657</td>\n",
       "      <td>0.412377</td>\n",
       "      <td>0.456685</td>\n",
       "      <td>357.961360</td>\n",
       "      <td>152.899536</td>\n",
       "      <td>0.421592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.342711</td>\n",
       "      <td>3.925831</td>\n",
       "      <td>45.437340</td>\n",
       "      <td>185.002558</td>\n",
       "      <td>86.452685</td>\n",
       "      <td>0.519664</td>\n",
       "      <td>0.233178</td>\n",
       "      <td>0.034632</td>\n",
       "      <td>4208.397711</td>\n",
       "      <td>1175.021739</td>\n",
       "      <td>1.192305</td>\n",
       "      <td>3.589256</td>\n",
       "      <td>1.089818</td>\n",
       "      <td>0.559777</td>\n",
       "      <td>183.861893</td>\n",
       "      <td>92.813299</td>\n",
       "      <td>0.479562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.436429</td>\n",
       "      <td>1.691614</td>\n",
       "      <td>13.456267</td>\n",
       "      <td>30.439134</td>\n",
       "      <td>2.562669</td>\n",
       "      <td>0.583222</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>1643.489630</td>\n",
       "      <td>41.202885</td>\n",
       "      <td>1.090756</td>\n",
       "      <td>2.854811</td>\n",
       "      <td>2.492266</td>\n",
       "      <td>0.492713</td>\n",
       "      <td>30.434626</td>\n",
       "      <td>11.100992</td>\n",
       "      <td>0.402156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.246903</td>\n",
       "      <td>2.233278</td>\n",
       "      <td>13.523534</td>\n",
       "      <td>51.809661</td>\n",
       "      <td>21.730801</td>\n",
       "      <td>0.518609</td>\n",
       "      <td>0.017276</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>2375.681462</td>\n",
       "      <td>649.441164</td>\n",
       "      <td>1.145824</td>\n",
       "      <td>4.128678</td>\n",
       "      <td>0.695627</td>\n",
       "      <td>0.550509</td>\n",
       "      <td>51.804294</td>\n",
       "      <td>26.174236</td>\n",
       "      <td>0.479627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62.648690</td>\n",
       "      <td>6.227530</td>\n",
       "      <td>55.605547</td>\n",
       "      <td>191.468927</td>\n",
       "      <td>68.852594</td>\n",
       "      <td>0.559241</td>\n",
       "      <td>0.031661</td>\n",
       "      <td>0.023676</td>\n",
       "      <td>8046.446327</td>\n",
       "      <td>1703.785824</td>\n",
       "      <td>1.157399</td>\n",
       "      <td>3.492833</td>\n",
       "      <td>0.071179</td>\n",
       "      <td>0.457634</td>\n",
       "      <td>191.396507</td>\n",
       "      <td>88.188495</td>\n",
       "      <td>0.440491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>181.383599</td>\n",
       "      <td>11.586681</td>\n",
       "      <td>146.048431</td>\n",
       "      <td>467.137589</td>\n",
       "      <td>142.116125</td>\n",
       "      <td>0.612408</td>\n",
       "      <td>0.037793</td>\n",
       "      <td>0.034232</td>\n",
       "      <td>17310.899564</td>\n",
       "      <td>2679.468079</td>\n",
       "      <td>1.261961</td>\n",
       "      <td>3.268800</td>\n",
       "      <td>-0.006301</td>\n",
       "      <td>0.391601</td>\n",
       "      <td>466.381948</td>\n",
       "      <td>183.942763</td>\n",
       "      <td>0.386384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 num_sess   num_days   num_probs    num_atts   num_hints  \\\n",
       "cluster_index                                                              \n",
       "1              121.623648   7.565688   92.571097  358.080371  246.780526   \n",
       "2               56.342711   3.925831   45.437340  185.002558   86.452685   \n",
       "3               14.436429   1.691614   13.456267   30.439134    2.562669   \n",
       "4               15.246903   2.233278   13.523534   51.809661   21.730801   \n",
       "5               62.648690   6.227530   55.605547  191.468927   68.852594   \n",
       "6              181.383599  11.586681  146.048431  467.137589  142.116125   \n",
       "\n",
       "               frac_corr_atts  frac_3s_atts  frac_1s_hints     time_atts  \\\n",
       "cluster_index                                                              \n",
       "1                    0.576761      0.110614       0.247601   9347.902114   \n",
       "2                    0.519664      0.233178       0.034632   4208.397711   \n",
       "3                    0.583222      0.011584       0.002672   1643.489630   \n",
       "4                    0.518609      0.017276       0.011072   2375.681462   \n",
       "5                    0.559241      0.031661       0.023676   8046.446327   \n",
       "6                    0.612408      0.037793       0.034232  17310.899564   \n",
       "\n",
       "                time_hints  max_probl_views  max_atts  learning_parameter  \\\n",
       "cluster_index                                                               \n",
       "1              2558.552269         1.314304  3.920657            0.412377   \n",
       "2              1175.021739         1.192305  3.589256            1.089818   \n",
       "3                41.202885         1.090756  2.854811            2.492266   \n",
       "4               649.441164         1.145824  4.128678            0.695627   \n",
       "5              1703.785824         1.157399  3.492833            0.071179   \n",
       "6              2679.468079         1.261961  3.268800           -0.006301   \n",
       "\n",
       "               difficulty_parameter  number of attempts  \\\n",
       "cluster_index                                             \n",
       "1                          0.456685          357.961360   \n",
       "2                          0.559777          183.861893   \n",
       "3                          0.492713           30.434626   \n",
       "4                          0.550509           51.804294   \n",
       "5                          0.457634          191.396507   \n",
       "6                          0.391601          466.381948   \n",
       "\n",
       "               number of incorrect attempts  frac_incorrect_atts  \n",
       "cluster_index                                                     \n",
       "1                                152.899536             0.421592  \n",
       "2                                 92.813299             0.479562  \n",
       "3                                 11.100992             0.402156  \n",
       "4                                 26.174236             0.479627  \n",
       "5                                 88.188495             0.440491  \n",
       "6                                183.942763             0.386384  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data_mean = stud_data.groupby('cluster_index').agg(np.mean).copy()\n",
    "stud_data_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant increase of `'frac_3s_atts'` for groups 4-5-6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=16.462911716329312, pvalue=5.0996180356250809e-59)\n",
      "Ttest_indResult(statistic=6.2931050213512316, pvalue=3.4739480257167589e-10)\n"
     ]
    }
   ],
   "source": [
    "arr4 = np.array(stud_data[stud_data['cluster_index'] == 4]['frac_3s_atts'])\n",
    "arr5 = np.array(stud_data[stud_data['cluster_index'] == 5]['frac_3s_atts'])\n",
    "arr6 = np.array(stud_data[stud_data['cluster_index'] == 6]['frac_3s_atts'])\n",
    "arr4 = arr4[~np.isnan(arr4)]\n",
    "arr5 = arr5[~np.isnan(arr5)]\n",
    "arr6 = arr6[~np.isnan(arr6)]\n",
    "print(stats.ttest_ind(arr5,arr4, equal_var = False))\n",
    "print(stats.ttest_ind(arr6,arr5, equal_var = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ", a significant increase of 'frac_1s_hints' for groups 4-5-6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=13.252648797032892, pvalue=3.4429894092371465e-39)\n",
      "Ttest_indResult(statistic=9.0112499269936261, pvalue=3.2062949164427214e-19)\n"
     ]
    }
   ],
   "source": [
    "arr4 = np.array(stud_data[stud_data['cluster_index'] == 4]['frac_1s_hints'])\n",
    "arr5 = np.array(stud_data[stud_data['cluster_index'] == 5]['frac_1s_hints'])\n",
    "arr6 = np.array(stud_data[stud_data['cluster_index'] == 6]['frac_1s_hints'])\n",
    "arr4 = arr4[~np.isnan(arr4)]\n",
    "arr5 = arr5[~np.isnan(arr5)]\n",
    "arr6 = arr6[~np.isnan(arr6)]\n",
    "print(stats.ttest_ind(arr5,arr4, equal_var = False))\n",
    "print(stats.ttest_ind(arr6,arr5, equal_var = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ", and a significant decrease of 'max_atts' for groups 4-5-6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-11.66474597325503, pvalue=6.3441131333456629e-31)\n",
      "Ttest_indResult(statistic=-5.813163173033753, pvalue=6.640246772802727e-09)\n"
     ]
    }
   ],
   "source": [
    "arr4 = np.array(stud_data[stud_data['cluster_index'] == 4]['max_atts'])\n",
    "arr5 = np.array(stud_data[stud_data['cluster_index'] == 5]['max_atts'])\n",
    "arr6 = np.array(stud_data[stud_data['cluster_index'] == 6]['max_atts'])\n",
    "arr4 = arr4[~np.isnan(arr4)]\n",
    "arr5 = arr5[~np.isnan(arr5)]\n",
    "arr6 = arr6[~np.isnan(arr6)]\n",
    "print(stats.ttest_ind(arr5,arr4, equal_var = False))\n",
    "print(stats.ttest_ind(arr6,arr5, equal_var = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase of `max_probl_views` is significant between groups 5 and 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=1.625027093046111, pvalue=0.1042377703597938)\n",
      "Ttest_indResult(statistic=15.833103986243177, pvalue=1.9284145705097942e-54)\n"
     ]
    }
   ],
   "source": [
    "arr4 = np.array(stud_data[stud_data['cluster_index'] == 4]['max_probl_views'])\n",
    "arr5 = np.array(stud_data[stud_data['cluster_index'] == 5]['max_probl_views'])\n",
    "arr6 = np.array(stud_data[stud_data['cluster_index'] == 6]['max_probl_views'])\n",
    "arr4 = arr4[~np.isnan(arr4)]\n",
    "arr5 = arr5[~np.isnan(arr5)]\n",
    "arr6 = arr6[~np.isnan(arr6)]\n",
    "print(stats.ttest_ind(arr5,arr4, equal_var = False))\n",
    "print(stats.ttest_ind(arr6,arr5, equal_var = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, increasing \"experience\" (in group sequence 4-5-6) also leads to:\n",
    "- increase of \"gaming\" fractions `'frac_3s_atts'` and `'frac_1s_hints'`;\n",
    "- increase of `'max_probl_views'` (so the problems are viewed in more details);\n",
    "- decrease of `'max_atts'` (so there are smaller attempts per problem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate mean leaning parameter and its dispersion for each group:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because learning parameter is determined from the fit of the learning curve, it is essential to analyse learning curves starting with some reasonable minimum number of attempts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, there is a very large spread in learning parameters: between -9.97 and 24.9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8980.000000\n",
       "mean        0.616437\n",
       "std         3.188777\n",
       "min        -9.965780\n",
       "25%        -0.054653\n",
       "50%         0.063602\n",
       "75%         0.218565\n",
       "max        24.908305\n",
       "Name: learning_parameter, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data['learning_parameter'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, for ~1/3 of students learning parameter is **negative**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3179"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data[stud_data['learning_parameter'] < 0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What best describes \"negative learners\"? First, look on extreme examples. Take \"extreme negative learners\" (students with learning rate < -0.5, and compare them with \"extreme positive learnens\" (students with learning rate > 0.5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sess</th>\n",
       "      <th>num_days</th>\n",
       "      <th>num_probs</th>\n",
       "      <th>num_atts</th>\n",
       "      <th>num_hints</th>\n",
       "      <th>frac_corr_atts</th>\n",
       "      <th>frac_3s_atts</th>\n",
       "      <th>frac_1s_hints</th>\n",
       "      <th>time_atts</th>\n",
       "      <th>time_hints</th>\n",
       "      <th>max_probl_views</th>\n",
       "      <th>max_atts</th>\n",
       "      <th>learning_parameter</th>\n",
       "      <th>difficulty_parameter</th>\n",
       "      <th>number of attempts</th>\n",
       "      <th>number of incorrect attempts</th>\n",
       "      <th>cluster_index</th>\n",
       "      <th>frac_incorrect_atts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.708075</td>\n",
       "      <td>2.720497</td>\n",
       "      <td>32.254658</td>\n",
       "      <td>51.360248</td>\n",
       "      <td>14.006211</td>\n",
       "      <td>0.688847</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.050475</td>\n",
       "      <td>3113.850932</td>\n",
       "      <td>371.161491</td>\n",
       "      <td>1.092419</td>\n",
       "      <td>2.245839</td>\n",
       "      <td>-1.227948</td>\n",
       "      <td>0.161278</td>\n",
       "      <td>51.291925</td>\n",
       "      <td>11.478261</td>\n",
       "      <td>3.509317</td>\n",
       "      <td>0.310729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>56.546180</td>\n",
       "      <td>2.928761</td>\n",
       "      <td>51.954220</td>\n",
       "      <td>78.542310</td>\n",
       "      <td>26.625058</td>\n",
       "      <td>0.171281</td>\n",
       "      <td>0.055839</td>\n",
       "      <td>0.151386</td>\n",
       "      <td>5421.411714</td>\n",
       "      <td>472.810955</td>\n",
       "      <td>0.224871</td>\n",
       "      <td>1.444326</td>\n",
       "      <td>1.702650</td>\n",
       "      <td>0.099337</td>\n",
       "      <td>78.469551</td>\n",
       "      <td>16.197256</td>\n",
       "      <td>1.275333</td>\n",
       "      <td>0.171545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9.965780</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.441860</td>\n",
       "      <td>-1.112757</td>\n",
       "      <td>0.102926</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>961.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.705882</td>\n",
       "      <td>-0.759733</td>\n",
       "      <td>0.154174</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2215.000000</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>1.093023</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>-0.594690</td>\n",
       "      <td>0.211333</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>397.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41457.000000</td>\n",
       "      <td>2319.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-0.503115</td>\n",
       "      <td>0.529482</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_sess    num_days   num_probs    num_atts   num_hints  \\\n",
       "count  161.000000  161.000000  161.000000  161.000000  161.000000   \n",
       "mean    34.708075    2.720497   32.254658   51.360248   14.006211   \n",
       "std     56.546180    2.928761   51.954220   78.542310   26.625058   \n",
       "min      1.000000    1.000000    1.000000    2.000000    0.000000   \n",
       "25%      5.000000    1.000000    5.000000   10.000000    2.000000   \n",
       "50%     11.000000    1.000000   11.000000   21.000000    5.000000   \n",
       "75%     35.000000    3.000000   35.000000   53.000000   13.000000   \n",
       "max    397.000000   13.000000  362.000000  588.000000  184.000000   \n",
       "\n",
       "       frac_corr_atts  frac_3s_atts  frac_1s_hints     time_atts   time_hints  \\\n",
       "count      161.000000    161.000000     161.000000    161.000000   161.000000   \n",
       "mean         0.688847      0.025639       0.050475   3113.850932   371.161491   \n",
       "std          0.171281      0.055839       0.151386   5421.411714   472.810955   \n",
       "min          0.200000      0.000000       0.000000     26.000000     0.000000   \n",
       "25%          0.588235      0.000000       0.000000    546.000000    46.000000   \n",
       "50%          0.727273      0.000000       0.000000    961.000000   172.000000   \n",
       "75%          0.814286      0.022222       0.000000   2215.000000   487.000000   \n",
       "max          0.975207      0.333333       1.000000  41457.000000  2319.000000   \n",
       "\n",
       "       max_probl_views    max_atts  learning_parameter  difficulty_parameter  \\\n",
       "count       161.000000  161.000000          161.000000            161.000000   \n",
       "mean          1.092419    2.245839           -1.227948              0.161278   \n",
       "std           0.224871    1.444326            1.702650              0.099337   \n",
       "min           1.000000    1.000000           -9.965780              0.001000   \n",
       "25%           1.000000    1.441860           -1.112757              0.102926   \n",
       "50%           1.000000    1.705882           -0.759733              0.154174   \n",
       "75%           1.093023    2.411765           -0.594690              0.211333   \n",
       "max           2.600000   11.000000           -0.503115              0.529482   \n",
       "\n",
       "       number of attempts  number of incorrect attempts  cluster_index  \\\n",
       "count          161.000000                    161.000000     161.000000   \n",
       "mean            51.291925                     11.478261       3.509317   \n",
       "std             78.469551                     16.197256       1.275333   \n",
       "min              2.000000                      1.000000       1.000000   \n",
       "25%             10.000000                      3.000000       3.000000   \n",
       "50%             21.000000                      5.000000       4.000000   \n",
       "75%             53.000000                     13.000000       4.000000   \n",
       "max            588.000000                    136.000000       6.000000   \n",
       "\n",
       "       frac_incorrect_atts  \n",
       "count           161.000000  \n",
       "mean              0.310729  \n",
       "std               0.171545  \n",
       "min               0.024793  \n",
       "25%               0.181818  \n",
       "50%               0.272727  \n",
       "75%               0.411765  \n",
       "max               0.800000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data[stud_data['learning_parameter'] < -0.5].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sess</th>\n",
       "      <th>num_days</th>\n",
       "      <th>num_probs</th>\n",
       "      <th>num_atts</th>\n",
       "      <th>num_hints</th>\n",
       "      <th>frac_corr_atts</th>\n",
       "      <th>frac_3s_atts</th>\n",
       "      <th>frac_1s_hints</th>\n",
       "      <th>time_atts</th>\n",
       "      <th>time_hints</th>\n",
       "      <th>max_probl_views</th>\n",
       "      <th>max_atts</th>\n",
       "      <th>learning_parameter</th>\n",
       "      <th>difficulty_parameter</th>\n",
       "      <th>number of attempts</th>\n",
       "      <th>number of incorrect attempts</th>\n",
       "      <th>cluster_index</th>\n",
       "      <th>frac_incorrect_atts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.767442</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>9.294275</td>\n",
       "      <td>20.773703</td>\n",
       "      <td>9.701252</td>\n",
       "      <td>0.658382</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.031332</td>\n",
       "      <td>975.757603</td>\n",
       "      <td>238.600179</td>\n",
       "      <td>1.078327</td>\n",
       "      <td>2.370444</td>\n",
       "      <td>4.841834</td>\n",
       "      <td>0.523349</td>\n",
       "      <td>20.770125</td>\n",
       "      <td>6.887299</td>\n",
       "      <td>3.181574</td>\n",
       "      <td>0.318386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.127075</td>\n",
       "      <td>0.965203</td>\n",
       "      <td>12.326656</td>\n",
       "      <td>28.717120</td>\n",
       "      <td>28.702815</td>\n",
       "      <td>0.254652</td>\n",
       "      <td>0.118064</td>\n",
       "      <td>0.109242</td>\n",
       "      <td>1235.419496</td>\n",
       "      <td>402.316758</td>\n",
       "      <td>0.271104</td>\n",
       "      <td>1.544594</td>\n",
       "      <td>7.776401</td>\n",
       "      <td>0.346560</td>\n",
       "      <td>28.710326</td>\n",
       "      <td>10.527272</td>\n",
       "      <td>0.927130</td>\n",
       "      <td>0.226612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.541964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.750000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.533341</td>\n",
       "      <td>0.252888</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>644.500000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.793611</td>\n",
       "      <td>0.520733</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>311.000000</td>\n",
       "      <td>1.026931</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.853239</td>\n",
       "      <td>0.749445</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>121.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10044.000000</td>\n",
       "      <td>6247.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>24.908305</td>\n",
       "      <td>1.669793</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          num_sess     num_days    num_probs     num_atts    num_hints  \\\n",
       "count  1118.000000  1118.000000  1118.000000  1118.000000  1118.000000   \n",
       "mean      9.767442     1.384615     9.294275    20.773703     9.701252   \n",
       "std      13.127075     0.965203    12.326656    28.717120    28.702815   \n",
       "min       1.000000     1.000000     1.000000     0.000000     0.000000   \n",
       "25%       2.000000     1.000000     2.000000     5.000000     1.000000   \n",
       "50%       6.000000     1.000000     5.000000    12.000000     3.000000   \n",
       "75%      11.000000     1.000000    11.000000    25.000000     9.000000   \n",
       "max     121.000000    12.000000   116.000000   332.000000   661.000000   \n",
       "\n",
       "       frac_corr_atts  frac_3s_atts  frac_1s_hints     time_atts   time_hints  \\\n",
       "count     1118.000000   1118.000000    1118.000000   1118.000000  1118.000000   \n",
       "mean         0.658382      0.040541       0.031332    975.757603   238.600179   \n",
       "std          0.254652      0.118064       0.109242   1235.419496   402.316758   \n",
       "min          0.000000      0.000000       0.000000      0.000000     0.000000   \n",
       "25%          0.541964      0.000000       0.000000    185.750000     9.000000   \n",
       "50%          0.666667      0.000000       0.000000    644.500000    94.500000   \n",
       "75%          0.833333      0.000000       0.000000   1199.000000   311.000000   \n",
       "max          1.000000      1.000000       1.000000  10044.000000  6247.000000   \n",
       "\n",
       "       max_probl_views     max_atts  learning_parameter  difficulty_parameter  \\\n",
       "count      1118.000000  1118.000000         1118.000000           1118.000000   \n",
       "mean          1.078327     2.370444            4.841834              0.523349   \n",
       "std           0.271104     1.544594            7.776401              0.346560   \n",
       "min           1.000000     0.000000            0.500000              0.001000   \n",
       "25%           1.000000     1.200000            0.533341              0.252888   \n",
       "50%           1.000000     2.000000            0.793611              0.520733   \n",
       "75%           1.026931     3.000000            1.853239              0.749445   \n",
       "max           5.000000    12.000000           24.908305              1.669793   \n",
       "\n",
       "       number of attempts  number of incorrect attempts  cluster_index  \\\n",
       "count         1118.000000                   1118.000000    1118.000000   \n",
       "mean            20.770125                      6.887299       3.181574   \n",
       "std             28.710326                     10.527272       0.927130   \n",
       "min              0.000000                      0.000000       1.000000   \n",
       "25%              5.000000                      1.000000       3.000000   \n",
       "50%             12.000000                      3.000000       3.000000   \n",
       "75%             25.000000                      9.000000       4.000000   \n",
       "max            332.000000                    121.000000       6.000000   \n",
       "\n",
       "       frac_incorrect_atts  \n",
       "count          1080.000000  \n",
       "mean              0.318386  \n",
       "std               0.226612  \n",
       "min               0.000000  \n",
       "25%               0.166667  \n",
       "50%               0.315789  \n",
       "75%               0.444444  \n",
       "max               1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data[stud_data['learning_parameter'] >= 0.5].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, \"extreme negative learners\" are very similar to \"extreme positive learners\" in terms of `'frac_corr_atts'`. However, they opened much more sessions (`'num_sess'`), tried to solve more problems (`'num_probs'`), made more attempts to solve the problems (`'num_atts'`) and spent more time (`time_atts`) for solving them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster_index\n",
       "1    20\n",
       "3    57\n",
       "4    58\n",
       "5    14\n",
       "6    12\n",
       "Name: num_sess, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data[stud_data['learning_parameter'] < -0.5].groupby('cluster_index').agg(len)['num_sess']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster_index\n",
       "1     88\n",
       "2     93\n",
       "3    501\n",
       "4    404\n",
       "5     28\n",
       "6      4\n",
       "Name: num_sess, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data[stud_data['learning_parameter'] >= 0.5].groupby('cluster_index').agg(len)['num_sess']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably, most of \"extreme learners\" belong to groups 3 and 4 that have the smallest `'num_atts'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sess</th>\n",
       "      <th>num_days</th>\n",
       "      <th>num_probs</th>\n",
       "      <th>num_atts</th>\n",
       "      <th>num_hints</th>\n",
       "      <th>frac_corr_atts</th>\n",
       "      <th>frac_3s_atts</th>\n",
       "      <th>frac_1s_hints</th>\n",
       "      <th>time_atts</th>\n",
       "      <th>time_hints</th>\n",
       "      <th>max_probl_views</th>\n",
       "      <th>max_atts</th>\n",
       "      <th>learning_parameter</th>\n",
       "      <th>difficulty_parameter</th>\n",
       "      <th>number of attempts</th>\n",
       "      <th>number of incorrect attempts</th>\n",
       "      <th>frac_incorrect_atts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121.623648</td>\n",
       "      <td>7.565688</td>\n",
       "      <td>92.571097</td>\n",
       "      <td>358.080371</td>\n",
       "      <td>246.780526</td>\n",
       "      <td>0.576761</td>\n",
       "      <td>0.110614</td>\n",
       "      <td>0.247601</td>\n",
       "      <td>9347.902114</td>\n",
       "      <td>2558.552269</td>\n",
       "      <td>1.314304</td>\n",
       "      <td>3.920657</td>\n",
       "      <td>0.412377</td>\n",
       "      <td>0.456685</td>\n",
       "      <td>357.961360</td>\n",
       "      <td>152.899536</td>\n",
       "      <td>0.421592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.342711</td>\n",
       "      <td>3.925831</td>\n",
       "      <td>45.437340</td>\n",
       "      <td>185.002558</td>\n",
       "      <td>86.452685</td>\n",
       "      <td>0.519664</td>\n",
       "      <td>0.233178</td>\n",
       "      <td>0.034632</td>\n",
       "      <td>4208.397711</td>\n",
       "      <td>1175.021739</td>\n",
       "      <td>1.192305</td>\n",
       "      <td>3.589256</td>\n",
       "      <td>1.089818</td>\n",
       "      <td>0.559777</td>\n",
       "      <td>183.861893</td>\n",
       "      <td>92.813299</td>\n",
       "      <td>0.479562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.436429</td>\n",
       "      <td>1.691614</td>\n",
       "      <td>13.456267</td>\n",
       "      <td>30.439134</td>\n",
       "      <td>2.562669</td>\n",
       "      <td>0.583222</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>1643.489630</td>\n",
       "      <td>41.202885</td>\n",
       "      <td>1.090756</td>\n",
       "      <td>2.854811</td>\n",
       "      <td>2.492266</td>\n",
       "      <td>0.492713</td>\n",
       "      <td>30.434626</td>\n",
       "      <td>11.100992</td>\n",
       "      <td>0.402156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.246903</td>\n",
       "      <td>2.233278</td>\n",
       "      <td>13.523534</td>\n",
       "      <td>51.809661</td>\n",
       "      <td>21.730801</td>\n",
       "      <td>0.518609</td>\n",
       "      <td>0.017276</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>2375.681462</td>\n",
       "      <td>649.441164</td>\n",
       "      <td>1.145824</td>\n",
       "      <td>4.128678</td>\n",
       "      <td>0.695627</td>\n",
       "      <td>0.550509</td>\n",
       "      <td>51.804294</td>\n",
       "      <td>26.174236</td>\n",
       "      <td>0.479627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62.648690</td>\n",
       "      <td>6.227530</td>\n",
       "      <td>55.605547</td>\n",
       "      <td>191.468927</td>\n",
       "      <td>68.852594</td>\n",
       "      <td>0.559241</td>\n",
       "      <td>0.031661</td>\n",
       "      <td>0.023676</td>\n",
       "      <td>8046.446327</td>\n",
       "      <td>1703.785824</td>\n",
       "      <td>1.157399</td>\n",
       "      <td>3.492833</td>\n",
       "      <td>0.071179</td>\n",
       "      <td>0.457634</td>\n",
       "      <td>191.396507</td>\n",
       "      <td>88.188495</td>\n",
       "      <td>0.440491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>181.383599</td>\n",
       "      <td>11.586681</td>\n",
       "      <td>146.048431</td>\n",
       "      <td>467.137589</td>\n",
       "      <td>142.116125</td>\n",
       "      <td>0.612408</td>\n",
       "      <td>0.037793</td>\n",
       "      <td>0.034232</td>\n",
       "      <td>17310.899564</td>\n",
       "      <td>2679.468079</td>\n",
       "      <td>1.261961</td>\n",
       "      <td>3.268800</td>\n",
       "      <td>-0.006301</td>\n",
       "      <td>0.391601</td>\n",
       "      <td>466.381948</td>\n",
       "      <td>183.942763</td>\n",
       "      <td>0.386384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 num_sess   num_days   num_probs    num_atts   num_hints  \\\n",
       "cluster_index                                                              \n",
       "1              121.623648   7.565688   92.571097  358.080371  246.780526   \n",
       "2               56.342711   3.925831   45.437340  185.002558   86.452685   \n",
       "3               14.436429   1.691614   13.456267   30.439134    2.562669   \n",
       "4               15.246903   2.233278   13.523534   51.809661   21.730801   \n",
       "5               62.648690   6.227530   55.605547  191.468927   68.852594   \n",
       "6              181.383599  11.586681  146.048431  467.137589  142.116125   \n",
       "\n",
       "               frac_corr_atts  frac_3s_atts  frac_1s_hints     time_atts  \\\n",
       "cluster_index                                                              \n",
       "1                    0.576761      0.110614       0.247601   9347.902114   \n",
       "2                    0.519664      0.233178       0.034632   4208.397711   \n",
       "3                    0.583222      0.011584       0.002672   1643.489630   \n",
       "4                    0.518609      0.017276       0.011072   2375.681462   \n",
       "5                    0.559241      0.031661       0.023676   8046.446327   \n",
       "6                    0.612408      0.037793       0.034232  17310.899564   \n",
       "\n",
       "                time_hints  max_probl_views  max_atts  learning_parameter  \\\n",
       "cluster_index                                                               \n",
       "1              2558.552269         1.314304  3.920657            0.412377   \n",
       "2              1175.021739         1.192305  3.589256            1.089818   \n",
       "3                41.202885         1.090756  2.854811            2.492266   \n",
       "4               649.441164         1.145824  4.128678            0.695627   \n",
       "5              1703.785824         1.157399  3.492833            0.071179   \n",
       "6              2679.468079         1.261961  3.268800           -0.006301   \n",
       "\n",
       "               difficulty_parameter  number of attempts  \\\n",
       "cluster_index                                             \n",
       "1                          0.456685          357.961360   \n",
       "2                          0.559777          183.861893   \n",
       "3                          0.492713           30.434626   \n",
       "4                          0.550509           51.804294   \n",
       "5                          0.457634          191.396507   \n",
       "6                          0.391601          466.381948   \n",
       "\n",
       "               number of incorrect attempts  frac_incorrect_atts  \n",
       "cluster_index                                                     \n",
       "1                                152.899536             0.421592  \n",
       "2                                 92.813299             0.479562  \n",
       "3                                 11.100992             0.402156  \n",
       "4                                 26.174236             0.479627  \n",
       "5                                 88.188495             0.440491  \n",
       "6                                183.942763             0.386384  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data.groupby('cluster_index').agg(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together with the smallest group 2, groups 3 and 4 also correspond to the largest `'learning_parameter'` variation across their members:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster_index\n",
       "1    2.575010\n",
       "2    4.092726\n",
       "3    6.263133\n",
       "4    3.261689\n",
       "5    0.904354\n",
       "6    0.151328\n",
       "Name: learning_parameter, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data.groupby('cluster_index').agg(np.std)['learning_parameter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that **both** absolute average value and standard deviation come to zero with increasing `'num_atts'`: a possible manifestation of the [Plateau effect](https://en.wikipedia.org/wiki/Plateau_effect)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I try to explain the observed **increase** of `'frac_incorrect_atts'` for 5 and more attempts.\n",
    "\n",
    "The group with the largest `'frac_incorrect_atts'` is **group 4** that also has the largest `'max_atts'` (number of maximal attempts averaged for all assessed problems). Consequently, students from two groups with the smallest `'frac_incorrect_atts'` (**groups 3 and 6**) also have the smallest `'max_atts'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frac_incorrect_atts</th>\n",
       "      <th>max_atts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>frac_incorrect_atts</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_atts</th>\n",
       "      <td>0.660316</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     frac_incorrect_atts  max_atts\n",
       "frac_incorrect_atts             1.000000  0.660316\n",
       "max_atts                        0.660316  1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data.groupby('cluster_index').agg(np.mean)[['frac_incorrect_atts', 'max_atts']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51717864000939062"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data.corr()['frac_incorrect_atts']['max_atts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, students from groups 3 and 6 contribute less (and students from group 4 contribute more) to problems with large number of attempts and **distort** the averaged learning curve towards larger `'frac_incorrect_atts'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with \"benchmark\" model (student with \"gaming\" vs \"non-gaming\" behaviour):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stud_data['gaming_index'] = stud_data['cluster_index'].replace({1: 0, 2: 0, 3: 1, 4: 1, 5: 1, 6:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sess</th>\n",
       "      <th>num_days</th>\n",
       "      <th>num_probs</th>\n",
       "      <th>num_atts</th>\n",
       "      <th>num_hints</th>\n",
       "      <th>frac_corr_atts</th>\n",
       "      <th>frac_3s_atts</th>\n",
       "      <th>frac_1s_hints</th>\n",
       "      <th>time_atts</th>\n",
       "      <th>time_hints</th>\n",
       "      <th>max_probl_views</th>\n",
       "      <th>max_atts</th>\n",
       "      <th>learning_parameter</th>\n",
       "      <th>difficulty_parameter</th>\n",
       "      <th>number of attempts</th>\n",
       "      <th>number of incorrect attempts</th>\n",
       "      <th>cluster_index</th>\n",
       "      <th>frac_incorrect_atts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaming_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106.475371</td>\n",
       "      <td>6.721068</td>\n",
       "      <td>81.633828</td>\n",
       "      <td>317.918101</td>\n",
       "      <td>209.576855</td>\n",
       "      <td>0.563511</td>\n",
       "      <td>0.139055</td>\n",
       "      <td>0.198182</td>\n",
       "      <td>8155.293081</td>\n",
       "      <td>2237.507499</td>\n",
       "      <td>1.285995</td>\n",
       "      <td>3.843756</td>\n",
       "      <td>0.569575</td>\n",
       "      <td>0.480607</td>\n",
       "      <td>317.562018</td>\n",
       "      <td>138.956677</td>\n",
       "      <td>1.232047</td>\n",
       "      <td>0.435068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.155449</td>\n",
       "      <td>5.546676</td>\n",
       "      <td>57.753393</td>\n",
       "      <td>189.282934</td>\n",
       "      <td>61.378341</td>\n",
       "      <td>0.562639</td>\n",
       "      <td>0.025360</td>\n",
       "      <td>0.018928</td>\n",
       "      <td>7497.856889</td>\n",
       "      <td>1344.003427</td>\n",
       "      <td>1.169468</td>\n",
       "      <td>3.551144</td>\n",
       "      <td>0.627261</td>\n",
       "      <td>0.477355</td>\n",
       "      <td>189.072927</td>\n",
       "      <td>79.730226</td>\n",
       "      <td>4.613023</td>\n",
       "      <td>0.434249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                num_sess  num_days  num_probs    num_atts   num_hints  \\\n",
       "gaming_index                                                            \n",
       "0             106.475371  6.721068  81.633828  317.918101  209.576855   \n",
       "1              69.155449  5.546676  57.753393  189.282934   61.378341   \n",
       "\n",
       "              frac_corr_atts  frac_3s_atts  frac_1s_hints    time_atts  \\\n",
       "gaming_index                                                             \n",
       "0                   0.563511      0.139055       0.198182  8155.293081   \n",
       "1                   0.562639      0.025360       0.018928  7497.856889   \n",
       "\n",
       "               time_hints  max_probl_views  max_atts  learning_parameter  \\\n",
       "gaming_index                                                               \n",
       "0             2237.507499         1.285995  3.843756            0.569575   \n",
       "1             1344.003427         1.169468  3.551144            0.627261   \n",
       "\n",
       "              difficulty_parameter  number of attempts  \\\n",
       "gaming_index                                             \n",
       "0                         0.480607          317.562018   \n",
       "1                         0.477355          189.072927   \n",
       "\n",
       "              number of incorrect attempts  cluster_index  frac_incorrect_atts  \n",
       "gaming_index                                                                    \n",
       "0                               138.956677       1.232047             0.435068  \n",
       "1                                79.730226       4.613023             0.434249  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_data.groupby('gaming_index').agg(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating visualisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anon Student Id</th>\n",
       "      <th>Session Id</th>\n",
       "      <th>Duration (sec)</th>\n",
       "      <th>Student Response Type</th>\n",
       "      <th>Problem Name</th>\n",
       "      <th>Problem View</th>\n",
       "      <th>Attempt At Step</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Day</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stu_001d187b1b375fe98b88696b250177f0</td>\n",
       "      <td>647501</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2004-11-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stu_001d187b1b375fe98b88696b250177f0</td>\n",
       "      <td>647501</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004-11-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stu_001d187b1b375fe98b88696b250177f0</td>\n",
       "      <td>647792</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2004-11-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stu_001d187b1b375fe98b88696b250177f0</td>\n",
       "      <td>647792</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2004-11-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stu_001d187b1b375fe98b88696b250177f0</td>\n",
       "      <td>647792</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2004-11-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Anon Student Id  Session Id  Duration (sec)  \\\n",
       "0  Stu_001d187b1b375fe98b88696b250177f0      647501           102.0   \n",
       "1  Stu_001d187b1b375fe98b88696b250177f0      647501            46.0   \n",
       "2  Stu_001d187b1b375fe98b88696b250177f0      647792            70.0   \n",
       "3  Stu_001d187b1b375fe98b88696b250177f0      647792            22.0   \n",
       "4  Stu_001d187b1b375fe98b88696b250177f0      647792             2.0   \n",
       "\n",
       "   Student Response Type  Problem Name  Problem View  Attempt At Step  \\\n",
       "0                      1          2218           1.0              1.0   \n",
       "1                      0          2218           1.0              2.0   \n",
       "2                      1          3093           1.0              1.0   \n",
       "3                      1          3093           1.0              1.0   \n",
       "4                      1          3093           1.0              2.0   \n",
       "\n",
       "   Outcome         Day  x  \n",
       "0      2.0  2004-11-10  0  \n",
       "1      0.0  2004-11-10  1  \n",
       "2      2.0  2004-11-10  0  \n",
       "3      2.0  2004-11-10  0  \n",
       "4      2.0  2004-11-10  0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_hdf('data.hdf','test')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stud_list = data['Anon Student Id'].unique()\n",
    "#print(stud_list[:5])\n",
    "stud_dict = {stud: cluster_index.loc[i, 1] for i, stud in enumerate(stud_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stu_001d187b1b375fe98b88696b250177f0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_index.loc[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_dict['Stu_001d187b1b375fe98b88696b250177f0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stu_001d187b1b375fe98b88696b250177f0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stu_00b8a37b3ab49bfe7d7a77014d1e4cf8</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stu_00c6652f296f103913139157c79a856f</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stu_01080cce4b1a14b3fd81d684421daed4</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stu_0153c9b08d68e42d9a2bb5f70086df00</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cluster_index\n",
       "Stu_001d187b1b375fe98b88696b250177f0            1.0\n",
       "Stu_00b8a37b3ab49bfe7d7a77014d1e4cf8            5.0\n",
       "Stu_00c6652f296f103913139157c79a856f            6.0\n",
       "Stu_01080cce4b1a14b3fd81d684421daed4            2.0\n",
       "Stu_0153c9b08d68e42d9a2bb5f70086df00            1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_df = pd.DataFrame()\n",
    "for item in stud_dict:\n",
    "    #print(item, stud_dict[item])\n",
    "    stud_df.loc[item, 'cluster_index'] = int(stud_dict[item])\n",
    "stud_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anon Student Id</th>\n",
       "      <th>Session Id</th>\n",
       "      <th>Duration (sec)</th>\n",
       "      <th>Student Response Type</th>\n",
       "      <th>Problem Name</th>\n",
       "      <th>Problem View</th>\n",
       "      <th>Attempt At Step</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Day</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stu_001d187b1b375fe98b88696b250177f0</td>\n",
       "      <td>647501</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2004-11-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stu_001d187b1b375fe98b88696b250177f0</td>\n",
       "      <td>647501</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004-11-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stu_001d187b1b375fe98b88696b250177f0</td>\n",
       "      <td>647792</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2004-11-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stu_001d187b1b375fe98b88696b250177f0</td>\n",
       "      <td>647792</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2004-11-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stu_001d187b1b375fe98b88696b250177f0</td>\n",
       "      <td>647792</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2004-11-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Anon Student Id  Session Id  Duration (sec)  \\\n",
       "0  Stu_001d187b1b375fe98b88696b250177f0      647501           102.0   \n",
       "1  Stu_001d187b1b375fe98b88696b250177f0      647501            46.0   \n",
       "2  Stu_001d187b1b375fe98b88696b250177f0      647792            70.0   \n",
       "3  Stu_001d187b1b375fe98b88696b250177f0      647792            22.0   \n",
       "4  Stu_001d187b1b375fe98b88696b250177f0      647792             2.0   \n",
       "\n",
       "   Student Response Type  Problem Name  Problem View  Attempt At Step  \\\n",
       "0                      1          2218           1.0              1.0   \n",
       "1                      0          2218           1.0              2.0   \n",
       "2                      1          3093           1.0              1.0   \n",
       "3                      1          3093           1.0              1.0   \n",
       "4                      1          3093           1.0              2.0   \n",
       "\n",
       "   Outcome         Day  x  \n",
       "0      2.0  2004-11-10  0  \n",
       "1      0.0  2004-11-10  1  \n",
       "2      2.0  2004-11-10  0  \n",
       "3      2.0  2004-11-10  0  \n",
       "4      2.0  2004-11-10  0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_125 = data[(data['Anon Student Id'].isin(stud_df[stud_df['cluster_index'] == 1].index)) | \\\n",
    "               (data['Anon Student Id'].isin(stud_df[stud_df['cluster_index'] == 2].index)) | \\\n",
    "               (data['Anon Student Id'].isin(stud_df[stud_df['cluster_index'] == 5].index))]\n",
    "data_125.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2 = data[(data['Anon Student Id'].isin(stud_df[stud_df['cluster_index'] == 2].index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = data[data['Outcome'] <= 1].groupby(['x']).agg(len)['Problem Name']\n",
    "\n",
    "s2 = data[data['Outcome'] == 1].groupby(['x']).agg(len)['Problem Name']\n",
    "\n",
    "s1[8] = s1.loc[8:].sum()\n",
    "for i in range(9, int(s1.index.max()+1)):\n",
    "    try:\n",
    "        s1.drop(i, inplace=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "s2[8] = s2.loc[8:].sum()\n",
    "for i in range(9, int(s2.index.max()+1)):\n",
    "    try:\n",
    "        s2.drop(i, inplace=True)\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_1 = data[(data['Anon Student Id'].isin(stud_df[stud_df['cluster_index'] == 1].index))]\n",
    "data_2 = data[(data['Anon Student Id'].isin(stud_df[stud_df['cluster_index'] == 2].index))]\n",
    "data_3 = data[(data['Anon Student Id'].isin(stud_df[stud_df['cluster_index'] == 3].index))]\n",
    "data_4 = data[(data['Anon Student Id'].isin(stud_df[stud_df['cluster_index'] == 4].index))]\n",
    "data_5 = data[(data['Anon Student Id'].isin(stud_df[stud_df['cluster_index'] == 5].index))]\n",
    "data_6 = data[(data['Anon Student Id'].isin(stud_df[stud_df['cluster_index'] == 6].index))]\n",
    "\n",
    "s1_1 = data_1[data_1['Outcome'] <= 1].groupby(['x']).agg(len)['Problem Name']\n",
    "\n",
    "s2_1 = data_1[data_1['Outcome'] == 1].groupby(['x']).agg(len)['Problem Name']\n",
    "\n",
    "s1_1[8] = s1_1.loc[8:].sum()\n",
    "for i in range(9, int(s1_1.index.max()+1)):\n",
    "    try:\n",
    "        s1_1.drop(i, inplace=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "s2_1[8] = s2_1.loc[8:].sum()\n",
    "for i in range(9, int(s2_1.index.max()+1)):\n",
    "    try:\n",
    "        s2_1.drop(i, inplace=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "s1_2 = data_2[data_2['Outcome'] <= 1].groupby(['x']).agg(len)['Problem Name']\n",
    "\n",
    "s2_2 = data_2[data_2['Outcome'] == 1].groupby(['x']).agg(len)['Problem Name']\n",
    "\n",
    "s1_2[8] = s1_2.loc[8:].sum()\n",
    "for i in range(9, int(s1_2.index.max()+1)):\n",
    "    try:\n",
    "        s1_2.drop(i, inplace=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "s2_2[8] = s2_2.loc[8:].sum()\n",
    "for i in range(9, int(s2_2.index.max()+1)):\n",
    "    try:\n",
    "        s2_2.drop(i, inplace=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "s1_3 = data_3[data_3['Outcome'] <= 1].groupby(['x']).agg(len)['Problem Name']\n",
    "\n",
    "s2_3 = data_3[data_3['Outcome'] == 1].groupby(['x']).agg(len)['Problem Name']\n",
    "\n",
    "s1_3[8] = s1_3.loc[8:].sum()\n",
    "for i in range(9, int(s1_3.index.max()+1)):\n",
    "    try:\n",
    "        s1_3.drop(i, inplace=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "s2_3[8] = s2_3.loc[8:].sum()\n",
    "for i in range(9, int(s2_3.index.max()+1)):\n",
    "    try:\n",
    "        s2_3.drop(i, inplace=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "s1_4 = data_4[data_4['Outcome'] <= 1].groupby(['x']).agg(len)['Problem Name']\n",
    "\n",
    "s2_4 = data_4[data_4['Outcome'] == 1].groupby(['x']).agg(len)['Problem Name']\n",
    "\n",
    "s1_4[8] = s1_4.loc[8:].sum()\n",
    "for i in range(9, int(s1_4.index.max()+1)):\n",
    "    try:\n",
    "        s1_4.drop(i, inplace=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "s2_4[8] = s2_4.loc[8:].sum()\n",
    "for i in range(9, int(s2_4.index.max()+1)):\n",
    "    try:\n",
    "        s2_4.drop(i, inplace=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "s1_5 = data_5[data_5['Outcome'] <= 1].groupby(['x']).agg(len)['Problem Name']\n",
    "\n",
    "s2_5 = data_5[data_5['Outcome'] == 1].groupby(['x']).agg(len)['Problem Name']\n",
    "\n",
    "s1_5[8] = s1_5.loc[8:].sum()\n",
    "for i in range(9, int(s1_5.index.max()+1)):\n",
    "    try:\n",
    "        s1_5.drop(i, inplace=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "s2_5[8] = s2_5.loc[8:].sum()\n",
    "for i in range(9, int(s2_5.index.max()+1)):\n",
    "    try:\n",
    "        s2_5.drop(i, inplace=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "s1_6 = data_6[data_6['Outcome'] <= 1].groupby(['x']).agg(len)['Problem Name']\n",
    "\n",
    "s2_6 = data_6[data_6['Outcome'] == 1].groupby(['x']).agg(len)['Problem Name']\n",
    "\n",
    "s1_6[8] = s1_6.loc[8:].sum()\n",
    "for i in range(9, int(s1_6.index.max()+1)):\n",
    "    try:\n",
    "        s1_6.drop(i, inplace=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "s2_6[8] = s2_6.loc[8:].sum()\n",
    "for i in range(9, int(s2_6.index.max()+1)):\n",
    "    try:\n",
    "        s2_6.drop(i, inplace=True)\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAELCAYAAABzmDdiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28b629c080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 8.3\n",
    "fig_size[1] = 4.7\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.xlim(0.5,8.5)\n",
    "plt.bar(s1.index, s1, width=0.9)\n",
    "#plt.bar(s2.index, s2, width=0.9)\n",
    "#plt.legend(['CORRECT', 'INCORRECT'])\n",
    "\n",
    "plt.xlabel(\"Attempt number\", size=14)\n",
    "plt.ylabel(\"Number of attempts\", size=14)\n",
    "ax1.tick_params(axis ='both', which='major', length=0, labelsize =14, color='black')\n",
    "ax1.tick_params(axis ='both', which='minor', length=0)\n",
    "labels = [item.get_text() for item in ax1.get_xticklabels()]\n",
    "labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8+']\n",
    "#labels = ['2', '4', '6', '8+']\n",
    "#print(labels)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(s1.index, s2/s1, 'r-o', linewidth=4, label='Average')\n",
    "ax2.plot(s1_1.index, s2_1/s1_1, 'c-+', label='group 1')\n",
    "ax2.plot(s1_2.index, s2_2/s1_2, 'b-+', label='group 2')\n",
    "ax2.plot(s1_3.index, s2_3/s1_3, 'c-.', label='group 3')\n",
    "ax2.plot(s1_4.index, s2_4/s1_4, 'b-.', label='group 4')\n",
    "ax2.plot(s1_5.index, s2_5/s1_5, 'c-x', label='group 5')\n",
    "ax2.plot(s1_6.index, s2_6/s1_6, 'b-x', label='group 6')\n",
    "ax2.legend()\n",
    "\n",
    "ax2.set_ylabel('Fraction of incorrect attempts', size=14, color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "ax2.tick_params(axis ='both', which='minor', length=0)\n",
    "ax2.tick_params(axis ='both', which='major', length=0, labelsize =14, color='red')\n",
    "\n",
    "ax1.set_xticklabels(labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
