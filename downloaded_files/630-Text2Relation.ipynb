{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4e1e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pesante/anaconda3/envs/text2event/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:1006: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    HfArgumentParser,\n",
    "    MBartTokenizer,\n",
    "    default_data_collator,\n",
    "    AutoModelWithLMHead,\n",
    "    set_seed\n",
    ")\n",
    "model_name = \"./models/First/\"\n",
    "model = AutoModelWithLMHead.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.encode(\"<extra_id_0> <extra_id_1>\") != [32099, 32098, 32097, 1]:\n",
    "    # For non-t5 tokenizer\n",
    "    tokenizer.add_special_tokens(\n",
    "        {\"additional_special_tokens\": [\"<Temp_S>\", \"<Temp_E>\", \"<Relation_S>\", \"<Relation_E>\", \\\n",
    "            \"<ORG>\", \"<VEH>\", \"<WEA>\", \"<LOC>\",\"<FAC>\",\"<End>\" ,\"<PER>\",\"<GPE>\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5610bc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32100, 32110, 32101, 32102]\n"
     ]
    }
   ],
   "source": [
    "b = tokenizer.convert_tokens_to_ids([\"<Temp_S>\", \"<Temp_E>\", \"<Relation_S>\", \"<Relation_E>\"])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fb90b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32100, 32110, 32101, 32102]\n",
      "32100\n",
      "kakd\n"
     ]
    }
   ],
   "source": [
    "tokenizer.add_special_tokens(\n",
    "        {\"additional_special_tokens\": [\"<Temp_S>\", \"<Temp_E>\", \"<Relation_S>\", \"<Relation_E>\", \\\n",
    "            \"<ORG>\", \"<VEH>\", \"<WEA>\", \"<LOC>\",\"<FAC>\",\"<End>\" ,\"<PER>\",\"<GPE>\"]})\n",
    "b = tokenizer.convert_tokens_to_ids([\"<Temp_S>\", \"<Temp_E>\", \"<Relation_S>\", \"<Relation_E>\"])\n",
    "print(b)\n",
    "print(tokenizer.convert_tokens_to_ids([\"<Temp_S>\"])[0])\n",
    "if tokenizer.convert_tokens_to_ids([\"<Temp_S>\"])[0] == 32100:\n",
    "    print(\"kakd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dbc8a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_space(text):\n",
    "    \"\"\"\n",
    "    add space between special token\n",
    "    :param text:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_text_list = list()\n",
    "    for item in zip(split_bracket.findall(text), split_bracket.split(text)[1:]):\n",
    "        new_text_list += item\n",
    "    return ' '.join(new_text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa6e68a",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b78dc742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-521fb87c8c936007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/pesante/.cache/huggingface/datasets/json/default-521fb87c8c936007/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3525bd891537480dbae4845b7d826750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9567c09b264e7fbdc93c3c8e14e9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/pesante/.cache/huggingface/datasets/json/default-521fb87c8c936007/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0151d9a41d486e9f99fd6b83f34af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "data_files = {}\n",
    "data_files[\"train\"] = './data/new_text2tree/one_ie_ace2005_subtype/train.json'\n",
    "extension = 'json'\n",
    "datasets = load_dataset(extension, data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d35de264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'relation']\n"
     ]
    }
   ],
   "source": [
    "column_names = datasets[\"train\"].column_names\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "902b6475",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets[\"train\"]\n",
    "text_column = \"text\"\n",
    "summary_column = \"event\"\n",
    "inputs = train_dataset[text_column]\n",
    "targets = train_dataset[summary_column]\n",
    "padding = \"max_length\"\n",
    "model_inputs = tokenizer(inputs, max_length= 256, padding=padding, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4af0368d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dd561b",
   "metadata": {},
   "source": [
    "# New data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bbf9842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from data_convert.format.text2tree import Text2Tree\n",
    "from data_convert.task_format.event_extraction import Event, DyIEPP\n",
    "from data_convert.utils import read_file, check_output, data_counter_to_table, get_schema, output_schema\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "target_class=Text2Tree\n",
    "type_format='subtype'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71cf6f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/17172 [00:00<00:00, 37560.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "in_filename = \"data/raw_data/ace05-EN/train.oneie.json\"\n",
    "output_filename = \"data/new_text2tree/ace2005_event/dev\"\n",
    "if not os.path.exists(output_filename):\n",
    "        os.makedirs(output_filename)\n",
    "event_output = open(output_filename + '.json', 'w')\n",
    "\n",
    "count = 0\n",
    "number = 0\n",
    "for line in read_file(in_filename):\n",
    "    document = Event(json.loads(line.strip()))\n",
    "    if len(document.entities) > 3:\n",
    "        break\n",
    "    for sentence in document.generate_relations():\n",
    "        number += 1\n",
    "        if(len(sentence['relations']) == 0):\n",
    "            count += 1\n",
    "print(count)\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8784edf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17172 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "in_filename = \"data/raw_data/ace05-EN/train.oneie.json\"\n",
    "output_filename = \"data/new_text2tree/ace2005_event/dev\"\n",
    "if not os.path.exists(output_filename):\n",
    "        os.makedirs(output_filename)\n",
    "event_output = open(output_filename + '.json', 'w')\n",
    "\n",
    "count = 0\n",
    "number = 0\n",
    "for line in read_file(in_filename):\n",
    "    document = Event(json.loads(line.strip()))\n",
    "    sentences = document.generate_relations()\n",
    "    for sentence in sentences:\n",
    "        if(len(sentence['relations']) > 0):\n",
    "            print(sentence['relations'])\n",
    "            break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ea3a75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for sentence in document.generate_relations():\n",
    "    print(sentence['relations'])\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52d6380e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 127.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "in_filename = \"data/datasets/conll04/conll04_train.json\"\n",
    "count = 0\n",
    "number = 0\n",
    "entity_set = set()\n",
    "relation_type_set = set()\n",
    "for line in read_file(in_filename):\n",
    "    for line_ in json.loads(line.strip()):\n",
    "        for entity in line_['entities']:\n",
    "            entity_set.add(entity['type'])\n",
    "        for relation in line_['relations']:\n",
    "            relation_type_set.add(relation['type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2194357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Org', 'Peop', 'Other', 'Loc'}\n",
      "{'Live_In', 'Kill', 'Located_In', 'OrgBased_In', 'Work_For'}\n"
     ]
    }
   ],
   "source": [
    "print(entity_set)\n",
    "print(relation_type_set)\n",
    "conll04_train_dev\n",
    "/data/datasets/conll04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88e88bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English', 'is', 'shown', 'to', 'be', 'trans-context-free', 'on', 'the', 'basis', 'of', 'coordinations', 'of', 'the', 'respectively', 'type', 'that', 'involve', 'strictly', 'syntactic', 'cross-serial', 'agreement', '.']\n",
      "[]\n",
      "[[0, 0, 'Material'], [10, 10, 'OtherScientificTerm'], [17, 20, 'OtherScientificTerm']]\n",
      " \n",
      "['The', 'agreement', 'in', 'question', 'involves', 'number', 'in', 'nouns', 'and', 'reflexive', 'pronouns', 'and', 'is', 'syntactic', 'rather', 'than', 'semantic', 'in', 'nature', 'because', 'grammatical', 'number', 'in', 'English', ',', 'like', 'grammatical', 'gender', 'in', 'languages', 'such', 'as', 'French', ',', 'is', 'partly', 'arbitrary', '.']\n",
      "[[29, 29, 31, 32, 'CONJUNCTION'], [48, 49, 51, 51, 'FEATURE-OF'], [54, 54, 51, 51, 'HYPONYM-OF']]\n",
      "[[23, 23, 'Generic'], [29, 29, 'OtherScientificTerm'], [31, 32, 'OtherScientificTerm'], [42, 43, 'OtherScientificTerm'], [45, 45, 'Material'], [48, 49, 'OtherScientificTerm'], [51, 51, 'Material'], [54, 54, 'Material']]\n",
      " \n",
      "['The', 'formal', 'proof', ',', 'which', 'makes', 'crucial', 'use', 'of', 'the', 'Interchange', 'Lemma', 'of', 'Ogden', 'et', 'al.', ',', 'is', 'so', 'constructed', 'as', 'to', 'be', 'valid', 'even', 'if', 'English', 'is', 'presumed', 'to', 'contain', 'grammatical', 'sentences', 'in', 'which', 'respectively', 'operates', 'across', 'a', 'pair', 'of', 'coordinate', 'phrases', 'one', 'of', 'whose', 'members', 'has', 'fewer', 'conjuncts', 'than', 'the', 'other', ';', 'it', 'thus', 'goes', 'through', 'whatever', 'the', 'facts', 'may', 'be', 'regarding', 'constructions', 'with', 'unequal', 'numbers', 'of', 'conjuncts', 'in', 'the', 'scope', 'of', 'respectively', ',', 'whereas', 'other', 'arguments', 'have', 'foundered', 'on', 'this', 'problem', '.']\n",
      "[]\n",
      "[[70, 71, 'Method'], [86, 86, 'Material']]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for relations_in_sentence, sentence_start, sentence, entity in zip(document.relations, document.sentence_start, document.sentences, document.ner):\n",
    "    print(sentence)\n",
    "    print(relations_in_sentence)\n",
    "    print(entity)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a86229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_relations(document):\n",
    "    relations = list()\n",
    "    for relation in document.relations:\n",
    "        arguments = list()\n",
    "        relation_type = relation['relation_type']\n",
    "        for argument in relation['arguments']:\n",
    "            argument_entity = document.entities[argument['entity_id']]\n",
    "            arguments += [list(range(argument_entity['start'], argument_entity['end']))]\n",
    "        for old_relation in relations:\n",
    "            if relation_type == old_relation['type']:\n",
    "                old_relation['arguments'].append(arguments)\n",
    "                continue\n",
    "        relations += [{'type': relation_type, 'arguments': [arguments]}]\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f9339fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_237158/2908624768.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrelations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_relations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_237158/588670879.py\u001b[0m in \u001b[0;36mgenerate_relations\u001b[0;34m(document)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrelation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0marguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mrelation_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'relation_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0margument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arguments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0margument_entity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entity_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "relations = generate_relations(document)\n",
    "print(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9dd2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_relation(document):\n",
    "    for relations_in_sentence, sentence_start in zip(document.relations, document.sentence_start):\n",
    "        relations = list()\n",
    "        type_set = set()\n",
    "        for relation in relations_in_sentence:\n",
    "#             'arguments': [['Arg-1', [9]], ['Arg-2', [14]]]\n",
    "            arguments = [list(range(relation[0]-sentence_start, relation[1]+1-sentence_start)),\n",
    "                         list(range(relation[2]-sentence_start,relation[3]+1-sentence_start))]\n",
    "            relation_type = relation[4].split('.')[0]\n",
    "            if relation_type in type_set:\n",
    "                for old_relation in relations:\n",
    "                    if relation_type == old_relation['type']:\n",
    "                        old_relation['arguments'].append(arguments)\n",
    "            else:\n",
    "                type_set.add(relation_type)\n",
    "                relations += [{'type': relation_type, 'arguments': [arguments]}]\n",
    "        print(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "524e8880",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Event' object has no attribute 'sentence_start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44862/1193920764.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_relation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_44862/3006856016.py\u001b[0m in \u001b[0;36mgenerate_relation\u001b[0;34m(document)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_relation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrelations_in_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_start\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mrelations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtype_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrelation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelations_in_sentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Event' object has no attribute 'sentence_start'"
     ]
    }
   ],
   "source": [
    "generate_relation(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2643b0b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Event' object has no attribute 'ner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_836619/1813248004.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mName_Entity_Type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents_in_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_start\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents_in_sentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrigger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Event' object has no attribute 'ner'"
     ]
    }
   ],
   "source": [
    "Name_Entity_Type = set()\n",
    "for ner, sentence, events_in_sentence, sentence_start in zip(document.ner , document.sentences, document.events, document.sentence_start):\n",
    "    events = list()\n",
    "    for event in events_in_sentence:\n",
    "        trigger, event_type = event[0]\n",
    "        trigger_ner = ner\n",
    "        trigger -= sentence_start\n",
    "\n",
    "        suptype, subtype = event_type.split('.')\n",
    "\n",
    "        if type_format == 'subtype':\n",
    "            event_type = subtype\n",
    "        elif type_format == 'suptype':\n",
    "            event_type = suptype\n",
    "        else:\n",
    "            event_type = suptype + type_format + subtype\n",
    "\n",
    "        arguments = list()\n",
    "        for start, end, role in event[1:]:\n",
    "            start -= sentence_start\n",
    "            end -= sentence_start\n",
    "            arguments += [[role, list(range(start, end + 1))]]\n",
    "\n",
    "        for argument in arguments:\n",
    "            for ner_pos in ner:\n",
    "                Name_Entity_Type.add(ner_pos[2])\n",
    "                if((ner_pos[0]-sentence_start) == argument[1][0]):\n",
    "                    argument.insert(1, ner_pos[2])\n",
    "            if(len(argument) != 3):\n",
    "                print(\"Wrong\")\n",
    "\n",
    "        event = {'type': event_type, 'tokens': [trigger], 'arguments': arguments}\n",
    "\n",
    "        events += [event]\n",
    "#         print(events)\n",
    "        if(len(event['arguments']) >1):\n",
    "            A_predict = {'tokens': sentence, 'events': events}\n",
    "# print(A_predict)\n",
    "print(Name_Entity_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "93312b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4674, 517, 1]\n",
      "[3, 8575, 566, 1]\n",
      "[9664, 188, 1]\n",
      "[301, 5618, 1]\n",
      "[377, 5173, 1]\n",
      "[3, 8742, 1]\n",
      "[350, 5668, 1]\n",
      "[32099, 1]\n"
     ]
    }
   ],
   "source": [
    "list_A = ['ORG', 'VEH', 'WEA', 'LOC', 'FAC', 'PER', 'GPE']\n",
    "for a in list_A:\n",
    "    entity_token = tokenizer.encode(a)\n",
    "    print(entity_token)\n",
    "print(tokenizer.encode('<extra_id_0>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e6adf2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32100, 32101, 32102, 32103, 32104, 8742, 32105]\n",
      "Wrong\n",
      "LOC\n",
      "0\n",
      "1.2132\n"
     ]
    }
   ],
   "source": [
    "entity_dic = {'ORG', 'VEH', 'WEA', 'LOC', 'FAC', 'PER', 'GPE'}\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": list_A})\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(tokenizer.convert_tokens_to_ids(list_A))\n",
    "if 'ORG' in list_A:\n",
    "    print(\"Wrong\")\n",
    "    \n",
    "print(tokenizer.decode(32103))\n",
    "print(tokenizer.pad_token_id)\n",
    "a = 1.213232\n",
    "b = round(a, 4)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41e4423",
   "metadata": {},
   "source": [
    "# OneIE data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00e04633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'Attack', 'tokens': [8], 'arguments': []}]\n",
      "[{'type': 'Attack', 'tokens': [8], 'arguments': []}, {'type': 'End-Position', 'tokens': [10], 'arguments': [['Person', 'PER', [12, 13]], ['Entity', 'GPE', [17]]]}]\n"
     ]
    }
   ],
   "source": [
    "events = list()\n",
    "# print(document.events)\n",
    "# print(document.entities)\n",
    "for event, entity in zip(document.events, document.entities):\n",
    "#     print(event)\n",
    "#     print(entity)\n",
    "    arguments = list()\n",
    "    for argument in event['arguments']:\n",
    "        argument_entity = document.entities[argument['entity_id']]\n",
    "#         print(\"argument_entity\", argument_entity)\n",
    "        arguments += [[argument['role'], argument_entity['entity_type'] ,list(range(argument_entity['start'], argument_entity['end']))]]\n",
    "\n",
    "    suptype, subtype = event['event_type'].split(':')\n",
    "\n",
    "    if type_format == 'subtype':\n",
    "        event_type = subtype\n",
    "    elif type_format == 'suptype':\n",
    "        event_type = suptype\n",
    "    else:\n",
    "        event_type = suptype + type_format + subtype\n",
    "\n",
    "    events += [{\n",
    "        'type': event_type,\n",
    "        'tokens': list(range(event['trigger']['start'], event['trigger']['end'])),\n",
    "        'arguments': arguments\n",
    "    }]\n",
    "    print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b8750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ner, sentence, events_in_sentence, sentence_start in zip(document.ner , document.sentences, document.events, document.sentence_start):\n",
    "        if(len(ner) > 0):\n",
    "            print((ner))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410da613",
   "metadata": {},
   "source": [
    "# Annotated from event text to tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e92ed6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_convert.utils import read_file, check_output, data_counter_to_table, get_schema, output_schema\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "type_start = '<extra_id_0>'\n",
    "type_end = '<extra_id_1>'\n",
    "role_start = '<extra_id_2>'\n",
    "role_end = '<extra_id_3>'\n",
    "\n",
    "def get_str_from_tokens(tokens, sentence, separator=' '):\n",
    "    start, end_exclude = tokens[0], tokens[-1] + 1\n",
    "    return separator.join(sentence[start:end_exclude])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56f1ce63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Attack', 'tokens': [7], 'arguments': [['Attacker', 'PER', [5]], ['Attacker', 'PER', [14]], ['Attacker', 'PER', [19]]]}\n",
      "fight\n",
      "{('Attack', 'Attacker')}\n"
     ]
    }
   ],
   "source": [
    "event_schema_set = set()\n",
    "\n",
    "for event in A_predict['events']:\n",
    "    print(event)\n",
    "    event_schema_set = event_schema_set | get_schema(event)\n",
    "    sep = ' '\n",
    "    predicate = sep.join([A_predict['tokens'][index]\n",
    "                          for index in event['tokens']])\n",
    "#     counter['pred'].update([predicate])\n",
    "#     counter['type'].update([event['type']])\n",
    "#     data_counter[in_filename].update(['event'])\n",
    "#     for argument in event['arguments']:\n",
    "#         data_counter[in_filename].update(['argument'])\n",
    "#         counter['role'].update([argument[0]])\n",
    "\n",
    "print(predicate)\n",
    "print(event_schema_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ad2a636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Britain has deployed some 45,000 troops to fight with the more than 250,000 US soldiers lined up against Iraqi troops .\n",
      " \n",
      "<extra_id_0> <extra_id_0> Attack fight <extra_id_0> Attacker PER troops <extra_id_1> <extra_id_0> Attacker PER soldiers <extra_id_1> <extra_id_0> Attacker PER troops <extra_id_1> <extra_id_1> <extra_id_1>\n"
     ]
    }
   ],
   "source": [
    "tokens=A_predict['tokens']\n",
    "predicate_arguments=A_predict['events']\n",
    "\n",
    "token_separator = ' '\n",
    "\n",
    "event_str_rep_list = list()\n",
    "\n",
    "for predicate_argument in predicate_arguments:\n",
    "    event_type = predicate_argument['type']\n",
    "\n",
    "    # predicate_argument['tokens'] is the trigger index\n",
    "    # tokens is the sentence tokens, we get the trigger text span here\n",
    "    predicate_text = get_str_from_tokens(predicate_argument['tokens'], tokens, separator=token_separator)\n",
    "\n",
    "    # prefix_tokens[predicate_argument['tokens'][0]] = ['[ ']\n",
    "    # suffix_tokens[predicate_argument['tokens'][-1]] = [' ]']\n",
    "\n",
    "    role_str_list = list()\n",
    "    # role_name is the argument role, role_tokens are corresponding text span index\n",
    "    for role_name, role_entity, role_tokens in predicate_argument['arguments']:\n",
    "        # if role_name == 'Place' or role_name.startswith('Time'):\n",
    "        if role_name == event_type:\n",
    "            continue\n",
    "        # get the role text span from role tokens index\n",
    "        role_text = get_str_from_tokens(role_tokens, tokens, separator=token_separator)\n",
    "#         print(role_text)\n",
    "#         print(role_entity)\n",
    "        if False:\n",
    "            role_str = ' '.join([role_start, role_name, role_entity ,role_text, role_end])\n",
    "        else:\n",
    "            role_str = ' '.join([type_start, role_name,role_entity ,role_text, type_end])\n",
    "        # All arguments in the sentence\n",
    "#         print(role_str)\n",
    "        role_str_list += [role_str]\n",
    "    role_str_list_str = ' '.join(role_str_list)\n",
    "    event_str_rep = f\"{type_start} {event_type} {predicate_text} {role_str_list_str} {type_end}\"\n",
    "    event_str_rep_list += [event_str_rep]\n",
    "\n",
    "# print(tokens)    \n",
    "source_text = token_separator.join(tokens)\n",
    "target_text = ' '.join(event_str_rep_list)\n",
    "\n",
    "if not False:\n",
    "    target_text = f'{type_start} ' + \\\n",
    "                    ' '.join(event_str_rep_list) + f' {type_end}'\n",
    "\n",
    "print(source_text) \n",
    "print(\" \")\n",
    "print(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "db7691c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['type_start  type_end', 'type_start  type_end']\n"
     ]
    }
   ],
   "source": [
    "a = [\"%s%s\" % (\"type_start  \", \"type_end\")] * 2\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61858c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ab2f49d",
   "metadata": {},
   "source": [
    "# Get Label Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90a5a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_name_tree(label_name_list, tokenizer, end_symbol='<end>'):\n",
    "    # Change recurring into non-recurring labels, \n",
    "    sub_token_tree = dict()\n",
    "\n",
    "    # this is label_name token ids\n",
    "    label_tree = dict()\n",
    "    for typename in label_name_list:\n",
    "#         print(typename)\n",
    "        after_tokenized = tokenizer.encode(typename)\n",
    "        label_tree[typename] = after_tokenized\n",
    "    print(label_tree)\n",
    "    for _, sub_label_seq in label_tree.items():\n",
    "        # sub_label_seq is the tokenize_ids of typename\n",
    "        parent = sub_token_tree\n",
    "        for value in sub_label_seq:\n",
    "            if value not in parent:\n",
    "                parent[value] = dict()\n",
    "            parent = parent[value]\n",
    "        parent[end_symbol] = None\n",
    "\n",
    "    return sub_token_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2639a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Extradite': [8505, 10700, 1], 'Sentence': [4892, 17, 1433, 1], 'Trial-Hearing': [20660, 18, 3845, 9, 1007, 1], 'Die': [316, 1], 'Elect': [3, 21543, 1], 'Declare-Bankruptcy': [28596, 60, 18, 21347, 9433, 75, 63, 1], 'Appeal': [25024, 1], 'Attack': [24655, 1], 'Merge-Org': [4039, 397, 18, 7395, 122, 1], 'Charge-Indict': [15907, 18, 1570, 12194, 1], 'Release-Parole': [13048, 18, 13212, 32, 109, 1], 'Divorce': [2043, 1967, 565, 1], 'Pardon': [2180, 2029, 1], 'Sue': [17564, 1], 'Start-Position': [3273, 18, 345, 32, 7, 4749, 1], 'Meet': [12325, 1], 'Demonstrate': [15782, 29, 7, 17, 2206, 1], 'Execute': [25183, 15, 1], 'Convict': [1193, 7287, 17, 1], 'Transport': [7608, 1], 'Transfer-Ownership': [9900, 18, 667, 210, 687, 2009, 1], 'Arrest-Jail': [1533, 6216, 18, 683, 9, 173, 1], 'Start-Org': [3273, 18, 7395, 122, 1], 'Transfer-Money': [9900, 18, 9168, 15, 63, 1], 'Phone-Write': [8924, 18, 24965, 15, 1], 'End-Position': [3720, 18, 345, 32, 7, 4749, 1], 'Fine': [11456, 1], 'End-Org': [3720, 18, 7395, 122, 1], 'Acquit': [4292, 10073, 1], 'Nominate': [465, 51, 8660, 1], 'Be-Born': [493, 18, 279, 127, 29, 1], 'Injure': [86, 10609, 15, 1], 'Marry': [1571, 651, 1]}\n"
     ]
    }
   ],
   "source": [
    "from extraction.event_schema import EventSchema\n",
    "event_schema = './data/text2tree/dyiepp_ace2005_subtype/event.schema'\n",
    "decoding_type_schema = EventSchema.read_from_file(event_schema)\n",
    "# print(decoding_type_schema.type_list)\n",
    "# print(decoding_type_schema.role_list)\n",
    "# print(decoding_type_schema.type_role_dict)\n",
    "type_tree = get_label_name_tree(decoding_type_schema.type_list, tokenizer, end_symbol='<tree-end>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2eb6d37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{210: {687: {2009: {1: {'<tree-end>': None}}}}}\n"
     ]
    }
   ],
   "source": [
    "# print(list(type_tree.keys()))\n",
    "# print(\" \")\n",
    "subtree = type_tree[9900][18][667]\n",
    "print(len(subtree))\n",
    "print(subtree)\n",
    "if '<tree-end>' in subtree:\n",
    "    print(\"end_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0452bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Plaintiff': [30837, 1], 'Instrument': [13507, 1], 'Person': [5780, 1], 'Entity': [4443, 485, 1], 'Beneficiary': [30570, 1208, 1], 'Adjudicator': [1980, 14312, 447, 1016, 1], 'Seller': [19980, 1], 'Prosecutor': [749, 7, 15, 3044, 127, 1], 'Artifact': [1261, 23, 8717, 1], 'Vehicle': [15095, 1], 'Attacker': [24655, 49, 1], 'Origin': [19477, 1], 'Victim': [12060, 2998, 1], 'Defendant': [3, 16196, 989, 288, 1], 'Agent': [8628, 1], 'Org': [955, 122, 1], 'Buyer': [19099, 1], 'Place': [3399, 1], 'Destination': [19344, 257, 1], 'Target': [12615, 1], 'Recipient': [419, 3389, 4741, 1], 'Giver': [6434, 52, 1]}\n",
      "dict_keys([30837, 13507, 5780, 4443, 30570, 1980, 19980, 749, 1261, 15095, 24655, 19477, 12060, 3, 8628, 955, 19099, 3399, 19344, 12615, 419, 6434])\n",
      "{30837: {1: {'<tree-end>': None}}, 13507: {1: {'<tree-end>': None}}, 5780: {1: {'<tree-end>': None}}, 4443: {485: {1: {'<tree-end>': None}}}, 30570: {1208: {1: {'<tree-end>': None}}}, 1980: {14312: {447: {1016: {1: {'<tree-end>': None}}}}}, 19980: {1: {'<tree-end>': None}}, 749: {7: {15: {3044: {127: {1: {'<tree-end>': None}}}}}}, 1261: {23: {8717: {1: {'<tree-end>': None}}}}, 15095: {1: {'<tree-end>': None}}, 24655: {49: {1: {'<tree-end>': None}}}, 19477: {1: {'<tree-end>': None}}, 12060: {2998: {1: {'<tree-end>': None}}}, 3: {16196: {989: {288: {1: {'<tree-end>': None}}}}}, 8628: {1: {'<tree-end>': None}}, 955: {122: {1: {'<tree-end>': None}}}, 19099: {1: {'<tree-end>': None}}, 3399: {1: {'<tree-end>': None}}, 19344: {257: {1: {'<tree-end>': None}}}, 12615: {1: {'<tree-end>': None}}, 419: {3389: {4741: {1: {'<tree-end>': None}}}}, 6434: {52: {1: {'<tree-end>': None}}}}\n"
     ]
    }
   ],
   "source": [
    "role_tree = get_label_name_tree(decoding_type_schema.role_list, tokenizer, end_symbol='<tree-end>')\n",
    "print(role_tree.keys())\n",
    "print(role_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b5221c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{30837: {1: {'<tree-end>': None}}, 13507: {1: {'<tree-end>': None}}, 5780: {1: {'<tree-end>': None}}, 4443: {485: {1: {'<tree-end>': None}}}, 30570: {1208: {1: {'<tree-end>': None}}}, 1980: {14312: {447: {1016: {1: {'<tree-end>': None}}}}}, 19980: {1: {'<tree-end>': None}}, 749: {7: {15: {3044: {127: {1: {'<tree-end>': None}}}}}}, 1261: {23: {8717: {1: {'<tree-end>': None}}}}, 15095: {1: {'<tree-end>': None}}, 24655: {49: {1: {'<tree-end>': None}}}, 19477: {1: {'<tree-end>': None}}, 12060: {2998: {1: {'<tree-end>': None}}}, 3: {16196: {989: {288: {1: {'<tree-end>': None}}}}}, 8628: {1: {'<tree-end>': None}}, 955: {122: {1: {'<tree-end>': None}}}, 19099: {1: {'<tree-end>': None}}, 3399: {1: {'<tree-end>': None}}, 19344: {257: {1: {'<tree-end>': None}}}, 12615: {1: {'<tree-end>': None}}, 419: {3389: {4741: {1: {'<tree-end>': None}}}}, 6434: {52: {1: {'<tree-end>': None}}}}\n"
     ]
    }
   ],
   "source": [
    "print(role_tree)\n",
    "if('<tree-end>' in role_tree):\n",
    "    print(\"Wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "be1a067d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<tree-end>': None}\n",
      "Wrong\n"
     ]
    }
   ],
   "source": [
    "first_tree = role_tree[30837]\n",
    "print(first_tree[1])\n",
    "if '<tree-end>' in first_tree[1]:\n",
    "    print(\"Wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e726fd3",
   "metadata": {},
   "source": [
    "# Transform output to Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8e19e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bracket(_text):\n",
    "    # replace the special token labels to Formal statement\n",
    "    _text = add_space(_text)\n",
    "    for start in [role_start, type_start]:\n",
    "        _text = _text.replace(start, left_bracket)\n",
    "    for end in [role_end, type_end]:\n",
    "        _text = _text.replace(end, right_bracket)\n",
    "    return _text\n",
    "\n",
    "def add_space(text):\n",
    "    \"\"\"\n",
    "    add space between special token\n",
    "    :param text:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_text_list = list()\n",
    "    for item in zip(split_bracket.findall(text), split_bracket.split(text)[1:]):\n",
    "        new_text_list += item\n",
    "    return ' '.join(new_text_list)\n",
    "\n",
    "def get_tree_str(tree):\n",
    "    \"\"\"\n",
    "    get str from event tree\n",
    "    :param tree:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    str_list = list()\n",
    "    for element in tree:\n",
    "        if isinstance(element, str):\n",
    "            str_list += [element]\n",
    "    return ' '.join(str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39af0a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<extra_id_0> <extra_id_0> ORG-AFF <extra_id_0> Minister <extra_id_0> British <extra_id_1> <extra_id_1> ORG-AFF <extra_id_1> <extra_id_0> PART-WHOLE <extra_id_0> Grand Hotel Europe <extra_id_0> Saint Petersburg <extra_id_1> <extra_id_1> PART-WHOLE <extra_id_1> <extra_id_1>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "left_bracket = '【'\n",
    "right_bracket = '】'\n",
    "text = \"<extra_id_0> <extra_id_0> ORG-AFF <extra_id_0> Minister <extra_id_0> British <extra_id_1> <extra_id_1> ORG-AFF <extra_id_1> <extra_id_0> PART-WHOLE <extra_id_0> Grand Hotel Europe <extra_id_0> Saint Petersburg <extra_id_1> <extra_id_1> PART-WHOLE <extra_id_1> <extra_id_1>\"\n",
    "from nltk.tree import ParentedTree\n",
    "brackets = left_bracket + right_bracket\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8113a5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<extra_id_0>   <extra_id_0>  ORG-AFF  <extra_id_0>  Minister  <extra_id_0>  British  <extra_id_1>   <extra_id_1>  ORG-AFF  <extra_id_1>   <extra_id_0>  PART-WHOLE  <extra_id_0>  Grand Hotel Europe  <extra_id_0>  Saint Petersburg  <extra_id_1>   <extra_id_1>  PART-WHOLE  <extra_id_1>   <extra_id_1> \n"
     ]
    }
   ],
   "source": [
    "split_bracket = re.compile(r\"<extra_id_\\d>\")\n",
    "new_text_list = list()\n",
    "for item in zip(split_bracket.findall(text), split_bracket.split(text)[1:]):\n",
    "    new_text_list += item\n",
    "print(' '.join(new_text_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4b2eaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【   【  ORG-AFF  【  Minister  【  British  】   】  ORG-AFF  】   【  PART-WHOLE  【  Grand Hotel Europe  【  Saint Petersburg  】   】  PART-WHOLE  】   】 \n"
     ]
    }
   ],
   "source": [
    "new_text = convert_bracket(text)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7fba06aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_tree = ParentedTree.fromstring(new_text, brackets=brackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "23f5c276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "  (ORG-AFF (Minister (British )) ORG-AFF)\n",
      "  (PART-WHOLE (Grand Hotel Europe (Saint Petersburg)) PART-WHOLE))\n"
     ]
    }
   ],
   "source": [
    "print(gold_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a82b518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG-AFF\n",
      "Minister   aa  British \n",
      "end ORG-AFF\n",
      "PART-WHOLE\n",
      "Grand Hotel Europe  aa  Saint Petersburg\n",
      "end PART-WHOLE\n"
     ]
    }
   ],
   "source": [
    "str_list = list()\n",
    "for relation_tree in gold_tree:\n",
    "    print(relation_tree.label())\n",
    "    for role_tree in relation_tree:\n",
    "        if isinstance(role_tree, str):\n",
    "            print(\"end\", role_tree)\n",
    "        else:\n",
    "            role1_text = role_tree.label() + ' ' + get_tree_str(role_tree)\n",
    "            role2_text = role_tree[-1].label() + ' '+get_tree_str(role_tree[-1])\n",
    "            print(role1_text + \"  aa  \"+ role2_text)\n",
    "#         print(role_tree.label()+ ' ' +a)\n",
    "#         print(role_tree[-1].label() + ' '+get_tree_str(role_tree[-1]))\n",
    "#         print(role_tree[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ee926d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kind = ' '.join(str_list)\n",
    "print(kind)\n",
    "new_kind = ' '.join(kind.split(' ')[1:])\n",
    "print(new_kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "aa2f458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LOC', 'ORG', 'VEH', 'FAC', 'PER', 'WEA', 'GPE', ' ']\n"
     ]
    }
   ],
   "source": [
    "b = []\n",
    "a = [\"LOC\", \"ORG\", \"VEH\", \"FAC\", \"PER\", \"WEA\", \"GPE\"]\n",
    "a.append(\" \")\n",
    "b =a\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61d1cfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LOC', 'ORG', 'VEH', 'FAC', 'PER', 'WEA', 'GPE', ' ', 1]\n"
     ]
    }
   ],
   "source": [
    "c = b+[1]\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24f17de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1cb04930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, '']\n"
     ]
    }
   ],
   "source": [
    "a = tokenizer.decode(3)\n",
    "b = [1,2,3]\n",
    "b.append(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8a39edb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1548, 3, 6, 38, 17952, 3859, 3292, 3457, 3, 6, 79, 33, 6326, 53, 3, 9, 775, 682, 13, 4719, 3, 6, 652, 5413, 13, 8, 7749, 9534, 45, 8, 10101, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "c = [0,1]\n",
    "print(c+a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "19a5e524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well  , as coalition forces push north  , they are encounter ing  a unique problem of combat  , getting rid of the weapons captured from the enemy  .\n"
     ]
    }
   ],
   "source": [
    "a =  [1548, 3, 6, 38, 17952, 3859, 3292, 3457, 3, 6, 79, 33, 6326, 53, 3, 9, 775, 682, 13, 4719, 3, 6, 652, 5413, 13, 8, 7749, 9534, 45, 8, 10101, 3, 5]\n",
    "b = list()\n",
    "for x in a:\n",
    "    b.append(tokenizer.decode(x))\n",
    "print(' '.join(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6da82dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Well', '', ',', 'as', 'coalition', 'forces', 'push', 'north', '', ',', 'they', 'are', 'encounter', 'ing', '', 'a', 'unique', 'problem', 'of', 'combat', '', ',', 'getting', 'rid', 'of', 'the', 'weapons', 'captured', 'from', 'the', 'enemy', '', '.']\n",
      "Well  , as coalition forces push north  , they are encounter ing  a unique problem of combat  , getting rid of the weapons captured from the enemy  .\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "labels = torch.tensor(a)\n",
    "decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=False)\n",
    "print(decoded_labels)\n",
    "print(' '.join(decoded_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7a662991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e6268beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, -1), (7, -1), (10, -2), (12, -2)]\n"
     ]
    }
   ],
   "source": [
    "special_token_set = {-1,-2}\n",
    "tgt_generated = [1,2,3,-1,2,3,2,-1,4,3,-2,4,-2]\n",
    "special_index_token = list(filter(lambda x: x[1] in special_token_set, list(enumerate(tgt_generated))))\n",
    "print(special_index_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bbc632aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad><extra_id_0><extra_id_0> PART-WHOLE<extra_id_0> Vivendi Universal<extra_id_0> media group<extra_id_0></s>\n"
     ]
    }
   ],
   "source": [
    "Target = [0, 32099, 32099, 4674, 517, 18, 188, 9089, 32099, 7471, 32099, 13143, 32099, 1]\n",
    "Target = [0, 32099, 32099, 3, 19846, 18, 518, 6299, 3765, 32099, 3, 19600, 989, 23, 12489, 32099, 783, 563, 32099, 1]\n",
    "text = tokenizer.decode(Target)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d7e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "Source = [2, 0, 7, 7, 7, 5]\n",
    "text2 = tokenizer.decode(Source)\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "37157c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "add_special_tokens\n",
    "print(tokenizer.sep_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8cf4f",
   "metadata": {},
   "source": [
    "# Test List in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "33d4a1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'relation': 1}]\n"
     ]
    }
   ],
   "source": [
    "record_list = list()\n",
    "record = {'relation': int}\n",
    "record['relation'] = 1\n",
    "record_list += [record]\n",
    "print(record_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b1ed815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'relation': 2}, {'relation': 2}]\n"
     ]
    }
   ],
   "source": [
    "record['relation'] = 2\n",
    "record_list += [record]\n",
    "print(record_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7dfb1cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9b84c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c55058a56784480959a0c71c1a45ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "Unable to load weights from pytorch checkpoint file for 'Babelscape/rebel-large' at '/home/wufeng/.cache/huggingface/transformers/0759d6afb2b4885699bd1f948cbbc28d9da3f97f6c71477ea72027efc50357b5.254c1b93946ad463de37ace02ecc0041c706e27f91f31c68a60ac76c340c9b88'. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/PURE/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m                     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PURE/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PURE/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: version_ <= kMaxSupportedFileFormatVersion INTERNAL ASSERT FAILED at /pytorch/caffe2/serialize/inline_container.cc:132, please report a bug to PyTorch. Attempted to read a PyTorch file with version 3, but the maximum supported version for reading is 2. Your PyTorch installation may be too old. (init at /pytorch/caffe2/serialize/inline_container.cc:132)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7f4070864193 in /home/wufeng/anaconda3/envs/PURE/lib/python3.8/site-packages/torch/lib/libc10.so)\nframe #1: caffe2::serialize::PyTorchStreamReader::init() + 0x1f5b (0x7f40739ec9eb in /home/wufeng/anaconda3/envs/PURE/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #2: caffe2::serialize::PyTorchStreamReader::PyTorchStreamReader(std::string const&) + 0x64 (0x7f40739edc04 in /home/wufeng/anaconda3/envs/PURE/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #3: <unknown function> + 0x6c1ef6 (0x7f40bb919ef6 in /home/wufeng/anaconda3/envs/PURE/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #4: <unknown function> + 0x295928 (0x7f40bb4ed928 in /home/wufeng/anaconda3/envs/PURE/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #5: <unknown function> + 0x13c7ae (0x562f435f77ae in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #6: _PyObject_MakeTpCall + 0x3bf (0x562f435ec25f in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #7: <unknown function> + 0x166d6a (0x562f43621d6a in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #8: PyObject_Call + 0x7d (0x562f435f257d in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #9: <unknown function> + 0xdc689 (0x562f43597689 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #10: _PyObject_MakeTpCall + 0x228 (0x562f435ec0c8 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #11: _PyEval_EvalFrameDefault + 0x5437 (0x562f43695e87 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #12: _PyEval_EvalCodeWithName + 0x888 (0x562f43687818 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #13: _PyFunction_Vectorcall + 0x594 (0x562f436887b4 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #14: <unknown function> + 0x1b9318 (0x562f43674318 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #15: _PyObject_MakeTpCall + 0x228 (0x562f435ec0c8 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #16: _PyEval_EvalFrameDefault + 0x4ef0 (0x562f43695940 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #17: _PyEval_EvalCodeWithName + 0x260 (0x562f436871f0 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #18: _PyFunction_Vectorcall + 0x594 (0x562f436887b4 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #19: _PyEval_EvalFrameDefault + 0x1517 (0x562f43691f67 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #20: _PyEval_EvalCodeWithName + 0x260 (0x562f436871f0 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #21: _PyFunction_Vectorcall + 0x594 (0x562f436887b4 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #22: <unknown function> + 0x166ca8 (0x562f43621ca8 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #23: PyObject_Call + 0x319 (0x562f435f2819 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #24: _PyEval_EvalFrameDefault + 0x1dd3 (0x562f43692823 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #25: _PyEval_EvalCodeWithName + 0x260 (0x562f436871f0 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #26: _PyFunction_Vectorcall + 0x594 (0x562f436887b4 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #27: <unknown function> + 0x166bde (0x562f43621bde in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #28: _PyEval_EvalFrameDefault + 0x4f81 (0x562f436959d1 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #29: _PyEval_EvalCodeWithName + 0x260 (0x562f436871f0 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #30: <unknown function> + 0x1f722f (0x562f436b222f in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #31: <unknown function> + 0x13bb0d (0x562f435f6b0d in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #32: _PyEval_EvalFrameDefault + 0x71a (0x562f4369116a in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #33: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #34: _PyEval_EvalFrameDefault + 0x1b5c (0x562f436925ac in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #35: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #36: _PyEval_EvalFrameDefault + 0x1b5c (0x562f436925ac in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #37: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #38: <unknown function> + 0x17cc45 (0x562f43637c45 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #39: _PyEval_EvalFrameDefault + 0x4bf (0x562f43690f0f in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #40: _PyFunction_Vectorcall + 0x1b7 (0x562f436883d7 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #41: _PyEval_EvalFrameDefault + 0x71a (0x562f4369116a in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #42: _PyFunction_Vectorcall + 0x1b7 (0x562f436883d7 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #43: _PyEval_EvalFrameDefault + 0x4bf (0x562f43690f0f in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #44: _PyEval_EvalCodeWithName + 0x260 (0x562f436871f0 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #45: _PyFunction_Vectorcall + 0x594 (0x562f436887b4 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #46: <unknown function> + 0x166ca8 (0x562f43621ca8 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #47: PyObject_Call + 0x319 (0x562f435f2819 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #48: _PyEval_EvalFrameDefault + 0x1dd3 (0x562f43692823 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #49: _PyEval_EvalCodeWithName + 0x888 (0x562f43687818 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #50: _PyFunction_Vectorcall + 0x594 (0x562f436887b4 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #51: <unknown function> + 0x166bde (0x562f43621bde in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #52: _PyEval_EvalFrameDefault + 0x1517 (0x562f43691f67 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #53: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #54: _PyEval_EvalFrameDefault + 0x1b5c (0x562f436925ac in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #55: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #56: _PyEval_EvalFrameDefault + 0x1b5c (0x562f436925ac in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #57: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #58: _PyEval_EvalFrameDefault + 0x1b5c (0x562f436925ac in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #59: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #60: _PyEval_EvalFrameDefault + 0x1b5c (0x562f436925ac in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #61: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #62: <unknown function> + 0xb439 (0x7f4103f8c439 in /home/wufeng/anaconda3/envs/PURE/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so)\nframe #63: _PyObject_MakeTpCall + 0x3bf (0x562f435ec25f in /home/wufeng/anaconda3/envs/PURE/bin/python)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/PURE/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m                         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m                             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"version\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m                                 raise OSError(\n",
      "\u001b[0;32m~/anaconda3/envs/PURE/lib/python3.8/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 64: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30288/2697748715.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Load model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Babelscape/rebel-large\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Babelscape/rebel-large\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m gen_kwargs = {\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PURE/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         raise ValueError(\n\u001b[1;32m    421\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PURE/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1370\u001b[0m                                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m                         raise OSError(\n\u001b[0m\u001b[1;32m   1373\u001b[0m                             \u001b[0;34mf\"Unable to load weights from pytorch checkpoint file for '{pretrained_model_name_or_path}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m                             \u001b[0;34mf\"at '{resolved_archive_file}'. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to load weights from pytorch checkpoint file for 'Babelscape/rebel-large' at '/home/wufeng/.cache/huggingface/transformers/0759d6afb2b4885699bd1f948cbbc28d9da3f97f6c71477ea72027efc50357b5.254c1b93946ad463de37ace02ecc0041c706e27f91f31c68a60ac76c340c9b88'. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "def extract_triplets(text):\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "    return triplets\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")\n",
    "gen_kwargs = {\n",
    "    \"max_length\": 256,\n",
    "    \"length_penalty\": 0,\n",
    "    \"num_beams\": 3,\n",
    "    \"num_return_sequences\": 3,\n",
    "}\n",
    "\n",
    "# Text to extract triplets from\n",
    "text = 'Punta Cana is a resort town in the municipality of Higüey, in La Altagracia Province, the easternmost province of the Dominican Republic.'\n",
    "\n",
    "# Tokenizer text\n",
    "model_inputs = tokenizer(text, max_length=256, padding=True, truncation=True, return_tensors = 'pt')\n",
    "\n",
    "# Generate\n",
    "generated_tokens = model.generate(\n",
    "    model_inputs[\"input_ids\"].to(model.device),\n",
    "    attention_mask=model_inputs[\"attention_mask\"].to(model.device),\n",
    "    **gen_kwargs,\n",
    ")\n",
    "\n",
    "# Extract text\n",
    "decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
    "\n",
    "# Extract triplets\n",
    "for idx, sentence in enumerate(decoded_preds):\n",
    "    print(f'Prediction triplets sentence {idx}')\n",
    "    print(extract_triplets(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bea83bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to load weights from pytorch checkpoint file for 'Babelscape/rebel-large' at '/home/wufeng/.cache/huggingface/transformers/0759d6afb2b4885699bd1f948cbbc28d9da3f97f6c71477ea72027efc50357b5.254c1b93946ad463de37ace02ecc0041c706e27f91f31c68a60ac76c340c9b88'. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/PURE/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m                     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PURE/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PURE/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: version_ <= kMaxSupportedFileFormatVersion INTERNAL ASSERT FAILED at /pytorch/caffe2/serialize/inline_container.cc:132, please report a bug to PyTorch. Attempted to read a PyTorch file with version 3, but the maximum supported version for reading is 2. Your PyTorch installation may be too old. (init at /pytorch/caffe2/serialize/inline_container.cc:132)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7f4070864193 in /home/wufeng/anaconda3/envs/PURE/lib/python3.8/site-packages/torch/lib/libc10.so)\nframe #1: caffe2::serialize::PyTorchStreamReader::init() + 0x1f5b (0x7f40739ec9eb in /home/wufeng/anaconda3/envs/PURE/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #2: caffe2::serialize::PyTorchStreamReader::PyTorchStreamReader(std::string const&) + 0x64 (0x7f40739edc04 in /home/wufeng/anaconda3/envs/PURE/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #3: <unknown function> + 0x6c1ef6 (0x7f40bb919ef6 in /home/wufeng/anaconda3/envs/PURE/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #4: <unknown function> + 0x295928 (0x7f40bb4ed928 in /home/wufeng/anaconda3/envs/PURE/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #5: <unknown function> + 0x13c7ae (0x562f435f77ae in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #6: _PyObject_MakeTpCall + 0x3bf (0x562f435ec25f in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #7: <unknown function> + 0x166d6a (0x562f43621d6a in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #8: PyObject_Call + 0x7d (0x562f435f257d in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #9: <unknown function> + 0xdc689 (0x562f43597689 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #10: _PyObject_MakeTpCall + 0x228 (0x562f435ec0c8 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #11: _PyEval_EvalFrameDefault + 0x5437 (0x562f43695e87 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #12: _PyEval_EvalCodeWithName + 0x888 (0x562f43687818 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #13: _PyFunction_Vectorcall + 0x594 (0x562f436887b4 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #14: <unknown function> + 0x1b9318 (0x562f43674318 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #15: _PyObject_MakeTpCall + 0x228 (0x562f435ec0c8 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #16: _PyEval_EvalFrameDefault + 0x4ef0 (0x562f43695940 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #17: _PyEval_EvalCodeWithName + 0x260 (0x562f436871f0 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #18: _PyFunction_Vectorcall + 0x594 (0x562f436887b4 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #19: _PyEval_EvalFrameDefault + 0x1517 (0x562f43691f67 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #20: _PyEval_EvalCodeWithName + 0x260 (0x562f436871f0 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #21: _PyFunction_Vectorcall + 0x594 (0x562f436887b4 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #22: <unknown function> + 0x166ca8 (0x562f43621ca8 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #23: PyObject_Call + 0x319 (0x562f435f2819 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #24: _PyEval_EvalFrameDefault + 0x1dd3 (0x562f43692823 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #25: _PyEval_EvalCodeWithName + 0x260 (0x562f436871f0 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #26: _PyFunction_Vectorcall + 0x594 (0x562f436887b4 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #27: <unknown function> + 0x166bde (0x562f43621bde in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #28: _PyEval_EvalFrameDefault + 0x4f81 (0x562f436959d1 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #29: _PyEval_EvalCodeWithName + 0x260 (0x562f436871f0 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #30: <unknown function> + 0x1f722f (0x562f436b222f in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #31: <unknown function> + 0x13bb0d (0x562f435f6b0d in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #32: _PyEval_EvalFrameDefault + 0x71a (0x562f4369116a in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #33: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #34: _PyEval_EvalFrameDefault + 0x1b5c (0x562f436925ac in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #35: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #36: _PyEval_EvalFrameDefault + 0x1b5c (0x562f436925ac in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #37: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #38: <unknown function> + 0x17cc45 (0x562f43637c45 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #39: _PyEval_EvalFrameDefault + 0x4bf (0x562f43690f0f in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #40: _PyFunction_Vectorcall + 0x1b7 (0x562f436883d7 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #41: _PyEval_EvalFrameDefault + 0x71a (0x562f4369116a in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #42: _PyFunction_Vectorcall + 0x1b7 (0x562f436883d7 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #43: _PyEval_EvalFrameDefault + 0x4bf (0x562f43690f0f in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #44: _PyEval_EvalCodeWithName + 0x260 (0x562f436871f0 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #45: _PyFunction_Vectorcall + 0x594 (0x562f436887b4 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #46: <unknown function> + 0x166ca8 (0x562f43621ca8 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #47: PyObject_Call + 0x319 (0x562f435f2819 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #48: _PyEval_EvalFrameDefault + 0x1dd3 (0x562f43692823 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #49: _PyEval_EvalCodeWithName + 0x888 (0x562f43687818 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #50: _PyFunction_Vectorcall + 0x594 (0x562f436887b4 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #51: <unknown function> + 0x166bde (0x562f43621bde in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #52: _PyEval_EvalFrameDefault + 0x1517 (0x562f43691f67 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #53: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #54: _PyEval_EvalFrameDefault + 0x1b5c (0x562f436925ac in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #55: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #56: _PyEval_EvalFrameDefault + 0x1b5c (0x562f436925ac in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #57: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #58: _PyEval_EvalFrameDefault + 0x1b5c (0x562f436925ac in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #59: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #60: _PyEval_EvalFrameDefault + 0x1b5c (0x562f436925ac in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #61: <unknown function> + 0x195462 (0x562f43650462 in /home/wufeng/anaconda3/envs/PURE/bin/python)\nframe #62: <unknown function> + 0xb439 (0x7f4103f8c439 in /home/wufeng/anaconda3/envs/PURE/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so)\nframe #63: _PyObject_MakeTpCall + 0x3bf (0x562f435ec25f in /home/wufeng/anaconda3/envs/PURE/bin/python)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/PURE/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m                         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m                             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"version\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m                                 raise OSError(\n",
      "\u001b[0;32m~/anaconda3/envs/PURE/lib/python3.8/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 64: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30288/3494269709.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Babelscape/rebel-large\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_name_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Babelscape/rebel-large\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/PURE/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         raise ValueError(\n\u001b[1;32m    421\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PURE/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1370\u001b[0m                                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m                         raise OSError(\n\u001b[0m\u001b[1;32m   1373\u001b[0m                             \u001b[0;34mf\"Unable to load weights from pytorch checkpoint file for '{pretrained_model_name_or_path}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m                             \u001b[0;34mf\"at '{resolved_archive_file}'. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to load weights from pytorch checkpoint file for 'Babelscape/rebel-large' at '/home/wufeng/.cache/huggingface/transformers/0759d6afb2b4885699bd1f948cbbc28d9da3f97f6c71477ea72027efc50357b5.254c1b93946ad463de37ace02ecc0041c706e27f91f31c68a60ac76c340c9b88'. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True."
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model_name_or_path = \"Babelscape/rebel-large\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7954a804",
   "metadata": {},
   "source": [
    "# Get  the label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2be2a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = './data/new_text2tree/ace_label/'\n",
    "if not os.path.exists(output_filename):\n",
    "        os.makedirs(output_filename)\n",
    "import json\n",
    "with open('./data/new_text2tree/one_ie_ace2005_subtype/test.json', 'r', encoding=\"utf-8\") as f:\n",
    "    # 读取所有行 每行会是一个字符串\n",
    "    for jsonstr in f.readlines():\n",
    "        # 将josn字符串转化为dict字典\n",
    "        jsonstr = json.loads(jsonstr)\n",
    "        with open(output_filename + 'test_end_before.json', 'a+', encoding='utf-8') as f2:\n",
    "            line = json.dumps(jsonstr[\"relation\"], ensure_ascii=False)\n",
    "            f2.write(line+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a3f46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
