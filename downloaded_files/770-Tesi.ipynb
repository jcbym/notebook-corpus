{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "touched-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sklearn.datasets as ds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mulearn import FuzzyInductor\n",
    "from mulearn.optimization import TensorFlowSolver\n",
    "from mulearn.kernel import GaussianKernel\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "def create_dataset(name):\n",
    "\n",
    "    #carico il dataset.\n",
    "    iris_X, iris_y = ds.load_iris(return_X_y=True)  # In iris_X matrice con i quattro valori per oggetto\n",
    "                                                    # In iris_y etichette rispettive (0,1,2)\n",
    "\n",
    "    labels = (\"Setosa\", \"Versicolor\", \"Virginica\") # Creo le etichette Setosa, Versicolor e Virginica\n",
    "\n",
    "    #creo dataframe con le etichette per i valori in iris_X \n",
    "    df = pd.DataFrame(iris_X, columns=[\"Sepal length\", \"Sepal width\",\n",
    "                                       \"Petal length\", \"Petal width\"])\n",
    "\n",
    "    #per i valori di iris_y associo le rispettive etichette\n",
    "    df['Class'] = iris_y\n",
    "    df['Class'] = df['Class'].map(lambda c: labels[c])\n",
    "\n",
    "    iris_dataset = iris_y.copy()\n",
    "\n",
    "    if(name == \"Setosa\"):\n",
    "        #creo dataset iris_setosa dove le etichette 0 diventano 1 e le altre a 0        \n",
    "        iris_dataset[iris_dataset != 0] = 2\n",
    "        iris_dataset[iris_dataset == 0] = 1\n",
    "        iris_dataset[iris_dataset == 2] = 0\n",
    "\n",
    "    if(name == \"Versicolor\"):\n",
    "        iris_dataset[iris_dataset==2] = 0\n",
    "    \n",
    "    if(name == \"Virginica\"):\n",
    "        iris_dataset[iris_dataset != 2] = 0\n",
    "        iris_dataset[iris_dataset == 2] = 1\n",
    "\n",
    "\n",
    "    return iris_X, iris_dataset\n",
    "\n",
    "\n",
    "def create_logger(path):   \n",
    "    \n",
    "    \n",
    "    fhandler = logging.FileHandler(filename = path)\n",
    "    \n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fhandler.setFormatter(formatter)\n",
    "    \n",
    "    logger.addHandler(fhandler)  \n",
    "    \n",
    "    return fhandler\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "demanding-breed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.24it/s]\n",
      "100%|██████████| 200/200 [00:36<00:00,  5.48it/s]\n",
      "100%|██████████| 300/300 [00:49<00:00,  6.08it/s]\n",
      "100%|██████████| 400/400 [01:06<00:00,  5.99it/s]\n",
      "100%|██████████| 500/500 [01:23<00:00,  5.99it/s]\n",
      "100%|██████████| 600/600 [01:43<00:00,  5.82it/s]\n",
      "100%|██████████| 700/700 [01:53<00:00,  6.14it/s]\n",
      "100%|██████████| 800/800 [02:08<00:00,  6.24it/s]\n",
      "100%|██████████| 900/900 [02:24<00:00,  6.24it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'FuzzyInductor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bf95135968b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensorflow not available'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fi impara iris_X con il confronto con le etichette vere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mrmse_tensorflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Tirocinio/Git/mulearn-main/mulearn/__init__.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, warm_start)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimated_membership_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fix_object_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         self.train_error_ = np.mean([(self.estimated_membership_(x) - mu) ** 2\n\u001b[0m\u001b[1;32m    143\u001b[0m                                      for x, mu in zip(X, y)])\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Tirocinio/Git/mulearn-main/mulearn/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimated_membership_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fix_object_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         self.train_error_ = np.mean([(self.estimated_membership_(x) - mu) ** 2\n\u001b[0m\u001b[1;32m    143\u001b[0m                                      for x, mu in zip(X, y)])\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'FuzzyInductor' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "handler = create_logger('./log/Setosa_c005_sigma01_penalization01.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 0.05\n",
    "sigma = 0.1\n",
    "    \n",
    "penalization = 0.1\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "logger.removeHandler(handler)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "palestinian-grammar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  5.96it/s]\n",
      "100%|██████████| 200/200 [00:33<00:00,  5.96it/s]\n",
      "100%|██████████| 300/300 [00:51<00:00,  5.86it/s]\n",
      "100%|██████████| 400/400 [01:03<00:00,  6.26it/s]\n",
      "100%|██████████| 500/500 [01:19<00:00,  6.27it/s]\n",
      "100%|██████████| 600/600 [01:53<00:00,  5.27it/s]\n",
      "100%|██████████| 700/700 [01:51<00:00,  6.28it/s]\n",
      "100%|██████████| 800/800 [02:07<00:00,  6.28it/s]\n",
      "100%|██████████| 900/900 [02:33<00:00,  5.85it/s]\n",
      "100%|██████████| 1000/1000 [02:53<00:00,  5.77it/s]\n",
      "100%|██████████| 1100/1100 [03:02<00:00,  6.04it/s]\n",
      "100%|██████████| 1200/1200 [03:12<00:00,  6.22it/s]\n",
      "100%|██████████| 1300/1300 [03:27<00:00,  6.26it/s]\n",
      "100%|██████████| 1400/1400 [03:44<00:00,  6.23it/s]\n",
      "100%|██████████| 1500/1500 [03:53<00:00,  6.42it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c005_sigma01_penalization01.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 0.05\n",
    "sigma = 0.1\n",
    "    \n",
    "penalization = 1\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unavailable-jefferson",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.46it/s]\n",
      "100%|██████████| 200/200 [00:30<00:00,  6.50it/s]\n",
      "100%|██████████| 300/300 [00:46<00:00,  6.44it/s]\n",
      "100%|██████████| 400/400 [01:01<00:00,  6.49it/s]\n",
      "100%|██████████| 500/500 [01:17<00:00,  6.49it/s]\n",
      "100%|██████████| 600/600 [01:32<00:00,  6.49it/s]\n",
      "100%|██████████| 700/700 [01:47<00:00,  6.51it/s]\n",
      "100%|██████████| 800/800 [02:03<00:00,  6.49it/s]\n",
      "100%|██████████| 900/900 [02:19<00:00,  6.46it/s]\n",
      "100%|██████████| 1000/1000 [02:34<00:00,  6.48it/s]\n",
      "100%|██████████| 1100/1100 [02:50<00:00,  6.45it/s]\n",
      "100%|██████████| 1200/1200 [03:05<00:00,  6.46it/s]\n",
      "100%|██████████| 1300/1300 [03:19<00:00,  6.50it/s]\n",
      "100%|██████████| 1400/1400 [03:35<00:00,  6.49it/s]\n",
      "100%|██████████| 1500/1500 [03:52<00:00,  6.45it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c005_sigma01_penalization10.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 0.05\n",
    "sigma = 0.1\n",
    "    \n",
    "penalization = 10\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "laughing-james",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.37it/s]\n",
      "100%|██████████| 200/200 [00:31<00:00,  6.41it/s]\n",
      "100%|██████████| 300/300 [00:46<00:00,  6.45it/s]\n",
      "100%|██████████| 400/400 [01:02<00:00,  6.45it/s]\n",
      "100%|██████████| 500/500 [01:17<00:00,  6.42it/s]\n",
      "100%|██████████| 600/600 [01:32<00:00,  6.46it/s]\n",
      "100%|██████████| 700/700 [01:48<00:00,  6.46it/s]\n",
      "100%|██████████| 800/800 [02:04<00:00,  6.43it/s]\n",
      "100%|██████████| 900/900 [02:19<00:00,  6.45it/s]\n",
      "100%|██████████| 1000/1000 [02:34<00:00,  6.46it/s]\n",
      "100%|██████████| 1100/1100 [02:50<00:00,  6.46it/s]\n",
      "100%|██████████| 1200/1200 [03:05<00:00,  6.46it/s]\n",
      "100%|██████████| 1300/1300 [03:21<00:00,  6.46it/s]\n",
      "100%|██████████| 1400/1400 [03:36<00:00,  6.46it/s]\n",
      "100%|██████████| 1500/1500 [03:51<00:00,  6.47it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c005_sigma01_penalization100.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 0.05\n",
    "sigma = 0.1\n",
    "    \n",
    "penalization = 100\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coordinate-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.46it/s]\n",
      "100%|██████████| 200/200 [00:31<00:00,  6.39it/s]\n",
      "100%|██████████| 300/300 [00:46<00:00,  6.47it/s]\n",
      "100%|██████████| 400/400 [01:01<00:00,  6.46it/s]\n",
      "100%|██████████| 500/500 [01:17<00:00,  6.44it/s]\n",
      "100%|██████████| 600/600 [01:32<00:00,  6.49it/s]\n",
      "100%|██████████| 700/700 [01:48<00:00,  6.45it/s]\n",
      "100%|██████████| 800/800 [02:03<00:00,  6.46it/s]\n",
      "100%|██████████| 900/900 [02:19<00:00,  6.44it/s]\n",
      "100%|██████████| 1000/1000 [02:35<00:00,  6.44it/s]\n",
      "100%|██████████| 1100/1100 [02:50<00:00,  6.44it/s]\n",
      "100%|██████████| 1200/1200 [03:05<00:00,  6.47it/s]\n",
      "100%|██████████| 1300/1300 [03:22<00:00,  6.42it/s]\n",
      "100%|██████████| 1400/1400 [03:36<00:00,  6.46it/s]\n",
      "100%|██████████| 1500/1500 [03:51<00:00,  6.47it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c005_sigma05_penalization01.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 0.05\n",
    "sigma = 0.5\n",
    "    \n",
    "penalization = 0.1\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "variable-mother",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.42it/s]\n",
      "100%|██████████| 200/200 [00:30<00:00,  6.49it/s]\n",
      "100%|██████████| 300/300 [00:46<00:00,  6.48it/s]\n",
      "100%|██████████| 400/400 [01:01<00:00,  6.48it/s]\n",
      "100%|██████████| 500/500 [01:17<00:00,  6.46it/s]\n",
      "100%|██████████| 600/600 [01:32<00:00,  6.45it/s]\n",
      "100%|██████████| 700/700 [01:48<00:00,  6.48it/s]\n",
      "100%|██████████| 800/800 [02:05<00:00,  6.39it/s]\n",
      "100%|██████████| 900/900 [02:18<00:00,  6.48it/s]\n",
      "100%|██████████| 1000/1000 [02:35<00:00,  6.43it/s]\n",
      "100%|██████████| 1100/1100 [02:50<00:00,  6.46it/s]\n",
      "100%|██████████| 1200/1200 [03:06<00:00,  6.44it/s]\n",
      "100%|██████████| 1300/1300 [03:21<00:00,  6.44it/s]\n",
      "100%|██████████| 1400/1400 [03:37<00:00,  6.44it/s]\n",
      "100%|██████████| 1500/1500 [03:53<00:00,  6.43it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c005_sigma05_penalization10.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 0.05\n",
    "sigma = 0.5\n",
    "    \n",
    "penalization = 10\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "normal-package",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.41it/s]\n",
      "100%|██████████| 200/200 [00:31<00:00,  6.44it/s]\n",
      "100%|██████████| 300/300 [00:47<00:00,  6.34it/s]\n",
      "100%|██████████| 400/400 [01:01<00:00,  6.48it/s]\n",
      "100%|██████████| 500/500 [01:17<00:00,  6.43it/s]\n",
      "100%|██████████| 600/600 [01:32<00:00,  6.46it/s]\n",
      "100%|██████████| 700/700 [01:48<00:00,  6.47it/s]\n",
      "100%|██████████| 800/800 [02:04<00:00,  6.44it/s]\n",
      "100%|██████████| 900/900 [02:19<00:00,  6.44it/s]\n",
      "100%|██████████| 1000/1000 [02:34<00:00,  6.45it/s]\n",
      "100%|██████████| 1100/1100 [02:50<00:00,  6.43it/s]\n",
      "100%|██████████| 1200/1200 [03:07<00:00,  6.40it/s]\n",
      "100%|██████████| 1300/1300 [03:22<00:00,  6.42it/s]\n",
      "100%|██████████| 1400/1400 [03:36<00:00,  6.47it/s]\n",
      "100%|██████████| 1500/1500 [03:53<00:00,  6.43it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c005_sigma05_penalization100.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 0.05\n",
    "sigma = 0.5\n",
    "    \n",
    "penalization = 100\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fixed-parish",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.34it/s]\n",
      "100%|██████████| 200/200 [00:31<00:00,  6.43it/s]\n",
      "100%|██████████| 300/300 [00:46<00:00,  6.41it/s]\n",
      "100%|██████████| 400/400 [01:02<00:00,  6.43it/s]\n",
      "100%|██████████| 500/500 [01:17<00:00,  6.44it/s]\n",
      "100%|██████████| 600/600 [01:33<00:00,  6.41it/s]\n",
      "100%|██████████| 700/700 [01:48<00:00,  6.46it/s]\n",
      "100%|██████████| 800/800 [02:04<00:00,  6.44it/s]\n",
      "100%|██████████| 900/900 [02:19<00:00,  6.44it/s]\n",
      "100%|██████████| 1000/1000 [02:35<00:00,  6.42it/s]\n",
      "100%|██████████| 1100/1100 [02:51<00:00,  6.41it/s]\n",
      "100%|██████████| 1200/1200 [03:05<00:00,  6.47it/s]\n",
      "100%|██████████| 1300/1300 [03:22<00:00,  6.41it/s]\n",
      "100%|██████████| 1400/1400 [03:37<00:00,  6.44it/s]\n",
      "100%|██████████| 1500/1500 [03:53<00:00,  6.44it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c005_sigma025_penalization100.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 0.05\n",
    "sigma = 0.25\n",
    "    \n",
    "penalization = 100\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "first-climate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.06it/s]\n",
      "100%|██████████| 200/200 [00:32<00:00,  6.09it/s]\n",
      "100%|██████████| 300/300 [00:49<00:00,  6.10it/s]\n",
      "100%|██████████| 400/400 [01:05<00:00,  6.10it/s]\n",
      "100%|██████████| 500/500 [01:22<00:00,  6.06it/s]\n",
      "100%|██████████| 600/600 [01:38<00:00,  6.11it/s]\n",
      "100%|██████████| 700/700 [01:54<00:00,  6.11it/s]\n",
      "100%|██████████| 800/800 [02:10<00:00,  6.12it/s]\n",
      "100%|██████████| 900/900 [02:27<00:00,  6.12it/s]\n",
      "100%|██████████| 1000/1000 [02:43<00:00,  6.10it/s]\n",
      "100%|██████████| 1100/1100 [03:00<00:00,  6.08it/s]\n",
      "100%|██████████| 1200/1200 [03:17<00:00,  6.08it/s]\n",
      "100%|██████████| 1300/1300 [03:33<00:00,  6.09it/s]\n",
      "100%|██████████| 1400/1400 [03:49<00:00,  6.10it/s]\n",
      "100%|██████████| 1500/1500 [04:06<00:00,  6.08it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c75_sigma01_penalization01.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 75\n",
    "sigma = 0.1\n",
    "    \n",
    "penalization = 0.1\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acute-publicity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  5.97it/s]\n",
      "100%|██████████| 200/200 [00:34<00:00,  5.86it/s]\n",
      "100%|██████████| 300/300 [00:49<00:00,  6.10it/s]\n",
      "100%|██████████| 400/400 [01:05<00:00,  6.08it/s]\n",
      "100%|██████████| 500/500 [01:22<00:00,  6.10it/s]\n",
      "100%|██████████| 600/600 [01:38<00:00,  6.12it/s]\n",
      "100%|██████████| 700/700 [01:55<00:00,  6.08it/s]\n",
      "100%|██████████| 800/800 [02:11<00:00,  6.08it/s]\n",
      "100%|██████████| 900/900 [02:27<00:00,  6.10it/s]\n",
      "100%|██████████| 1000/1000 [02:44<00:00,  6.09it/s]\n",
      "100%|██████████| 1100/1100 [03:01<00:00,  6.06it/s]\n",
      "100%|██████████| 1200/1200 [03:17<00:00,  6.07it/s]\n",
      "100%|██████████| 1300/1300 [03:34<00:00,  6.07it/s]\n",
      "100%|██████████| 1400/1400 [03:49<00:00,  6.09it/s]\n",
      "100%|██████████| 1500/1500 [04:06<00:00,  6.09it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c75_sigma01_penalization10.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 75\n",
    "sigma = 0.1\n",
    "    \n",
    "penalization = 10\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "material-teach",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.08it/s]\n",
      "100%|██████████| 200/200 [00:33<00:00,  6.05it/s]\n",
      "100%|██████████| 300/300 [00:49<00:00,  6.04it/s]\n",
      "100%|██████████| 400/400 [01:05<00:00,  6.07it/s]\n",
      "100%|██████████| 500/500 [01:22<00:00,  6.10it/s]\n",
      "100%|██████████| 600/600 [01:38<00:00,  6.06it/s]\n",
      "100%|██████████| 700/700 [01:55<00:00,  6.04it/s]\n",
      "100%|██████████| 800/800 [02:11<00:00,  6.09it/s]\n",
      "100%|██████████| 900/900 [02:27<00:00,  6.09it/s]\n",
      "100%|██████████| 1000/1000 [02:44<00:00,  6.09it/s]\n",
      "100%|██████████| 1100/1100 [03:01<00:00,  6.07it/s]\n",
      "100%|██████████| 1200/1200 [03:17<00:00,  6.07it/s]\n",
      "100%|██████████| 1300/1300 [03:33<00:00,  6.10it/s]\n",
      "100%|██████████| 1400/1400 [03:51<00:00,  6.05it/s]\n",
      "100%|██████████| 1500/1500 [04:06<00:00,  6.08it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c75_sigma01_penalization100.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 75\n",
    "sigma = 0.1\n",
    "    \n",
    "penalization = 100\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fewer-hampshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.03it/s]\n",
      "100%|██████████| 200/200 [00:33<00:00,  5.99it/s]\n",
      "100%|██████████| 300/300 [00:49<00:00,  6.07it/s]\n",
      "100%|██████████| 400/400 [01:05<00:00,  6.07it/s]\n",
      "100%|██████████| 500/500 [01:22<00:00,  6.07it/s]\n",
      "100%|██████████| 600/600 [01:38<00:00,  6.06it/s]\n",
      "100%|██████████| 700/700 [01:55<00:00,  6.08it/s]\n",
      "100%|██████████| 800/800 [02:12<00:00,  6.06it/s]\n",
      "100%|██████████| 900/900 [02:28<00:00,  6.05it/s]\n",
      "100%|██████████| 1000/1000 [02:43<00:00,  6.11it/s]\n",
      "100%|██████████| 1100/1100 [03:00<00:00,  6.09it/s]\n",
      "100%|██████████| 1200/1200 [03:18<00:00,  6.06it/s]\n",
      "100%|██████████| 1300/1300 [03:34<00:00,  6.06it/s]\n",
      "100%|██████████| 1400/1400 [03:51<00:00,  6.06it/s]\n",
      "100%|██████████| 1500/1500 [04:07<00:00,  6.07it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c75_sigma05_penalization01.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 75\n",
    "sigma = 0.5\n",
    "    \n",
    "penalization = 0.1\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "subjective-douglas",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.01it/s]\n",
      "100%|██████████| 200/200 [00:33<00:00,  6.05it/s]\n",
      "100%|██████████| 300/300 [00:49<00:00,  6.07it/s]\n",
      "100%|██████████| 400/400 [01:05<00:00,  6.06it/s]\n",
      "100%|██████████| 500/500 [01:22<00:00,  6.09it/s]\n",
      "100%|██████████| 600/600 [01:38<00:00,  6.09it/s]\n",
      "100%|██████████| 700/700 [01:55<00:00,  6.05it/s]\n",
      "100%|██████████| 800/800 [02:12<00:00,  6.06it/s]\n",
      "100%|██████████| 900/900 [02:28<00:00,  6.07it/s]\n",
      "100%|██████████| 1000/1000 [02:44<00:00,  6.06it/s]\n",
      "100%|██████████| 1100/1100 [03:01<00:00,  6.07it/s]\n",
      "100%|██████████| 1200/1200 [03:17<00:00,  6.06it/s]\n",
      "100%|██████████| 1300/1300 [03:34<00:00,  6.06it/s]\n",
      "100%|██████████| 1400/1400 [03:51<00:00,  6.06it/s]\n",
      "100%|██████████| 1500/1500 [04:06<00:00,  6.08it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c75_sigma05_penalization10.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 75\n",
    "sigma = 0.5\n",
    "    \n",
    "penalization = 10\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "racial-dakota",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  5.96it/s]\n",
      "100%|██████████| 200/200 [00:33<00:00,  6.02it/s]\n",
      "100%|██████████| 300/300 [00:49<00:00,  6.10it/s]\n",
      "100%|██████████| 400/400 [01:05<00:00,  6.07it/s]\n",
      "100%|██████████| 500/500 [01:22<00:00,  6.04it/s]\n",
      "100%|██████████| 600/600 [01:38<00:00,  6.08it/s]\n",
      "100%|██████████| 700/700 [01:55<00:00,  6.04it/s]\n",
      "100%|██████████| 800/800 [02:12<00:00,  6.02it/s]\n",
      "100%|██████████| 900/900 [02:28<00:00,  6.08it/s]\n",
      "100%|██████████| 1000/1000 [02:45<00:00,  6.03it/s]\n",
      "100%|██████████| 1100/1100 [03:00<00:00,  6.10it/s]\n",
      "100%|██████████| 1200/1200 [03:18<00:00,  6.05it/s]\n",
      "100%|██████████| 1300/1300 [03:34<00:00,  6.06it/s]\n",
      "100%|██████████| 1400/1400 [03:51<00:00,  6.04it/s]\n",
      "100%|██████████| 1500/1500 [04:07<00:00,  6.06it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c75_sigma05_penalization100.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 75\n",
    "sigma = 0.5\n",
    "    \n",
    "penalization = 100\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wooden-spray",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  5.99it/s]\n",
      "100%|██████████| 200/200 [00:32<00:00,  6.09it/s]\n",
      "100%|██████████| 300/300 [00:49<00:00,  6.08it/s]\n",
      "100%|██████████| 400/400 [01:05<00:00,  6.07it/s]\n",
      "100%|██████████| 500/500 [01:22<00:00,  6.08it/s]\n",
      "100%|██████████| 600/600 [01:39<00:00,  6.06it/s]\n",
      "100%|██████████| 700/700 [01:56<00:00,  6.03it/s]\n",
      "100%|██████████| 800/800 [02:12<00:00,  6.06it/s]\n",
      "100%|██████████| 900/900 [02:28<00:00,  6.05it/s]\n",
      "100%|██████████| 1000/1000 [02:46<00:00,  6.01it/s]\n",
      "100%|██████████| 1100/1100 [03:02<00:00,  6.04it/s]\n",
      "100%|██████████| 1200/1200 [03:18<00:00,  6.03it/s]\n",
      "100%|██████████| 1300/1300 [03:40<00:00,  5.89it/s]\n",
      "100%|██████████| 1400/1400 [04:09<00:00,  5.62it/s]\n",
      "100%|██████████| 1500/1500 [04:29<00:00,  5.57it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c75_sigma025_penalization01.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 75\n",
    "sigma = 0.25\n",
    "    \n",
    "penalization = 0.1\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "serial-median",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  5.97it/s]\n",
      "100%|██████████| 200/200 [00:32<00:00,  6.09it/s]\n",
      "100%|██████████| 300/300 [00:49<00:00,  6.08it/s]\n",
      "100%|██████████| 400/400 [01:06<00:00,  6.05it/s]\n",
      "100%|██████████| 500/500 [01:22<00:00,  6.06it/s]\n",
      "100%|██████████| 600/600 [01:39<00:00,  6.03it/s]\n",
      "100%|██████████| 700/700 [01:55<00:00,  6.04it/s]\n",
      "100%|██████████| 800/800 [02:11<00:00,  6.06it/s]\n",
      "100%|██████████| 900/900 [02:27<00:00,  6.09it/s]\n",
      "100%|██████████| 1000/1000 [02:44<00:00,  6.10it/s]\n",
      "100%|██████████| 1100/1100 [03:00<00:00,  6.11it/s]\n",
      "100%|██████████| 1200/1200 [03:18<00:00,  6.04it/s]\n",
      "100%|██████████| 1300/1300 [03:34<00:00,  6.06it/s]\n",
      "100%|██████████| 1400/1400 [03:51<00:00,  6.04it/s]\n",
      "100%|██████████| 1500/1500 [04:06<00:00,  6.09it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c75_sigma025_penalization10.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 75\n",
    "sigma = 0.25\n",
    "    \n",
    "penalization = 10\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mighty-uncle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.04it/s]\n",
      "100%|██████████| 200/200 [00:32<00:00,  6.07it/s]\n",
      "100%|██████████| 300/300 [00:48<00:00,  6.14it/s]\n",
      "100%|██████████| 400/400 [01:05<00:00,  6.09it/s]\n",
      "100%|██████████| 500/500 [01:21<00:00,  6.13it/s]\n",
      "100%|██████████| 600/600 [01:38<00:00,  6.08it/s]\n",
      "100%|██████████| 700/700 [01:55<00:00,  6.07it/s]\n",
      "100%|██████████| 800/800 [02:10<00:00,  6.14it/s]\n",
      "100%|██████████| 900/900 [02:27<00:00,  6.12it/s]\n",
      "100%|██████████| 1000/1000 [02:44<00:00,  6.07it/s]\n",
      "100%|██████████| 1100/1100 [03:04<00:00,  5.97it/s]\n",
      "100%|██████████| 1200/1200 [03:16<00:00,  6.12it/s]\n",
      "100%|██████████| 1300/1300 [03:46<00:00,  5.74it/s]\n",
      "100%|██████████| 1400/1400 [04:41<00:00,  4.98it/s]\n",
      "100%|██████████| 1500/1500 [04:57<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "handler = create_logger('./log/Setosa_c75_sigma025_penalization100.log')\n",
    "\n",
    "\n",
    "    \n",
    "c = 75\n",
    "sigma = 0.25\n",
    "    \n",
    "penalization = 100\n",
    "n_iter = 100\n",
    "    \n",
    "iris_X, iris_dataset = create_dataset(\"Setosa\")\n",
    "\n",
    "# Gurobi prova\n",
    "fi = FuzzyInductor(c = c, k=GaussianKernel(sigma = sigma))\n",
    "fi.fit(iris_X, iris_dataset)\n",
    "\n",
    "#rmse gurobi\n",
    "rmse_gurobi = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "logger.debug(\"RMSE GUROBI: \" + str(rmse_gurobi))\n",
    "\n",
    " \n",
    "    \n",
    "while n_iter <= 1500:\n",
    "        \n",
    "    #TensoFlow prova\n",
    "\n",
    "    try:\n",
    "        fi = FuzzyInductor(solver=TensorFlowSolver(n_iter = n_iter, penalization = penalization), c = c, k=GaussianKernel(sigma = sigma))\n",
    "    except (ModuleNotFoundError, ValueError):\n",
    "        print('Tensorflow not available')\n",
    "\n",
    "    fi.fit(iris_X, iris_dataset) #fi impara iris_X con il confronto con le etichette vere\n",
    "\n",
    "    rmse_tensorflow = mean_squared_error(iris_dataset, fi.predict(iris_X), squared=False)\n",
    "    logger.debug(\"RMSE TENSORFLOW: \"+ str(rmse_tensorflow))\n",
    "\n",
    "    #salvare distanza tra (rmse gurobi) e (rmse tensorFlow)\n",
    "    distance = mt.fabs((rmse_tensorflow) - (rmse_gurobi))\n",
    "    logger.debug(\"DISTANCE RMSE: \"+ str(distance))\n",
    "\n",
    "    #salvare coppia num iterazioni - distanza\n",
    "    couples = [(n_iter, distance)]\n",
    "    logger.debug(\"COUPLE(DISTANCE RMSE): \"+ str(couples))\n",
    "\n",
    "    n_iter += 100 \n",
    "\n",
    "\n",
    "\n",
    "logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-intranet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
