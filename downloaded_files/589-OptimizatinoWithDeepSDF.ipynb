{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import (NNConv, GMMConv, GraphConv, Set2Set)\n",
    "from torch_geometric.nn import (SplineConv, graclus, max_pool, max_pool_x, global_mean_pool)\n",
    "\n",
    "import trimesh\n",
    "\n",
    "from visualization_utils import plot_mesh_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_instance_from_mesh(mesh: trimesh.base.Trimesh) -> torch_geometric.data.Data:\n",
    "        ''' Takes a raw trimesh mesh and transforms it \n",
    "            into a pytorch geometric data instance for prediction normals on each vertex.\n",
    "            \n",
    "            Warning! For some reasons the resulting graph is not directed.\n",
    "        '''\n",
    "\n",
    "        edge_indices = mesh.edges\n",
    "\n",
    "        edge_attributes = [0] * len(edge_indices)\n",
    "        for i, (a, b) in enumerate(edge_indices):\n",
    "            edge_attributes[i] = mesh.vertices[b] - mesh.vertices[a]\n",
    "\n",
    "        data = torch_geometric.data.Data(   x=torch.tensor(mesh.vertices, dtype=torch.float), \n",
    "                                            y=torch.tensor(mesh.vertex_normals, dtype=torch.float),\n",
    "                                            edge_index=torch.tensor(edge_indices, dtype=torch.long).t().contiguous(), \n",
    "                                            edge_attr=torch.tensor(edge_attributes, dtype=torch.float),\n",
    "                                            face=mesh.faces )\n",
    "        return data\n",
    "\n",
    "class NoramalsDataset(torch_geometric.data.Dataset):\n",
    "    ''' Just load a mesh at each iteration and convert it into a data instance.\n",
    "        \n",
    "        Warning! Probably it would be much more eficient to implement \n",
    "            InMemoryDataset and/or store preprocess instances.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, root, transform=None, pre_transform=None, \n",
    "                             apply_rotation=False, train=True, delimetr=0.7):\n",
    "        super(NoramalsDataset, self).__init__(root, transform, pre_transform)\n",
    "        \n",
    "        self.apply_rotation = apply_rotation\n",
    "        \n",
    "        self.objects = list()\n",
    "        for (dirpath, dirnames, filenames) in os.walk(root):\n",
    "            self.objects += [os.path.join(dirpath, file) for file in filenames if file[-4:] == '.obj']\n",
    "        \n",
    "        delimetr = int(delimetr * len(self.objects))\n",
    "        if train:\n",
    "            self.objects = self.objects[:delimetr]\n",
    "        else:\n",
    "            self.objects = self.objects[delimetr:]\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return []\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.objects)\n",
    "\n",
    "    def get(self, idx):\n",
    "        mesh = trimesh.load(self.objects[idx])\n",
    "        if self.apply_rotation:\n",
    "            mesh.apply_transform(trimesh.transformations.random_rotation_matrix())\n",
    "        return make_data_instance_from_mesh(mesh)\n",
    "    \n",
    "class NoramalsInMemoryDataset(torch_geometric.data.InMemoryDataset):\n",
    "    '''\n",
    "        Preprocess dataset and store it\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(NoramalsInMemoryDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['0.obj']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        print(\"Attempt to download dataset\")\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = []\n",
    "        \n",
    "        object_pathes = list()\n",
    "        for (dirpath, dirnames, filenames) in os.walk(self.raw_dir):\n",
    "            object_pathes += [os.path.join(dirpath, file) for file in filenames if file[-4:] == '.obj']\n",
    " \n",
    "        for object_path in tqdm(object_pathes):\n",
    "            mesh = trimesh.load(object_path)\n",
    "            data_list.append(make_data_instance_from_mesh(mesh))\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplineBlock(nn.Module):\n",
    "    def __init__(self, num_in_features, num_outp_features, mid_features, kernel=3, dim=3):\n",
    "        super(SplineBlock, self).__init__()\n",
    "        self.conv1 = SplineConv(num_in_features, mid_features, dim, kernel, is_open_spline=False)\n",
    "        self.conv2 = SplineConv(mid_features, 2 * mid_features, dim, kernel, is_open_spline=False)\n",
    "        self.conv3 = SplineConv(2 * mid_features + num_in_features, num_outp_features, dim, kernel, is_open_spline=False)\n",
    "\n",
    "    def forward(self, data):\n",
    "        res = F.elu(self.conv1(data.x, data.edge_index, data.edge_attr))\n",
    "        res = F.elu(self.conv2(res, data.edge_index, data.edge_attr))\n",
    "        res = torch.cat([res, data.x], dim=1)\n",
    "        res = self.conv3(res, data.edge_index, data.edge_attr)\n",
    "        return res\n",
    "\n",
    "\n",
    "class SplineCNN(nn.Module):\n",
    "    def __init__(self, num_features, kernel=3, dim=3):\n",
    "        super(SplineCNN, self).__init__()\n",
    "        self.block1 = SplineBlock(num_features, 3, 9, kernel, dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        res = self.block1(data)\n",
    "        return res\n",
    "    \n",
    "class SplineCNN2(nn.Module):\n",
    "    def __init__(self, num_features, kernel=3, dim=3):\n",
    "        super(SplineCNN2, self).__init__()\n",
    "        self.block1 = SplineBlock(num_features, 16, 9, kernel, dim)\n",
    "        self.block2 = SplineBlock(16, 3, 32, kernel, dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        data.x = F.elu(self.block1(data))\n",
    "        res = F.elu(self.block2(data))\n",
    "        return res\n",
    "    \n",
    "class SplineCNN4(nn.Module):\n",
    "    def __init__(self, num_features, kernel=3, dim=3):\n",
    "        super(SplineCNN4, self).__init__()\n",
    "        self.block1 = SplineBlock(num_features, 16, 9, kernel, dim)\n",
    "        self.block2 = SplineBlock(16, 64, 32, kernel, dim)\n",
    "        self.block3 = SplineBlock(64, 64, 128, kernel, dim)\n",
    "        self.block4 = SplineBlock(64, 3, 16, kernel, dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        data.x = F.elu(self.block1(data))\n",
    "        data.x = F.elu(self.block2(data))\n",
    "        data.x = F.elu(self.block3(data))\n",
    "        \n",
    "        return self.block4(data)\n",
    "    \n",
    "\n",
    "class MoNet(nn.Module):\n",
    "    def __init__(self, num_features, kernel=[3, 3, 3], dim=3):\n",
    "        super(MoNet, self).__init__()\n",
    "        self.conv1 = GMMConv(in_channels=num_features, out_channels=8, dim=dim, kernel_size=kernel)\n",
    "        self.conv2 = GMMConv(in_channels=8, out_channels=16, dim=dim, kernel_size=kernel)\n",
    "        self.conv3 = GMMConv(in_channels=16, out_channels=8, dim=dim, kernel_size=kernel)\n",
    "        self.conv4 = GMMConv(in_channels=8, out_channels=3, dim=dim, kernel_size=kernel)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        data.x = F.elu(self.conv1(data.x, data.edge_index, data.edge_attr))\n",
    "        data.x = F.elu(self.conv2(data.x, data.edge_index, data.edge_attr))\n",
    "        data.x = F.elu(self.conv3(data.x, data.edge_index, data.edge_attr))\n",
    "        data.x = self.conv4(data.x, data.edge_index, data.edge_attr)\n",
    "        return data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader, device, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    for data in tqdm(train_loader, leave=False):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        responce = model(data)\n",
    "        loss = F.mse_loss(responce, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    del data, loss, responce \n",
    "\n",
    "def validate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "\n",
    "    for data in tqdm(test_loader):\n",
    "        data = data.to(device)\n",
    "        pred = model(data)\n",
    "        loss += F.mse_loss(data.y, pred).cpu().detach().numpy()\n",
    "    return loss / len(test_loader)\n",
    "\n",
    "def process_model(network, out_file_name, train_loader, validation_loader,\n",
    "                  init_lr=0.1, num_epochs=150):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = network(dataset.num_features).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.8, patience=3, min_lr=0.00001, verbose=True)\n",
    "\n",
    "   \n",
    "    start_time = time.time()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        train(epoch, model, train_loader, device, optimizer)\n",
    "        test_acc = validate(model, validation_loader, device)\n",
    "        scheduler.step(test_acc)\n",
    "        with open(out_file_name, 'a') as file:\n",
    "            print('Epoch: {:02d}, Time: {:.4f}, Validation Accuracy: {:.4f}'\\\n",
    "                  .format(epoch, time.time() - start_time, test_acc), file=file)\n",
    "\n",
    "#         start_time = time.time()\n",
    "#         test_acc = validate(model, test_loader, device)\n",
    "#         print('Test, Time: {:.4f}, Accuracy: {:.4f}'\\\n",
    "#               .format(time.time() - start_time, test_acc))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 26.4 s, total: 43.3 s\n",
      "Wall time: 43.3 s\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = NoramalsDataset('/cvlabsrc1/cvlab/dataset_shapenet/manifolds/02691156/')\n",
    "# train_loader = torch_geometric.data.DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# validation_dataset = NoramalsDataset('/cvlabsrc1/cvlab/dataset_shapenet/manifolds/02691156/', train=False)\n",
    "# validation_loader = torch_geometric.data.DataLoader(validation_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "%time dataset = NoramalsInMemoryDataset('/cvlabsrc1/cvlab/dataset_shapenet/normals_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch_geometric.data.DataLoader(dataset[:-16], batch_size=4, shuffle=False)\n",
    "validation_loader = torch_geometric.data.DataLoader(dataset[-16:], batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dataset[:1500]\n",
    "validation_loader = dataset[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92b032e287040fd836f62f9d3b3c768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=150), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ca4a1cc98046a088df4e3c5e3ef191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = process_model(SplineCNN4, 'SplineV4', train_loader, validation_loader, init_lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 24 12:26:41 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.26       Driver Version: 440.26       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:18:00.0 Off |                    0 |\r\n",
      "| N/A   56C    P0    72W / 300W |      0MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if it works on their dataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "cora_dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, aa):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch_geometric.data.DataLoader(cora_dataset, batch_size=1, shuffle=False)\n",
    "model = process_model(Net, 'SplineV1', loader, loader, init_lr=0.1, num_epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy files to a new directory\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "objects = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk('/cvlabsrc1/cvlab/dataset_shapenet/manifolds/02933112/'):\n",
    "    objects += [os.path.join(dirpath, file) for file in filenames if file[-4:] == '.obj']\n",
    "\n",
    "for idx, obj_path in enumerate(objects):\n",
    "    copyfile(obj_path, '/cvlabsrc1/cvlab/dataset_shapenet/normals_dataset/raw_dir/{}.obj'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
